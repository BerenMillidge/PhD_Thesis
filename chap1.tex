\chapter{Introduction}
% 
The Free Energy Principle (FEP) \citep{friston2006free,friston2012free,friston2019particularphysics,parr2020markov} is an emerging theory in theoretical neuroscience which aims to tackle an extremely deep and fundamental question -- can one characterise necessary behaviour of any system that maintains a statistical separation from its environment \citep{parr2020markov,friston2019particularphysics,bruineberg2020emperor}? Specifically, it argues that any such system can be seen as performing an elemental kind of Bayesian inference where the dynamics of the internal states of such a system can be interpreted as minimizing a variational free energy functional \citep{beal2003variational} \footnote{Hence the name the `free-energy principle'}, and thus performing approximate (variational) Bayesian inference \citep{friston2019particularphysics}. The FEP is thus effectively a formalization and generalization of the Ashbyan good regulator principle \citep{conant1970every}, where an intrinsic property of these kinds of systems is that they in some sense come to embody a Bayesian model of their surroundings, and the perform a inference using this model \citep{baltieri2020predictions}.

The free-energy principle therefore provides a close link between the notions of self-organisation and dissipative structures in thermodynamics \citep{prigogine1973theory,seifert2008stochastic}, with cybernetic notions of feedback, regulation, and control \citep{wiener2019cybernetics,kalman1960contributions,johnson2005pid}, to more `cognitive' ideas of inference and learning \citep{schmidhuber1991possibility,dayan2008decision,rao1999predictive}. Specifically, we see that, in some sense, all of these notions can be construed as necessary properties and consequences of systems that self-organize to, and maintain themselves at, a non-equilibrium steady state. While having developed over time into a very general theory of self-organising systems, the free energy principle has emerged from theoretical neuroscience as a way to understand the properties of biological and cognitive systems, especially the brain \citep{friston2003learning,friston2006free}. As such, the most developed process theories, which are explicitly inspired by the free-energy principle -- predictive coding \citep{mumford1992computational,rao1999predictive,friston2005theory}, and active inference \citep{friston2012active,friston2015active,friston2017active}, each purport to be theories of inference, action, and learning in the brain. A core tenet of the free-energy principle is that perception, action, and learning can all be unified under a single inference objective which minimizes a single objective -- the variational free energy. As we shall see, these different `process theories' arise simply from the choice of a specific parametrization of the generative model and the variational density, where certain choices have been found to be useful and also give potentially biologically plausible inference and learning rules. In this thesis, we focus on the high level applications of the free energy principle to neuroscience and to machine learning, and make multiple contributions to the literature through the application of the free energy principle to all of perception, action, and learning. Specifically, in this thesis, we are primarily concerned with \emph{scaling up} methods which have emerged in the theoretical neuroscience literature, to the extremely challenging and complex tasks which can be solved with modern machine learning methods. The value of scaling up such methods is twofold. Firstly, FEP inspired process theories often possess significant biological plausibility, in that they provide a potential account of what the brain is doing -- thus, if they can scale them up to handle the sort of tasks that the brain must solve, then we can be more confident that these theories could, in theory, be actually implemented in the brain. Secondly, the free energy principle and its process theories contain many insights which can potentially be used to improve and extend current state of the art methods in machine learning. In this thesis, we aim to present both kinds of contributions -- firstly by demonstrating that FEP inspired models and process theories can scale, and secondly, by showcasing how ideas from the FEP can be used to advance the field of machine learning or neuroscience on its own terms. 


\subsection{Thesis Overview}

This thesis is organized into three main parts. In the first section (Chapter 3), we consider applications of the free energy principle to \emph{perception} -- and make contributions to the FEP process theory of \emph{predictive coding}. In the second section (Chapters 4 and 5), we consider applications of the free energy principle to \emph{action}, and work with the process theory of \emph{active inference}. Finally, in the third section (Chapter 6), we consider applications of the free energy principle to \emph{learning}, and especially focus on what FEP-inspired models and process theories can tell us about the nature of credit assignment in the brain. Below is a chapter by chapter breakdown of the work in the thesis and what I see are the main contributions to both machine learning and neuroscience in each. Throughout the thesis, since each chapter covers a fairly distinct topic, I have tried to make each chapter modular and mostly independent of the others. Each chapter contains an introduction and mini literature review on the field it discusses, as well as presenting my original work.



%and we work primarily with the process theories of predictive coding and active inference rather than with the general theoretical apparatus of the FEP itself. The thesis splits naturally into two halves. In the first half, we primarily investigate active inference, which is primarily concerned with action selection, and has close links with reinforcement learning. We work on scaling up active inference methods using techniques from machine learning, which have proven instrumental in increasing the power of deep reinforcement learning in the last decade. In the second half of the thesis we focus instead on predictive coding, which interfaces primarily with perception in machine learning and neuroscience. We focus first on empirically testing implementations of predictive coding schemes on machine learning tasks, understanding their relation to other methods in the literature, and improving their biological plausibility and performance characteristics. We also contributions more relevant to pure neuroscience by attacking the problem of credit assignment in the brain where, inspired by predictive coding, we design several biologically plausible algorithms which could, in theory, perform credit assignment in neural circuits.

%\section{Thesis Overview}

%The first half of this thesis will consist of the application of the free-energy principle to machine learning. Specifically, I will review my work integrating and applying active inference and deep reinforcement learning, with the aim both of scaling up active inference approaches to adaptive action selection to be able to handle complex tasks with large underlying state-spaces as well as. conversely, using insights from active inference and the free-energy principle to improve modern deep reinforcement learning methods.

In Chapter 2, I will give a detailed overview of the free energy principle, starting from first principles, and include a discussion of the mathematical assumptions and provide some of my opinions on the philosophical nature of the theory and its potential utility. I will then give a brief walk-through of discrete state space active inference as presented in \citep{friston2015active,friston2017process,da2020active} which will be the focus of the `scaling up' work in Chapter 4.

In Chapter 3, we deal principally with models of perception and predictive coding. We begin by giving a brief overview and mathematical walkthrough of predictive coding theory as it is presented in \citep{friston2005theory,friston2008hierarchical,buckley2017free}. We then cover in depth two contributions to the theory of predictive coding. 
%First, we introduce and discuss hybrid predictive coding, which understands the predictive coding algorithm in terms of iterative inference, and proposes additional amortised `upwards' connections to implement feedforward-sweep like functionality. We demonstrate that this method improves and stabilizes the performance of the predictive coding algorithm while possessing a host of additional algorithmic benefits, not least the capability to automatically tune the amount of computation expended to the intrinsic difficulty  of the task. 
First, we present work where we scale up and empirically test the performance of large scale predictive coding networks on machine learning datasets, which had not been tested before in the literature. We also clarify the relationship between predictive coding and other known algorithms such as Kalman filtering. Secondly, we discuss relaxing various relatively un-biologically plausible aspects of the predictive coding equations, such as the need for symmetric forward and backwards weights, the necessity of using nonlinear derivatives in the update rules, and the one-to-one error to value neuron connectivity required by the standard algorithms. All of these conditions put serious constraints on the biological plausibility of the algorithm, and here we show that to some extent they can each be relaxed without harming performance. %I also present my earlier work on implementing and empirically testing the properties and performance of predictive coding networks on machine learning datasets, as well as my work understanding the relationship between predictive coding and Kalman Filtering.

Then, in Chapters 4 and 5, I present my work on the applications of the free energy principle to questions of action selection and control. Chapter 4 focuses predominantly on scaling up active inference methods to achieve results comparable to those achieved in the deep reinforcement learning literature, while Chapter 5 takes a more abstract and mathematical approach and investigates in depths the mathematical origin of objective functionals which combine both exploitatory and exploratory behaviour -- an approach which has the potential to finesse the exploration-exploitation dilemna \citep{friston2015active}.

Specifically, in Chapter 4, I will first review the rudiments of reinforcement learning (RL), and its current incarnation in deep reinforcement learning, including the two paradigms of model-free and model-based approaches. I will then present two of my contributions of merging active inference and deep reinforcement learning under the new paradigm of deep active inference. I will first discuss deep active inference in the model-free paradigm, and show how in this case the active inference equations can naturally be understood as specifying an actor-critic architecture with a bootstrapped value function, except one where the value-function becomes the expected-free energy functional, which provides an intrinsic source of exploratory drive to the algorithm which can improve performance. I then discuss the similarities and differences to standard deep reinforcement learning algorithms and empirically compare the performance of the algorithms on a number of challenging continuous control tasks from OpenAI gym \citep{brockman2016openai}. 

Then I will present a second piece of work which applies active inference instead to the model-based reinforcement learning paradigm. We will show that in this case, we can use the powerful generative `world models' \citep{ha_recurrent_2018} of active inference to work as transition models of the learnt dynamics, and then the use of action selection in planning. The use of the expected free energy functional again furnishes an intrinsic exploratory for active inference agents, which we again show is crucial to effective, goal-directed exploration and that it empirically improves performance on a suite of continuous control tasks. We then conceptualize reinforcement learning through the lens of inference, and understand the distinction between model-free and model-based reinforcement learning through the lens of iterative and amortised inference. We then demonstrate how these two types of inference can be \emph{combined}, leading to a novel hybrid inference algorithm which we show attains both the sample efficiency of model-based reinforcement learning with the higher asymptotic performance and fast computation time of model-free RL.

Then, in Chapter 5, we move into a more abstract, mathematical domain. Here we grapple with deep questions underlying the objective functions of reinforcement learning. Specifically, we wish to understand the mathematical origin and nature of the expected free energy term which grants deep active inference agents their superior exploratory capacities. Having tackled this, we turn to the deeper question of the mathematical origin of information-seeking exploratory terms within the inference objective optimized in reinforcement learning methods, and thus the mathematical origin of exploratory drives. We present a new dichotomy between \emph{evidence} and \emph{divergence} objectives, and demonstrate how only \emph{divergence} objectives, which intuitively can be seen as minimizing the divergence between the predicted and desired futures, rather than simply maximizing the \emph{likelihood} of the desired future, are required to obtain such terms. We then relate this fundamental dichotomy to a number of objectives prominent in both the cognitive science, neuroscience, and machine learning literatures. Finally, we further seek to explore the general possible space of variational objective functionals for control, and provide a wide-ranging categorisation of the potential of such functionals within our framework.

%The second half of the thesis deals with applications of the free-energy principle, and especially the process theory of predictive coding, to neuroscience applications. I make contributions both to the theory of predictive coding, as well as the theory of credit assignment in the brain. The credit assignment problem concerns how the brain can successfully assign credit backwards from an output to all the many synapses of neurons, distant in space and potentially time from the outcome. Specifically, we are interested in designing biologically plausible approximations to the backpropagation of error algorithm, which has recently achieved incredible success at training deep neural network architectures in machine learning.

Finally, in Chapter 6, we turn to the application of insights and ideas from the free energy principle to \emph{learning}. Specifically, we focus on the vexing question of how to achieve credit assignment in the brain. This is necessary since, we assume, that most of the statistical `parameters' in the brain -- such as synaptic weights -- start out initialized fairly randomly during development and thus need to be trained or learned through interactions with the environment \footnote{It is possible that some pathways, especially low-level subcortical pathways may be, to some extent, hardwired by evolution. However, it is generally considered infeasible for the immense number and complexity of the neocortical circuitry to be hardwired in this way}. Understanding how this learning can take place is a fundamental question within neuroscience. One approach, which has recently been immensely successful in machine learning with large artificial neural networks, is the idea of learning through gradient descent using the backpropagation of error algorithm. Since backpropagation of error is such a successful algorithm in artificial neural network -- which, although simplified are nevertheless generally quite a close substrate to biological neural networks -- it is very likely that it would also work to successfully train biological neural networks, if it could be implemented in a biologically plausible manner in such networks. The question, then, becomes whether and how backprop can be implemented in biologically plausible neural networks. While this is an extremely broad question which cannot likely be answered in a single thesis, we present two novel contributions to this question here.

Specifically, in Chapter 6, we first provide a brief review of the credit assignment problem in the brain, as well as the backpropagation algorithm (and automatic differentiation in general), for context, and then present our two contributions to this field. First, we demonstrate how under certain conditions, predictive coding itself can be utilized as a biologically plausible method of credit assignment in the brain, can apply to any arbitrary computation graph, and can be used to train modern machine learning architectures such as CNNs and LSTMs with performance comparable to backprop. Secondly, we introduce a novel, simpler algorithm for credit assignment in the brain, which we call Activation Relaxation and then discuss their similarities and differences. We end with a discussion of the current state of credit assignment algorithms and backpropagation in the brain, and the importance of this field of research.

Finally, in Chapter 7, we provide a discussion and overview of the work in our thesis. We will briefly survey what has been achieved, and where the limitations and directions for future work lie, as well as the implications of the work of this thesis. 

\section{Statement of Contributions}

This statement provides a detailed overview of the work undertaken in this PhD which has resulted in research papers, both the papers included in this thesis and also those not included. I provide a brief summary of the key results and narrative of each paper, as well as a detailed breakdown my contributions. * denotes equal contribution.


\subsection{Included in Thesis}

%\subsubsection{Chapter 2}

%This introduction to the Free-Energy-Principle, and my understanding of the principle itself, the resolution of many apparent paradoxes and the remaining issues of many more, and the philosophical status and claims of the FEP is heavily indebted to the Particular Physics Reading Group, and in particular many enlightening discussions with Conor Heins, Alec Tschantz, Maxwell Ramstead, Martin Biehl, Nathaniel Virgo, and Lancelot da Costa. Much of this work and discussion is at a very preliminary stage and has not yet been converted into publications, or even pre-prints, so credit cannot be given through the usual citation mechanism. Instead, I acknowledge them here.

%\begin{itemize}

%\item  FEP philosophy/intro paper (if I write one!)

%\item Active inference review (Alec's one which I'll be in separately, probably).
%\end{itemize}

\subsubsection{Chapter 3}

\begin{itemize}

\item \emph{Predictive Coding -- a Theoretical and Experimental review} (2021). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. \emph{In Preparation}

This paper provides a full review of  recent advances in predictive coding, as well as the mathematical basis of the theory. It covers all of the mathematical, implementational, and neuronal aspects of predictive coding theory. As a first author paper, I conceptualised the idea, collated the necessary materials for the review, and wrote the paper. Alexander Tschantz, Christopher Buckley, and Anil Seth, contributed edits and other editorial suggestions.

\item  \emph{Neural Kalman Filtering} (2021). \textbf{Beren Millidge}, Alexander Tscahtnz, Anil Seth, Christopher Buckley. \emph{Arxiv}

This paper reviews the close connection between Kalman filtering and linear predictive coding, demonstrates that predictive coding can closely approximate the performance of Kalman filtering on filtering tasks, and proposes a low-level neural implementation of predictive coding which could be implemented in the brain. As a first author paper, I conceptualised the idea, worked out the mathematical derivations, implemented the model and experiments, and wrote a first draft of the paper. Alexander Tschantz, Christopher Buckley, and Anil Seth contributed editorial and narrative suggestions.

\item  \emph{Relaxed Predictive Coding} (2020). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. (-/submitted to neural networks). 

This paper shows how several biologically implausible aspects of the predictive coding algorithm -- backwards weight symmetry, nonlinear derivatives, and one-to-one error unit connectivity -- can be relaxed without unduly harming performance on challenging object recognition tasks. As a first author paper, I conceptualised the idea, implemented the code and experiments, and wrote up a first draft of the paper. Alexander Tschantz, Anil Seth, and Christopher Buckley contributed editorial suggestions.

%\item \emph{(-/ Hybrid Paper)} (2021). Alexander Tschantz*, \textbf{Beren Millidge}*, Anil Seth, Christopher Buckley (-/submitted ???).

%This paper interprets predictive coding in terms of iterative and amortised inference, and demonstrates that adding amortised feedforward connections to predictive coding networks can stabilize and improve performance, while also adding the neural functionality of the feedforward sweep. As a joint first author paper, I contributed equally to the conceptualisation of the idea, the formulation of the model, and the implementation of the model in code. Alexander Tschantz took the lead with the writing of the paper, although I also contributed to the first draft. I also contributed editorial suggestions to later drafts.

\item \emph{Implementing Predictive Processing and Active Inference: Preliminary Steps and Results} (2019). \textbf{Beren Millidge}, Richard Shillcock. 

This paper provides reference implementations of multi-layer predictive coding networks trained for object recognition within a machine learning paradigm. As a first author paper, I conceptualised the idea, wrote the code and experiments, and wrote up the initial draft of the paper. Richard Shillcock contributed edits.

\end{itemize}

\subsubsection{Chapter 4}
\begin{itemize}
\item \emph{Deep Active Inference as Variational Policy Gradients} (2019). \textbf{Beren Millidge}. Published in the \emph{Journal of Mathematical Psychology}. 
\newline

This paper merges active inference and model-free deep reinforcement learning to create a deep active inference agent, very similar to actor-critic methods in deep reinforcement learning. The performance of deep active inference and deep reinforcement learning is compared on a suite of OpenAI Gym continuous control tasks. As a sole author paper, I conceptualised the idea, executed it mathematically and in code, designed and implemented the experiments and wrote up the paper. 

\item \emph{Reinforcement Learning through Active Inference} (2020). Alexander Tschantz*, \textbf{Beren Millidge}* , Anil Seth, Christopher Buckley. Published in ICLR workshop on \emph{Bridging AI and Cognitive Science}. \newline

This paper applies active inference to model-based reinforcement learning methods for continuous control. We use an ensemble transition model parametrised by deep neural networks for model-based planning. The expected free energy and free-energy-of-the-expected future objective functionals provide additional exploratory bonuses which allow considerably greater and faster performance of the method compared to standard deep reinforcement learning baselines. I was joint first author on this paper. While the initial idea was primarily conceptualized by Alexander Tschantz and Christopher Buckley, I contributed equally to the design and implementation of the algorithm, the experiments, and the writing of the paper.

\item \emph{Reinforcement Learning as Iterative and Amortised inference} (2020). \textbf{Beren Millidge}*, Alexander Tschantz*, Anil Seth, Christopher Buckley. \emph{Arxiv}. \newline

This short workshop paper derives the key mathematical result of understanding model-free and model-based reinforcement learning in terms of iterative and amortised inference. It then partitions known reinforcement learning algorithms into a quadrant based on two orthogonal axes -- firstly whether it uses iterative or amortised reinforcement learning, and secondly whether we optimize over plans or over policies. As a joint first author, I contributed equally (with Alexander Tschantz) in the idea, formulation of the dichotomy, and the mathematical derivations. I also was the primary author of the text of the paper. Alexander Tschantz, Christopher Buckley, and Anil Seth also contributed edits to the paper draft.

\item \emph{Control as Hybrid Inference} (2020). Alexander Tschantz, \textbf{Beren Millidge}, Anil Seth, Christopher Buckley. Published in ICML workshop on the \emph{Theoretical Foundations of Reinforcement Learning}. \newline 

This paper combines both iterative (model-based) and amortised (model-free) reinforcement learning methods to obtain a hybrid method which combines both the sample-efficiency of model-based RL, with the asymptotic performance and fast computation of model-free methods. As second author, I contributed equally to the idea, the mathematical derivation, and architectural formulation of the hybrid agent. Alexander Tschantz took the lead with implementing the agent in code, designing and running, the experiments, and writing up the initial draft of the paper. I then contributed paper edits along with Anil Seth and Christopher Buckley.
\end{itemize}

\subsubsection{Chapter 5}
\begin{itemize}

\item \emph{Whence the Expected Free Energy} (2020). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. Published in \emph{Neural Computation}.

This paper investigates the mathematical origin of the expected free energy functional in active inference, demonstrates its relationship to other algorithm, and proposes a novel, more principled objective, the free-energy of the expected future (FEEF). As a first author, I primarily conceptualised the idea and worked out the mathematical results. I also wrote up the initial draft and was instrumental in handling later edits. Christopher Buckley also contributed significantly to some of the mathematical results. Alexander Tschantz, Christopher Buckley, and Anil Seth, also contributed through edits to the main text of the paper.

\item  \emph{On the relationship of Active Inference and Control as Inference} (2020). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. Published in the \emph{IEEE International Workshop on Active Inference}.

This paper derives the relationship between active inference methods, and the control as inference paradigm which is popular within the reinforcement learning community. As first author, I conceptualised the idea, derived the primary mathematical results, and wrote the initial draft of the paper. Alexander Tschantz, Anil Seth,  and Christopher Buckley contributed paper edits.

\item \emph{Understanding the Origin of Information-Seeking Exploration in Probabilistic Objectives for Control} (2021).\textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. Submitted to \emph{Royal Society Interface}. 

This paper introduces the dichotomy between evidence and divergence objectives, demonstrates how divergence objectives are necessary for the emergence of information maximizing exploration, and unifies many disparate objectives proposed in the machine learning and cognitive science communities under this formalism. As a first author paper, I conceptualised and derived the mathematical results, and wrote up a first draft of the paper. Alexander Tschantz, Christopher Buckley, and Anil Seth contributed paper edits and narrative suggestions. Alexander Tschantz contributed heavily to the cognitive science and psychophysics sections.
\end{itemize}

\subsubsection{Chapter 6}

\begin{itemize}

%\item  \emph{(-/credit assignment review)}. (2021). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. (-/submitted to?). 

%This review paper contains most of the review material on credit assignment methods in the brain in this chapter. As a first author paper, I conceptualized the idea, collated the necessary material for the review, and wrote the initial draft. Alexander Tschantz, Christopher Buckley, and Anil Seth contributed editorial suggestions.

\item \emph{Predictive Coding Approximates Backprop along Arbitrary Computation Graphs} (2020). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. (-/submitted to -??). 

This paper demonstrates that predictive coding can approximate the backpropagation of error algorithm along arbitrary computation graphs. Predictive coding is used to train state of the art machine learning architectures, and obtains identical performance to backprop even for deep and complex architectures. As a first author paper, I conceptualised the idea, implemented the models and experiments in code, and wrote up the initial draft of the paper. Alexander Tschantz, Christopher Buckley, and Anil Seth contributed paper edits and narrative suggestions.

\item \emph{Activation Relaxation: A Local, Dynamical Approximation to Backpropagation in the Brain} (2020). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. (-/submitted to -??).

This paper introduces a novel algorithm for approximating backpropagation in a local, biologically plausible way, which we call the activation relaxation algorithm. Crucially, this approach is significantly simpler than predictive coding, in that it does not require a special population of error neurons. Additionally, we show that several of the remaining biologically implausible aspects of the algorithm -- specifically the symmetric backwards weights -- can also be relaxed, leading to an extremely simple and biologically plausible algorithm for credit assignment. As a first author paper, I invented the algorithm and performend the mathematical derivations. I implemented the model in code, and ran the experiments. I wrote up the initial draft of the paper. Alexander Tschantz, Christopher Buckley, and Anil Seth contributed editorial suggestions.

\item \emph{Investigating the Scalability and Biological Plausibility of the Activation Relaxation Algorithm} (2020). \textbf{Beren Millidge}, Alexander Tschantz, Anil Seth, Christopher Buckley. Published at \emph{NeurIPS 2020 Workshop: Beyond Backprop}.

This paper extends and empirically tests the Activation Relaxation algorithm on more challenging tasks including large-scale CNN models. Moreover, it investigates the degree to which the loosening the assumptions of the activation relaxation algorithm hinder performance. As a first author paper, I conceptualized the core ideas to test, implemented the experiment and analyzed the results. I wrote up the initial draft of the paper. Alexander Tschantz, Christopher Buckley, and Anil Seth contributed editorial suggestions.
\end{itemize}
\subsection{Not Included in the Thesis}
\begin{itemize}

\item \emph{Combining active inference and hierarchical predictive coding -- a tutorial review and case study} (2019). \textbf{Beren Millidge}, Richard Shillcock.

This paper uses hierarchical predictive coding networks as a dynamics model for a simple active inference approach which is then applied to discrete action reinforcement learning tasks such as the cart-pole. As a first author paper, I conceptualised the idea, implemented the code and experiments, and wrote up the initial draft. Richard Shillcock contributed paper edits and suggestions.

\item \emph{A predictive processing account of visual saliency using cross-predicting autoencoders} (2018). \textbf{Beren Millidge}, Richard Shillcock. \emph{Psyarxiv}.

This paper demonstrates how applying a cross-modal prediction objective in predictive coding, allows for the development of error representations which provide a good empirical match to estimates of visual saliency in natural image scenes. As a first author paper, I contributed equally in conceptualising the idea with my supervisor, Richard Shillcock. I implemented the models and experiments, and wrote up the initial draft of the pape 2,192 contributions in the last year r. Richard Shillcock then contributed with editorial suggestions.

\item  \emph{Exploring infant vocal imitation in Tadarida brasiliensis mexicana} (2019). Richard Shillcock, \textbf{Beren Millidge}, Andrea Ravignani. Published in \emph{Neurobiology of Speech and Language}.

This paper introduces a multi-agent model of vocal imitation in bat infants, which provides a gradient soundscape which can guide mothers to pups in a crowded bat colony. As a second author paper, I contributed substantially to the development of the model. I implemented the model in code and ran the experiments. I contributed substantially to the writing of the paper.

%\item (-/hopfield paper) (2021). \textbf{Beren Millidge}, Alexander Tschantz, Christopher Buckley. \emph{In preparation}.

%This paper provides a novel formulation of Hopfield networks as performing variational inference over binary bernoulli latent variables. Using this perspective, we can then derive an additional EM algorithm for learning the weights (as a prior) of the Boltzmann machine, and demonstrate that this improves performance on challenging combinatorial inference problems such as Sudoku. Christopher Buckley was the primary originator of the idea and initial mathematical formulation, although I also contributed. I contributed equally with Alexander Tschantz on the implementation of the model in code, and running the experiments and obtaining results. I was the primary author for writing up most of the paper while Christopher Buckley wrote the mathematical methods section.

\item \emph{Curious inferences: reply to Sun and Firestone on the Dark Room Problem} (2020). Anil Seth, \textbf{Beren Millidge}, Christopher Buckley, Alexander Tschantz. Published in \emph{Trends in Cognitive Science}. 

This short response argues against the \emph{Dark Room Problem} in predictive coding by suggesting that the intrinsic exploratory drives of the expected free energy and other objectives such as the free-energy of the expected future suffice to drive the agent away from dark-room environments. I was involved in the conceptualisation and writing of the piece, although the main impetus behind this response lay with Anil Seth.

\item \emph{The Acquisition of Culturally Patterned Attention Styles under Active Inference} (2020). Axel Constant, Alexander Tschantz, \textbf{Beren Millidge}, Filipo Criado-Boado, Andy Clark. \emph{Arxiv}.

This paper presents an active inference model of culturally patterned saccade behaviour trained on archaeological vase patterns. It demonstrates that more complex patterns result in more vertically oriented saccade behaviour, thus corroborating experimental studies. I jointly designed and implemented the active inference model with Alexander Tschantz and ran the experiments. I also wrote the first draft of the methods section of the paper. Andy Clark, Felipe Criado-Boado, and Axel Constant conceptualised the idea and experiments.

%\item(-/CEM maths paper???)

%\item (-/ Lagrangian active inference???)

%\item (-/springs?)

%\item Active inference tutorial with Alec etc? 

\end{itemize}
