
\chapter{The Free Energy Principle}

The free energy principle is a grand theory, arising out of theoretical neuroscience, with deep ambitions to provide a unified understanding of the nature of self organisation under the rubric of Bayesian inference \citep{friston2006free,friston_free_2019,friston2010free,friston2012free}. Perhaps the central postulate of this theory is the `Free Energy Lemma' which states that one can interpret any self organizing system, of any type and on any scale, as performing a kind of elemental Bayesian inference upon the external environment that surrounds it \citep{friston2013life,friston2012ao,friston2019particularphysics}. More generally than this, it claims to provide a recipe, in terms of a set of statistical independencies -- which we call the `Markov Blanket', following \citep{pearl2011Bayesian} -- which define precisely and mathematically what it means to be a system at all \citep{friston2019particularphysics}. Understanding self-organization through the lens of inference provides an exceptionally powerful perspective for understanding the nature of self-organizing systems, as it allows one to immediately grasp the nature of the dynamics which undergird self-organization, as well as apply the extremely large and powerful literature on Bayesian inference methods and algorithms to the dynamics of self-organizing systems \citep{parr2020modules,parr2020Markov,yedidia2011message}. 
Moreover, by framing everything in statistical terms -- in terms of conditional independencies, generative models, and approximate variational distributions -- the free energy principle provides a novel and powerful vocabulary to talk about such systems, as well as to ask questions such as `what kind of generative model does this system embody?' \citep{baltieri2020predictions, maturana2012autopoiesis} which would be impossible to ask and answer without it. Ultimately, this new statistical and inferential perspective upon dynamics may lead to important advances or novel insights.

This perspective also has exceptionally close relationships with early cybernetic views of control and regulation \citep{wiener2019cybernetics,conant1970every,kalman1960new}, and philosophically the FEP can be seen as a mathematical generalization of Ashby's notion that every good regulator of a system must become, in effect, a model of the system \citep{conant1970every}. The FEP nuances this notion slightly by instead stating that every system that regulates itself against the external environment, must in some sense embody a generative model of the environment, and also that the flow of the internal states of the system necessarily perform approximate variational inference upon an approximate posterior distribution over the external states of the environment, such that, broadly, they track the fluctuations in the external environment.

The free energy principle originated in theoretical neuroscience, as an attempt to understand the mathematical properties that a self-organising living, biotic system, \emph{must} possess in order to sustain itself against thermodynamic equilibrium. It was first and especially applied to understanding the function of the brain \citep{friston2006free,friston2010action,friston2012history}, and has been developed into two main process theories -- predictive coding \citep{rao1999predictive,friston2003learning,friston2005theory,friston2008hierarchical} and active inference \citep{friston2009reinforcement,friston2012active,friston2015active,friston2017process,friston2018deep,da2020active} which have been investigated in a wide variety of paradigms, where it has been used to investigate a wide variety of phenomena from \citep{friston2014anatomy,friston2015knowing,friston2015active}, information foraging and saccades \citep{parr2017uncertainty,parr2018active,parr2019computational} exploratory behaviour \citep{schwartenbeck2013exploration,friston2015active,friston2017curiosity,friston2020sophisticated}, concept learning \citep{schwartenbeck_computational_2019}, and a variety of neuropsychiatric disorders \citep{lawson2014aberrant,adams2012smooth,mirza2019impulsivity,cullen2018active}. These process theories translate the abstract formulation of the FEP into concrete and practical algorithms by specifying certain generative models, variational distributions, and inference procedures, and have been shown to be extremely useful both in providing powerful and biologically plausible theories of learning and inference in the brain, and also in developing highly effective inference algorithms which have advanced the state of the art in machine learning \citep{parr2019neuronal,millidge_deep_2019,tschantz2020reinforcement,millidge2020relationship}. 

In this chapter, we will provide a relatively self-contained step through of the key mathematical results of the most recent incarnation of the free energy principle as presented in \citep{friston2019particularphysics, parr2020Markov}, as well as the details of the discrete-state-space active inference process theory \citep{friston2015active,da2020active}. While none of the material in this chapter is original, it is necessary (especially the material on active inference), to understand what is to come in later chapters. Since this thesis covers a fairly wide range of topics, each individual thesis chapter also comes with its own literature review covering the necessary background for the original material in that chapter.

It is important to note that the material in the first section of this chapter (walkthrough of the Free Energy principle as described in \citet{friston2019particularphysics}) is not original to me and draws heavily from an unpublished monograph \citep{friston2019particularphysics}, albeit a monograph which has widely been viewed as the canonical reference point for the theory. Additionally, many core elements of the theory presented here have been published elsewhere \citep{friston2013life, friston2020some,parr2020Markov,friston2020sentience}. Notably, a fair amount of the material covered here is also controversial within the community and the validity of many required assumptions still remains to be assessed. Where relevant, in this section, we provide additional disclaimers highlighting core assumptions and potentially problematic elements of the mathematical exposition -- and additionally in the discussion section we include an itemized list of all assumptions as well as critical discussions on each. While some of this material is somewhat extraneous to the original work covered in later chapters, we believe that this presentation of the free energy principle gives the reader valuable context into the broader paradigm of the FEP which has inspired much of the original work in this thesis. Additionally, by condensing the logical flow of the FEP, and providing a detailed critical discussion of the logic and assumptions required, we aim to provide a broader service to the community by helping to make clear the current state as well as current controversies and debates at the cutting-edge of the free energy community.

Finally, it is important to note that the process theories derived from the FEP -- which we will primarily focus on in the rest of the thesis -- do not strictly require the full mathematical structure of the FEP to hold for their validity. As scientific theories about the real world, they rise or fall on empirical considerations independently of the overall mathematical construct of the FEP, and thus while the material in this chapter is useful contextually, it is not necessary to understand the work in the chapters that follow. Throughout we have aimed to make sure that each chapter, by and by large, is `modular', so that they can be read and understood in isolation. As such, we have striven to ensure that each chapter contains sufficient background information within it to let it be understood and evaluated independently of the others.

% be very clear and explicit -- i.e. non informed reader you have to buy all of the particular physics add modularity and get a pre-note that you don't have to buy all the arguments in particular physics -- i..e narrative flow but could omit it

%The FEP is famously a very mathematically deep and broad theory, incorporating concepts and techniques from a wide range of disciplines such as advanced statistical methods for Bayesian inference, stochastic thermodynamics, classical physics, and differential geometry. The level of mathematical sophistication required, as well as sometimes dense expositions of the theory in key works, has made full comprehension of the core arguments and central results of the theory difficult to achieve, and has often resulted in confusion in the literature. In this tutorial, we aim to provide a self-contained and intuitive walk-through of the key mathematical results underpinning the FEP, relying on a fairly minimal amount of prerequisite knowledge -- specifically, linear algebra, probability theory and statistics, and basic concepts of differential equations. We also aim to derive all results in a fully explicit way, with substantial commentary to aid intuitive understanding and to make clear all assumptions and major logical moves in the argument. We additionally provide a fairly detailed discussion on the nature and meaning of the core results of the FEP. Finally, we provide a fully worked out case-study of an extremely simple and tractable system which fulfills all the criteria of the FEP and which the abstract mathematical results of the FEP can be applied to. This system can be used to build intuition about the kinds of dynamics the FEP describes, and the nature of the interpretations it ascribes to them, as well as can form a maximally simple test-bed environment for extending the ideas of the FEP.

%\subsection{Related Work}

%While there have been many excellent tutorials on the process theories arising from the free energy principle, such as predictive coding \citep{bogacz2017tutorial,buckley2017free} (-/cite my tutorial), and active inference \citep{da2020active} (-/cites, alec ???), there is a general lack in the literature of mathematically detailed tutorials tackling the central claims of the FEP, especially in its most recent formulation in the \citet{friston2019particularphysics}. This monograph currently represents the theoretical state of the art of the free energy-Principle, and we aim to recapitulate its main results.

%The FEP also involves deep knowledge from a variety of disciplines. For thorough tutorials on variational Bayesian inference, we recommend \citep{fox2012tutorial,beal2003variational,blei2017variational}. For an excellent walk through of differential geometry, information-geometry, and the role of the Fisher Information matrix, we recommend \citet{caticha2015basics}. For a detailed treatment of the principles of stochastic thermodynamics which underlie much of the FEP, we recommend \citet{seifert2008stochastic,seifert2012stochastic,esposito2010three1,van2010three2}. Finally, since the publication of the particular physics monograph, the theory of the FEP has been developed in numerous further publications. A concise overview of the theory is given in \citet{parr2020Markov}. Further development of the operationalization of Markov Blankets is given in \citet{parr2020modules}. Discussion upon different inference algorithms and divergences has been given in \citet{yedidia2011message,blei2017variational}. (-/? Anything else??? )

\section{History and Logical Structure}
\begin{figure}
  \centering
  \includegraphics[scale=0.2]{chapter_2_figures/FEP_logic_flow.pdf}
  \caption{The logical flow of the argument of the FEP from the initial formulation to the crucial approximate Bayesian inference lemma. We begin with a setting of random Langevin stochastic dynamical systems, which possess a non-equilibrium-steady state. By applying the Ao decomposition, we can understand the dynamics in terms of a gradient descent upon the surprisal. Upon the addition of a Markov Blanket partition, we can express subsets in terms of their own marginal flows via the marginal flow lemma. If we then identify the internal states as parametrizing a variational distribution over the external states, we can interpret the marginal flow on the surprisal as a flow on the variational free energy, under the Laplace approximation.}
\end{figure}
Historically, the free energy principle has evolved over the course of about fifteen years. Its intellectual development can best be seen in two phases. In the first phase, an intuitive and heuristic treatment emerged with \citet{friston2006free} which stated that the imperative to minimize variational free energy emerged from a necessary imperative of minimizing the system's entropy, or log model evidence, which is upper bounded by variational free energy. This imperative emerges due to the self-sustaining nature of biological systems such as brains, in that they maintain a set distribution against the inexorably increasing entropic nature of thermodynamic reality \citep{friston2009free}. In order to do so, systems must constantly seek to reduce and maintain their entropy across their state space. Since the VFE is computationally tractable while the entropy itself is not, it was postulated that neural systems maintain themselves by implicitly minimizing this proxy rather than the actual entropy itself \citep{friston2010free}.

Later, in the second phase \citep{friston2013life}, this heuristic argument and intuition was related more formally to concepts in stochastic thermodynamics \citep{friston2012ao,friston2012free}. Specifically, the framework developed mathematically into a description of stochastic dynamics (as stochastic differential equations) separated into `external, internal, and blanket' states by a statistical construct called a \emph{Markov Blanket}. This blanket makes precise the statistical independence conditions required to make sense of talking about a `system' as distinct from its `environment'. Moreover, by separating the `blanket' into `sensory' and `active' states, one can obtain a statistical description of the core elements of a perception-action-loop, a central concept in cybernetics, control theory, and reinforcement learning. Secondly, the theory developed a precise notion of what it means to maintain a stable `phenotype' which is interpreted mathematically as a non-equilibrium steady-state density (NESS) over the state-space. This steady state is non-equilibrium due to the presence of `solenoidal flows' which are flows orthogonal to the gradient of the NESS density. Mathematically, such flows do not increase or decrease the entropy of the steady-state-density, but do, however, in contrast to an equilibrium steady state (ESS), provide a clear arrow of time. Given this, it is claimed, that under certain conditions, one can draw a relationship between the flow dynamics and the process of variational Bayesian inference through the minimization of the variational free energy (VFE)-- which measures the discrepancy between an approximate posterior and generative model -- and that the dynamics that result from this specific kind of flow under a Markov blanket at the NESS density can be seen as approximating a gradient descent upon the VFE, thus licensing the interpretation of the system as performing a basic kind of Bayesian inference or, `self-evidencing' T \citep{hohwy2008predictive,clark2015surfing}

While the intuitions and basic logical structure of the theory has remained roughly constant since \citet{friston2013life,friston2012free}, the mathematical formulation and some of the arguments have been refined in the most recent \citet{friston2019particularphysics} monograph and related papers \citep{friston2020some,parr2020Markov}. These papers have drawn close connections between the formulation of free energy principle, and many aspects of physics including the principle of least action in classical mechanics, and notions of information length and the arrow of time in stochastic thermodynamics. Additionally, the Particular Physics monograph \citep{friston2019particularphysics} contains a novel information-geometric gloss on the nature of the Bayesian inference occurring in the system. Specifically, it argues that the internal states of the system can be seen as points on an \emph{statistical manifold} that parametrize distributions over the external states, and that thus the internal states can be described using a `dual-aspect information geometry.' According to this perspective, internal states evolve in both the `intrinsic' state space of the system's physical dynamics, while simultaneously parameterising a manifold of statistical beliefs about external states - the so-called `extrinsic' information geometry. 

While the mathematical depths of the FEP often appears formidably complex to the uninitiated, the actual logical structure of the theory is relatively straightforward. First, we want to define what it means to be `a system' that keeps itself apart from the outside `environment' over a period of time. The FEP answers this question precisely its own way. We define a `system' as a dynamical system which has a non-equilibrium steady state (NESS) which it maintains over an appreciable length of time, and that the dynamics are structured in such a way that they obey the `Markov Blanket Condition'. Specifically, having a NESS can be intuitively thought of as defining dynamics which produce something like a system -- i.e. a recognizable pattern of states which persists relatively unchanged for some period of time. For instance, we can think of the biological systems in such a manner. Biological organisms maintain relatively steady states, against constant entropic dissipation, for relatively long (by thermodynamic standards) periods of time. Of course, from a purely thermodynamical perspective, in resisting entropy themselves, biological organisms are not countering the law of thermodynamics. To achieve their steady state requires a constant influx of energy -- hence it is a non-equilibrium steady state (NESS). From this perspective, we can understand biological organisation to be the process of creating `dissipative structures' \citep{prigogine1973theory, kondepudi2014modern} which only manage to maintain themselves at steady state and reduce their own entropy at the expense of consuming energy and increasing the entropy production rate of their environment \citep{prigogine2017non}. Illustrative physical examples of similar NESS states are Benard convection cells , and the Belousov-Zhabotinsky reaction \citep{zwanzig2001nonequilibrium}. In practical terms, we can consider the NESS density to be the `phenotype' of the system. From the perspective of the FEP, we are not usually concerned with whether a set of dynamics possesses a NESS density, or how convergence \emph{to} the NESS density works, instead we take it as an axiom that we possess a system with a NESS density, and are instead concerned with the dynamical behaviour of the system \emph{at} the NESS density. While this is clearly a special case, nevertheless dynamical systems at NESS already exhibit rich behaviours to effectively maintain themselves there, and it is these properties which necessarily any system which maintains itself at NESS, which are the fundamental object of study of the FEP. 

Secondly, now that we have a system which has a NESS density, and thus exhibits some stability through time, we also require a statistical way to separate the `system' from the `environment'. The FEP handles this by stipulating that any system it considers must fulfil a set of criteria which we call the Markov Blanket conditions. These conditions, deriving from the idea of Markov blankets in Bayesian networks \citep{pearl2011Bayesian,pearl2014probabilistic}, set forth a set of conditional independence requirements that allow a system to be statistically separated from its environment \footnote{Whenever we say Markov Blanket, following standard use in the literature, we mean the \emph{minimal} Markov blanket -- i.e. the Markov Blanket which requires the fewest number of blanket states to achieve the required conditional independencies.}. Specifically, we require that the dynamics of the system can be partitioned into three sets of states -- `internal' states which belong to the system of study, `external' states which correspond to the environment, and `blanket states' which correspond to the boundary between the system and its environment. Specifically, we require the internal states to be conditionally independent of the external states given the blanket states, and vice versa. Thus all `influence' of the environment must travel through the blanket, and cannot directly interact with the internal states of the system which are `shielded' behind the blanket \footnote{Interestingly, mathematically, the MB condition and all of the FEP is completely symmetrical between `internal' and `external' states. Thus from the perspective of the system, the `external states' are its environment, but from the perspective of the environment, the `external states' are the system. This means that the environment models and performs inference about the system just as the system models and performs inference on the environment. We can thus think of the environment-system interaction as a duality of inference, where each tries to model and infer the other in a loop.}

Now that we have a system with a NESS density which obeys the Markov Blanket conditions, so that we can partition it into external, internal, and blanket states, we then wish to understand the dynamics of the system \emph{at} the NESS density, so we can understand the necessary behaviours of the system to allow the NESS to be maintained. The derivation of the FEP then uses the Helmholtz (Ao) decomposition \citep{yuan2017sde,yuan2011potential,yuan2012beyond} to represent the dynamics as a gradient flow on the log of the NESS density (which is called the surprisal) with both dissipative (in the direction of the gradient) and solenoidal (orthogonal to the gradient) components. Now that we can express the flows of the system in terms of gradients of the log NESS density, we then invoke the \emph{Marginal Flow Lemma} to write out the dynamics of each component of the partitioned dynamics (i.e. external, internal, and blanket states) solely in terms of a gradient flow on its own marginal NESS density. This means that we can express, for instance, the dynamics of the internal states solely in terms of gradient flows on the marginal NESS density over the internal and blanket states.

Given this marginal partition, we can analyze and understand each of the flows in each partition of the system independently. Specifically, to understand the Ashbyan notion that `every good regulator of a system is a model of the system' , we wish to understand the relationship between the flows of the internal and external states, which are statistically separated from the blanket. Despite this separation, it is possible to define a mapping between the most likely internal state, given a specific configuration of the blanket states, and the distribution over the most likely external state of the system. We can use this mapping to interpret internal states as parametrizing a variational or approximate distribution \emph{over} the external states. This interpretation sets up the `dual-aspect' information geometry of the internal states, since internal state changes simultaneously represent changes in parameters of the distribution over internal states (which can potentially be non-parametric), and changes to the parameters of the variational distribution over external states. This latter interpretation means that the internal states parameterise a statistical manifold equipped with a Fisher information metric (if the variational distribution is in the exponential family), and in general becomes amenable to the techniques of information geometry \citep{amari1995information,ollivier2017information} Finally, given that we can interpret the internal states as paramterising a \emph{distribution} over external states, we can reconsider the gradient flow upon the log NESS density with a new light. Specifically, we can understand the marginal NESS density to represent the implicit \emph{generative model} of the system, and the gradient flow dynamics as a descent upon the free energy, with a perfect Bayes-optimal posterior. Alternatively, if we invoke an approximate posterior distribution over external states which is parametrized by the internal states, we can represent the gradient flow of the internal states as performing an approximate minimization of the variational free energy (VFE), and thus the internal states of the system can be interpreted as performing approximate variational Bayes. This is the \emph{key result} of the FEP. It states, simply, that the necessary dynamics of any system that maintains itself at a non-equilibrium steady state, and possesses a Markov Blanket, can be interpreted as modelling, and performing approximate variational inference upon the external states beyond its own Markov Blanket. It thus generalizes and makes precise Ashby's notion that every good regulator must in some sense be a model of the system \citep{conant1970every}. Here we see that in order to maintain a non-equilibrium steady state, to counteract the dissipative forces inherent in thermodynamics, it is necessary to perform some kind of inference about the environment beyond the system itself. 

\section{Formulation}

Here we begin the precise mathematical description of the FEP. We aim to provide a consistent notation, and more detailed derivations of key results than are often presented. The presentation in this chapter mostly follows the order of presentation in \citet{friston2019particularphysics}, although many circumstantial topics are omitted to focus on the main flow of the argument. We begin with the basic mathematical setting and formulation of the theory. We assume that the dynamics we wish to describe can be expressed in terms of a Langevin stochastic differential equation \citep{jaswinskistochastic},
\begin{align*}
\label{FEP_dynamics}
\frac{dx}{dt} = f(x) + \omega \numberthis
\end{align*}
where $x = [x_0 \dots x_N]$ is a vector of states of some dimensionality, and f(x) is an arbitrary nonlinear but differentiable function of the states. Expressing the dynamics in terms of a Langevin stochastic differential equation is a very flexible parametrization of the dynamics, and is the standard form studied in the field of stochastic differential equations, thus allowing the immediate use of results from that field. Specifically, here we assume already that this process is not history dependent. The dynamics only depend on the instantaneous values of the states. In practice, history dependent systems can be represented in this fashion, albeit somewhat unintuitively by adding sufficient statistics of the history to the state itself. $\omega$ is assumed to be white (zero autocorrelation) Gaussian noise with zero mean such that $\omega$ = $\mathcal{N}(x; 0, 2\Gamma)$ where $\Gamma$ is the half the variance of the noise. Zero autocorrelation means that the covariance between the noise at any two time instants, even infintesimally close together, is 0 -- $\E[\omega_t \omega_{t+\delta}^T] = 0$. We assume that this noise is added additively to the dynamics.

This stochastic differential equation can also be represented not in terms of dynamically changing states, but in terms of a dynamically changing \emph{probability distribution} over states. This transformation is achieved through the Fokker-Planck equation, by which we can derive that the change in the distribution over states can be written as,
\begin{align*}
\label{FP_equation}
\frac{d p(x,t)}{dt} = - \nabla_x f(x,t)p(x,t) + \nabla_x \Gamma \nabla_x p(x,t) \numberthis
\end{align*}

Where $p(x,t)$ is the instantaneous distribution over the states at a given time $t$. 
%$p(x,t)$ begins with the distribution $p(x_0, 0) = \mathcal{N}(f(x_0,0), \Gamma)$ due to the initial noise term $\omega$ and the starting state $x_0$. 
Here $\nabla_x f(x,t)$ is the gradient function and simply denotes the vector of partial derivatives of the function $f$ with respect to each element of the vector $x$. $\nabla_x f(x) = [ \frac{\partial f(x,t)}{\partial x_0}, \frac{\partial f(x,t)}{\partial x_N}, \dots , \frac{\partial f(x,t)}{\partial x_N}]$. $\nabla^2_x f(x)$ represents the matrix of second partial derivatives of the function.

Next, we presuppose that the dynamics expressed in Equation \ref{FEP_dynamics} tend towards a non-equilibrium steady state $\lim_{t \to \infty} p(x,t) \to p^*(x)$ where we represent the steady state distribution as $p^*(x)$. Note that this distribution no longer depends on time, since it is by definition at a steady state. We use $p^*$ to make clear that this distribution is at steady state. By definition a steady state distribution does not change with time, so that $\frac{dp^*(x)}{dt} = 0$.

The distinction between an equilibrium steady state and a non-equilibrium steady state (NESS) distribution is subtle and important. An equilibrium steady state, mathematically, is one where the property of detailed balance holds. This means that any transition between states at equilibrium is just as likely to go in the `forwards' direction as it is to go in the `backwards' direction. In effect, the dynamics are completely symmetric to time, and thus there is no notion of an arrow of time in such systems. Conversely, a non-equilibrium steady state is one where detailed balance does not hold, so there is a directionality to the dynamics, and thus an arrow of time, even though the actual distribution over states remains constant. From a thermodynamic perspective, the equilibrium-steady-state is the inexorable endpoint of the second law of thermodynamics, since it is the maximum entropy state. Conversely, a NESS is not a maximum entropy solution, since the directionality of the dynamics means that there is a degree of predictability in the system which could in theory be exploited to produce work. Non-equilibrium steady states can arise in thermodynamic systems but require an external source of driving energy as a constant input to the system, which is then dissipated to the external surroundings and gives the NESS a positive entropy production rate. To take an intuitive example, we can think about the thermodynamic equilibrium of a cup of coffee with cream added. The equilibrium steady state (ESS) is when the coffee and cream have completely diffused into one another, so that the cream maintains a constant proportion throughout the entire coffee cup. This will be the inevitable result (by the second law of thermodynamics) of adding an initially low entropy highly concentrated cream scoop into the coffee. On the other hand, we can think of the non-equilibrium steady state (NESS) as to be when the cream and coffee are equally diffused throughout, but somebody \footnote{Of course the analogy fails here since this represents a system with external driving (the person stirring) whereas the true NESS has no external driving and as such is just `intrinsically being stirred' with no stirrer.} is constantly stirring the coffee in a specific direction. Here, we are at steady state because the concentrations of cream and coffee don't change over time, but nevertheless there is a directionality to the dynamics in the direction of the stirring. This directionality is only maintained due to a constant input of energy \footnote{It's important to note that here we are using physical intuition and concepts like `energy' in a purely metaphorical sense. All results here apply to arbitrary SDEs which do not necessarily follow the same constraints as physical systems -- i.e. respect conservation of energy} to the system (the stirring) \footnote{Interestingly, physical experience with this analogy would suggest that the solenoidal dynamics leading to NESS would lead to faster convergence to the NESS density compared to the strictly dissipative dynamics leading to ESS -- effectively, stirring helps the cream diffuse faster. This insight has been applied to the design of highly efficient Markov-Chain-Monte-Carlo samplers in machine learning \citep{metropolis1953equation,neal2011MCMC,betancourt2013generalizing}}. The flow caused by the stirring is referred to as the `solenoidal flow' and mathematically is necessarily orthogonal to the gradient of the steady state distribution. This is necessary so that the solenoidal flow does not ascend or descent the gradient of the density, and thus change the steady state distribution which, as a steady state, by definition cannot change \footnote{Importantly, in this coffee-cream example, we are not claiming that if the stirring is removed then it will settle into a different steady state distribution, merely that the steady state with the stirring is non-equilibrium steady state (NESS) while the steady-state without stirring is an equilibrium steady state (ESS) due to the lack of solenoidal flow. Adding solenoidal flow to an ESS always can generate a NESS while the converse is not true. There are NESSs which can exist solely in virtue of their solenoidal dynamics without a corresponding ESS. An example of this would be a spinning top, which remains spinning solely due to its solenoidal motion.}. Biological self organizing systems are often considered to be `dissipative structures', or non-equilibrium steady states from the perspective of thermodynamics \citep{prigogine1973theory,kondepudi2014modern}, since they maintain a relatively steady state over time which requires a constant influx of energy to maintain. 

Given that we presuppose a system with a NESS density, we wish to understand the dynamics \emph{at} the NESS density -- specifically, how does the solenoidal flow help prevent the system from relaxing into an equilibrium-steady-state (ESS)? To understand this, we utilize the Helmholtz decomposition \citep{yuan2017sde,yuan2012beyond,friston2012ao} to rewrite the dynamics at the NESS into a form of a dissipative and solenoidal ascent upon the gradient of the log NESS density,
\begin{align*}
\frac{dx}{dt} = (\Gamma(x) - Q(x))\nabla_x \ln p^*(x) \numberthis
\end{align*}
Where $\Gamma(x)$ is a dissipative component of the flow which tries to ascend the log density. It is the amplitude of the random fluctuations in the original SDE formulation \citep{jordan1998variational,yuan2010constructive,yuan2011potential}, which in effect are constantly trying to `smooth out' the NESS density and increase its entropy. Conversely, the $Q(x)$ represents the solenoidal portion of the flow which, although orthogonal to the gradient of the log potential, successfully counteracts the dissipative effects of the $\Gamma(x)$ terms to maintain the dynamics at a steady state. While $\Gamma(x)$ and $Q(x)$ can in theory be state-dependent, from here on out we typically assume that they are not -- $\Gamma(x) = \Gamma$; $Q(x) = Q$, and additionally assume that $\Gamma$ is a diagonal matrix \footnote{Technically, we only need to assume a \emph{block-diagonal} matrix, but we also typically also assume that the noise in each state dimension is independent}, so there is no cross-correlation between states in the noise added to the system.

It is straightforward to verify that the Helmholtz decomposition of the dynamics satisfies the steady state condition $\frac{dp^*(X)}{dt} = 0$ by plugging this form into the Fokker-Planck equation (Equation \ref{FP_equation}),
\begin{align*}
\frac{dp^*(x)}{dt} &= - \nabla_x \big[(\Gamma - Q)\nabla_x \ln p^*(x) \big] p^*(x) + \Gamma \nabla^2_x p^*(x) \\
 &= - \nabla_x \big[(\Gamma - Q)\frac{\nabla_x p^*(x)}{p^*(x)} \big] p^*(x) + \Gamma \nabla^2_x p^*(x) \\
&= - \nabla_x \big[(\Gamma - Q) \nabla_x p^*(x) \big] + \Gamma \nabla^2_x p^*(x) \\
&= -\Gamma \nabla^2_x p^*(x) + \nabla_x Q \nabla_x p^*(x) + \Gamma \nabla^2_x p^*(x) \\
&= \nabla_x Q \nabla_x p^*(x) = 0 \numberthis
\end{align*}

Where the last line follows because, by definition, the gradient of the solenoidal flow with respect to the gradient of the log density is 0, since the solenoidal flow must be orthogonal to the gradient of the density, which is represented by the solenoidal $Q$ matrix being antisymmetric $Q = -Q^T$.

\section{Markov Blankets}

From these preliminaries, we have a set of dynamics of states $x$, which possess a NESS density, and we can express the dynamics at the NESS density in terms of dissipative $\Gamma$ and a solenoidal $Q$ flows on the gradient of the log density. Now, we begin to explore the statistical structure of these dynamics in terms of a Markov Blanket. Specifically, we next require that we can partition the states $x$ of the dynamics into three separate units. External states $\eta$, internal states $\mu$, and blanket states $b$ such that $x = [\eta,\mu,b]$. Intuitively, the external states represent the `environment'; the internal states represent the `system' we wish to describe, and the blanket states represent the statistical barrier between the system and its environment. For instance, we might wish to describe the dynamical evolution of a simple biological system such as a bacterium in such a manner. Here, the internal states would describe the internal cellular environment of the bacterium -- the cytoplasm, the nucleus, the ribosomes etc. The external states would be the environment outside the bacterium, while the blanket states would represent the cell membrane, sensory epithelia, and potentially active instruments such as the flagella which interact physically with the external environment. The key intuition behind the FEP is that although all influence between external and internal states is mediated by the blanket states, simply maintaining the non-equilibrium steady state against environmental perturbations requires that the internal states in some sense model and perform (variational) Bayesian inference on the external states. The Markov Blanket condition is straightforward. It simply states that the internal and external states must be independent given the blanket states,
\begin{align*}
\label{MB_condition}
p^*(x) = p^*(\eta,\mu,b) = p^*(\eta | b)p^*(\mu|b)p^*(b) \numberthis
\end{align*}

\begin{figure}
  \centering
  \includegraphics[scale=1]{chapter_2_figures/Markov_blankets.jpg}
  \caption{The intuition behind the Markov Blanket partition. The brain (or bacillus) consists of internal states $\mu$ which are separated from the outside world (external states $\eta$ by the blanket states $b$, which can themselves be partitioned into sensory states $s$, representing the sensory epithelia, and which are directly influenced by external states, and active states $a$ representing the organisms effectors and which are directly influenced by internal states, and act on external states. We see that perception concerns the minimization of free energy of the \emph{internal states}, while action concerns the minimization of the expected free energy of the \emph{active states}. Figure originally appeared in \citet{friston2019particularphysics}}
\end{figure}

While in probabilistic terms this factorisation is straightforward, it has more complex consequences for the dynamical flow of the system. Firstly, we additionally decompose the blanket states into sensory $s$ and active $a$ states such that $b = [s,a]$ and thus, ultimately $x = [\eta,\mu,s,a]$. Sensory states are blanket states that are causal children of the external states -- i.e. the states that the environment acts on directly. Active states are those blanket states that are not causal children of the external states. Essentially, external states influence sensory states, which influence internal states, which influence active states, which influence external states. The circular causality implicit in this loop is what allows the Markov Blanket condition to represent the perception-action loop. For notational purposes, we also define \emph{autonomous} states $\alpha = [a,\mu]$ which consist of active and internal states, and \emph{particular} states $\pi = [\mu,s,a]$ which consist of sensory, active, and internal states.

The next step is to understand what the conditional independence requirements put forth in Equation \ref{MB_condition} imply for the dynamics of the flow. Specifically, we obtain the \emph{marginal flow lemma} (see \citet{friston2019physics} for a full derivation), which states that the marginal flow of a partition, averaged under its complement, can be expressed as an Ao-decomposed flow on the gradients of the log of the marginal distribution. For instance, the flow of the internal states $\mu$, averaged under the complement $\tilde{\pi}$ of the particular states $\pi$ can be expressed as,

\begin{align*}
  f_\mu (\pi) \triangleq \E_{p(\tilde{\pi} | \pi)}[\frac{d \mu (x)}{dt}] = (\Gamma_{\mu \mu} - Q_{\mu \mu)} \nabla_\mu \ln p^*(\pi) + Q_{\mu \tilde{\mu}} \nabla_{\tilde{\mu}} \ln p^*(\pi) \numberthis
\end{align*}

Importantly, we see that the marginal flow lemma allows us to express the flow of a subset of states, averaged under their complements, in terms of independent Helmholtz decompositions on their marginal NESS densities, if we ignore solenoidal coupling terms (such as $Q_{\mu \tilde{\mu}}$). This allows us to investigate in detail the information-theoretic interactions of one set of states with another, and allows us to gain intuition and understanding of the core information-theoretic properties of the perception-action loop. For instance, using the marginal flow lemma we can express the flow of autonomous (active and internal) $\alpha = (a,i)$ as,
\begin{align*}
f_\alpha(x) = (\Gamma_{\alpha \alpha} - Q_{\alpha \alpha}) \nabla_\alpha \ln p^*(\pi) \numberthis
\end{align*}
where we see that autonomous states follow a gradient descent on the marginal NESS density of the internal, sensory, and active states, and attempt to suppress their surprisal or, on average, their entropy. We can use a series of mathematical `inflationary devices' to express this surprisal in terms of its interaction with the external states beyond the blanket.
\begin{align*}
  -\ln p^*(\pi) &= \E_{p^*(\eta | \pi)}\big[ -\ln p^*(\pi) \big] \\
  &= \E_{p^*(\eta | \pi)}\big[ \ln p^*(\eta | \pi) -\ln p^*(\eta,\pi) \big] \\
  &= \E_{p^*(\eta | \pi)}\big[ \ln p^*( \eta| \pi) -\ln p^*(\pi | \eta) - \ln p^*(\eta) \big] \\
  &=\underbrace{\E_{p^*(\eta | \pi)}\big[ -\ln p^*(\pi | \eta) \big]}_{\text{Inaccuracy}} + \underbrace{\KL \big[p^*(\eta | \pi) || p(\eta)\big]}_{\text{Complexity}} \numberthis
\end{align*}
Thus we can see that the flow of autonomous states acts to minimize the inaccuracy (maximize accuracy) and minimize the complexity of the external states with respect to the particular states of the system in question. Parsed into more intuitive terms, we can thus see that the flow of `system' states ($\pi$) aim to maximize the \emph{likelihood} of the internal states given the external states -- i.e. perform maximum likelihood inference on themselves (c.f. `self evidencing' \citep{hohwy2016self}) -- while simultaneously minimizing the complexity -- or the divergence between the external states given the internal states, and the `prior' distribution over the external states. In short, by re-expressing the flow in information-theoretic terms, we can obtain a decomposition of the entropy term into intuitive and interpretable sub-components which can help us reason about the kinds of behaviours these systems must exhibit.

\section{Variational Inference}

Variational inference is a technique and method for approximating intractable integrals in Bayesian statistics \citep{feynman1998statistical,jordan1998introduction,ghahramani2001propagation,jordan1999introduction,fox2012tutorial,neal1998view}. Typically, a direct application of Bayes-rule to compute posteriors in complicated systems fails due to the intractability of the log model evidence, which appears in the denominator of Bayes' rule. While there exist numerical or sampling-based methods to precisely compute this integral, they typically scale poorly with the dimension of the problem -- a phenomenon which is known as the curse of dimensionality \citep{goodfellow2016deep}. Variational techniques originated from methods in statistical physics in the 1970s and 1980s \citep{feynman1998statistical}, and were then taken up in mainstream statistics and machine learning in the 1990s \citep{ghahramani2001propagation,beal2003variational,jordan1998introduction} where they have become an influential, often dominant approach for approximating posteriors and fitting complex high-dimensional Bayesian models to data \citep{feynman1998statistical,jordan1999introduction,ghahramani2000graphical,beal2003variational,blei2017variational,kingma_auto-encoding_2013,dayan1995helmholtz}.

The core idea of variational inference is to approximate an intractable inference problem with a tractable optimization problem. Thus, instead of directly computing a posterior distribution $p(H | D)$ where $H$ is some set of hypotheses and $D$ is the data, we instead postulate an approximate or variational distribution $q(H | D; \theta)$ which is often, although not always, parametrized with some fixed number of parameters $\theta$. We then seek to optimize the parameters $\theta$ to minimize the divergence between the approximate and true posterior,
\begin{align*}
\theta^* = \underset{\theta}{argmin} \, \KL[q(H | D; \theta) || p(H | D)] \numberthis
\end{align*}
Unfortunately, this optimization problem is itself intractable since it contains the intractable posterior as an element. Instead, we minimize a tractable bound on this quantity called the variational free energy (VFE) $\mathcal{F}(D,\theta)$,
\begin{align*}
\mathcal{F}(D, \theta) &= \KL[q(H | D; \theta) || p(H, D)] \\
&= \KL[q(H | D; \theta) || p(H | D)] - \ln p(D) \\
&\geq \KL[q(H | D; \theta) || p(H | D)] \numberthis
\end{align*}

Since the VFE is based on a divergence between the variational distribution and the generative model $p(D,H)$, it is tractable as we assume we know the generative model that gave rise to the data. By minimizing the VFE, therefore, we reduce the divergence between the true and approximate posteriors, and thus improve our estimate of the posterior. 

Secondly, the variational free energy is simultaneously a bound upon the log model evidence $\ln p(D)$, a quantity of great important for model-selection \citep{geweke2007Bayesian,friston2018Bayesian}, and which is usually intractable to compute due to the implicit integration over all possible hypotheses (or parameters) $p(D) = \int dH p(D | H)p(H)$.
\begin{align*}
\ln p(D) &= \KL[q(H | D; \theta) || p(H, D)] - \mathcal{F}(D,\theta) \\
&\geq -\mathcal{F}(D,\theta) \numberthis
\end{align*}
The second line follows due to the non-negativity of the KL divergence. The VFE is the foundation of the free energy principle as, we shall show, we can interpret self-organizing systems which maintain themselves at a non-equilibrium-steady state to be implicitly minimizing the VFE, and thus performing variational Bayesian inference.

It is important to note here that while the variational free energy $\mathcal{F}$ is not technically a KL divergence, since the two distributions it involves do not share the same support (one being a posterior and the other a joint), for notational convenience in this thesis we slightly abuse the KL notation to represent free energies of one form or another. Formally, we will use $\mathcal{F}[q(x), p(x,y)] = \E_{q(x)}[\ln p(y | x)] + \KL[q(x)||p(x)] = \ln p(y) + \KL[q(x)||p(x|y)] := \KL[q(x)||[(x,y)]$.

We can gain some intuition for the effects of minimizing the VFE by decomposing into various constituent terms. Here we showcase two different decompositions which each give light to certain facets of the objective function,
\begin{align*}
\label{VFE_decomp}
  \mathcal{F}(D, \theta) &= \underbrace{\E_{q(H | D; \theta})[\ln p(H,D)]}_{\text{Energy}} - \underbrace{\mathbf{H}[q(H | D; \theta)]}_{\text{Entropy}} \numberthis \\ 
  &= -\underbrace{\E_{q(H | D;\theta)}[\ln p(D | H)]}_{\text{Accuracy}} + \underbrace{\KL[q(H | D;\theta)||p(H)]}_{\text{Complexity}} \numberthis
\end{align*}
Here we see that we can decompose the variational free energy into two separate decompositions, each consisting of two terms. The first decomposition splits the VFE into an `energy' term, which effectively scores the likelihood of the generative model averaged under the variational distribution, whilst the entropy term encourages the variational distribution to become maximally entropic. Essentially, this decomposition can be interpreted as requiring that the variational distribution maximize the joint probability of the generative model (energy), while simultaneously remaining as uncertain as possible (entropy) \footnote{Interestingly, this energy, entropy decomposition is precisely why this information-theoretic quantity is named the variational \emph{free energy}. The thermodynamic free energy, a central quantity in statistical physics, has an identical decomposition into the energy and the entropy.}. The second decomposition -- into an `accuracy' and a `complexity' term -- speaks more to the role of the VFE in inference. Here the accuracy term can be interpreted as driving the variational density to produce a maximum likelihood fit of the data, by maximizing their likelihood under the variational density. The complexity term can be seen as a regularizer, which tries to keep the variational distribution close to the prior distribution, and thus restrains variational inference from pure maximum-likelihood fitting.
\section{Intrinsic and Extrinsic information geometries}

Now, we wish to understand the relationship between the internal states and the external states, which are separated by the blanket states. Importantly, the existence of the blanket means that we can define a mapping between the most likely internal state, given a specific blanket state, and a distribution over external states \footnote{This function is defined if we assume injectivity between the most likely internal and blanket states \citep{parr2020Markov}.}. We define the most likely internal and external states given a blanket state as,
\begin{align*}
\bm{\eta}(b) &= \underset{\eta}{argmax} \, p(\eta | b) \\
\bm{\mu}(b) &= \underset{\mu}{argmax} \, p(i | b) \numberthis
\end{align*}

Next, we assume that there is a smooth and differentiable function $\sigma$ which maps between the most likely internal and external states given a blanket state,
\begin{align*}
\bm{\eta}(b) = \sigma(\bm{\mu}(b)) \numberthis
\end{align*}
Importantly, we interpret the output of this function -- the most likely external states given the blanket states -- as parametrizing the mean over a full distribution over the external states, as a function of the internal states $q(\eta; \bm{\eta}(b)) = q(\eta; \sigma(\bm{\mu}(b)))$. This allows us to interpret the flow of internal states as parametrising distributions over the external states. 

Crucially, we can say that if any given set of internal states parametrizes a distribution over external states, then the space of internal states effectively represent a \emph{space of distributions} over external states, parametrized by internal states. This space of distributions may be, and usually is, curved and non-euclidean in nature. The field of information geometry has emerged to allow us to describe and mathematically characterise such spaces correctly \citep{amari1995information,caticha2015basics}. A key result in information geometry is that the space of parameters of families of exponential distributions is a non-euclidean space with the Fisher Information as its metric. A metric is simply a notion of distance for a given space. For instance, in Euclidean space, the metric is $\sqrt{\sum_\mu^N x_\mu^2}$ where $N$ is the dimensionality of the space. We can represent general coordinate transformers on spaces with any metric through the use of a metric tensor $\bm{G}$. Essentially, we measure differences between distributions in terms of the KL divergence, and thus if we want to see how an infinitesimal change in the parameters of a distribution results in changes to the distribution itself, we can measure an infinitesimal change in their KL divergence as a function of the infinitesimal change in the parameters. i.e. 
\begin{align*}
\frac{\partial p(x; \theta)}{\partial \theta} = \lim_{\delta \theta \to 0} \KL[p(x; \theta) || p(x; \theta + \delta \theta)] \numberthis
\end{align*}
In the case of the space of parameters of exponential distributions, the metric tensor is the Fisher information, which arises as from the Taylor expansion of the infinitesimal KL divergence between the two distributions. We define $\theta' = \theta + \delta \theta$. Specifically, since there is only an infintesimal change, we can Taylor-expand around $\theta' = \theta$ to obtain,
\begin{align*}
  \KL[p(x;\theta)||p(x;\theta')] &\approx \underbrace{\KL[p(x;\theta)||p(x;\theta)]}_{=0} + \underbrace{\frac{\partial \KL[p(x;\theta)||p(x;\theta')]}{\partial \theta}|_{\theta = \theta'}(\theta - \theta')}_{=0} \\ &+ \frac{\partial^2 \KL[p(x;\theta)||p(x;\theta')]}{\partial \theta^2}|_{\theta = \theta'}(\theta - \theta')^2 \numberthis
\end{align*}`
Where the first two terms vanish, so we need only handle the second term,
\begin{align*}
  \KL[p(x;\theta)||p(x;\theta')] &\approx \frac{\partial^2 \KL[p(x;\theta)||p(x;\theta')]}{\partial \theta^2}|_{\theta = \theta'}(\theta - \theta')^2 \\
  &= \int p(x; \theta) \frac{\partial \ln p(x;\theta)}{\partial \theta}\frac{\partial \ln p(x;\theta)}{\partial \theta} \\ 
  &= \mathbb{F} \numberthis
\end{align*}
% need to give proper explanation of this
where $\mathcal{\mu}$ is the Fisher information. Since the internal states can be interpreted as parametrizing distributions over external states, as parameters, they lie on an information-geometric manifold with a Fisher information metric. This is the extrinsic information geometry. Simultaneously, the internal states also parametrize (implicitly) a second (empirical) distribution over the internal states. This parametrization gives rise to a second information geometry -- the intrinsic geometry, since it represents the relationship the internal states have to the distribution over themselves. Specifically, suppose $\bm{\mu}$ define the sufficient statistics of a variational density over internal states $q(\mu; \bm{\mu})$, and $\bm{\eta} = \sigma(\bm{\mu})$ define the sufficient statistics of the variational density over external states $q(\eta;\bm{\eta})$, then we can see that the internal states in fact parametrize \emph{two} densities and thus partake in two simultaneous information geometries. First, there is a metric defined over the space of internal densities,
\begin{align*}
  \mathcal{\mu}(\bm{\mu}) = \frac{\partial ^2 \KL[q(\mu;\bm{\mu})||q(\mu;\bm{\mu} + \delta \bm{\mu})]}{\partial \bm{\mu}^2}|_{\bm{\mu} + \delta \bm{\mu} = \bm{\mu}}\numberthis
\end{align*}
which is called the \emph{intrinsic} information geometry. And secondly, a metric defined over the space of external densities, parametrized by internal states,
\begin{align*}
  \mathcal{\mu}(\bm{\eta}) =\frac{\partial^2 \KL[q(\eta; \bm{\eta})||q(\eta;\bm{\eta} + \delta \bm{\eta})]}{\partial \bm{\eta}^2}|_{\bm{\eta} + \delta \bm{\eta} = \bm{\eta}} \numberthis
\end{align*}
which is called the \emph{extrinsic} information geometry. These well-defined intrinsic and extrinsic information geometries, allow us to interpret the motion of the internal as also movement on the intrinsic and extrinsic statistical manifolds. Crucially, enabling us to make mathematically precise the link between two conceptually distinct ideas -- dynamical motion in space, and variational inference (i.e. Bayesian belief updating) on parameters of distributions. Using this underlying information-geometric framework, in the next section we shall go on to see how we can interpret the dynamics of a non-equilibrium system at NESS as performing approximate variational Bayesian inference on its external environment.

\section{Self-Organization and Variational Inference}
Here we present the key results of the free energy principle via the free energy lemma. This says, firstly, that the dynamics of the autonomous states can be interpreted as minimizing a free energy functional over the external states, and thus can be construed as performing a kind of elemental Bayesian (variational) inference. Specifically, we will first consider the general case in terms of the `particular' free energy, which stipulatively assumes that the system obtains the correct posterior at every time-point, rendering the traditional variational bound superfluous, and thus demonstrating that in a way self-organizing systems maintaining themselves at NESS can be construed as performing \emph{exact} Bayesian inference on the generative model they embody through their NESS density. We thus reach the key statement of the FEP -- that the dynamics of self-organizing systems that maintain themselves at NESS can be interpreted as performing exact Bayesian inference on the external states beyond their blanket or, alternatively, they can be interpreted as approximating approximate (variational) Bayesian inference. 

We then introduce the general case of the \emph{variational free energy}, which is in general a bound upon the log of the NESS density, and we show in the special case of assuming that the variational distribution over external states which is parametrized by the internal states can be approximated by the Laplace approximation, that we can interpret the flow of autonomous states as directly performing a descent upon the variational free energy and thus directly performing variational Bayesian inference. Since we, as the modeller, can specify the variational distribution in any desired way, then this means that this interpretation is tenable for an extremely wide range of systems. The Laplace approximation approximates the variational distribution as a Gaussian where the variance is a function of the curvature at the mean. Intuitively, this assumption is that the Gaussian is tightly peaked around the mean value. This approximation is theoretically well-justified, due to the underlying Gaussianity of the stochastic noise in the system, and the likely concentration of the probability mass around the mean. Moreover, the Gaussian distribution arises regularly in nature whenever averages over large numbers of independent events are taken (c.f. the Central Limit Theorem (CLT)), and can thus be considered a natural modelling choice for distribution of the mode of the external states given the blanket, which likely is composed of contributions from a large number of specific external states. 

To recall, we can write the flow of autonomous states $\alpha = (i,a)$ in terms of a gradient descent on the log NESS density of the particular states $\ln p(\pi)$ with both dissipative and solenoidal components via the Helmholtz decomposition.
\begin{align*}
f_\alpha(x)= -(\Gamma - Q)\nabla_\alpha \ln p^*(s, \alpha) \numberthis
\end{align*}

Then we can define the particular free energy as the variational free energy, where the variational distribution over external states, is stipulatively defined to be equal to the `true' posterior distribution over external states given the particular states $q(\eta | \pi) = p^*(\eta | \pi)$ \footnote{We implicitly assume here that the variational distribution can be stipulated to be of the same family of the true posterior, so that they can match one another}. With this assumption, we can define the particular free energy using the standard form for the variational free energy
\begin{align*}
\mathcal{F}_{particular} &= \KL[q(\eta | \pi) || p^*(\eta,\pi)] \\
&= -\underbrace{\E_{q(\eta | \pi}[\ln p^*(\eta | \pi)]}_{\text{Accuracy}} + \underbrace{\KL[(q\eta | \pi) || p^*(\pi)]}_{\text{Complexity}} \\
&= \underbrace{\ln p^*(\pi)}_{\text{Evidence}} + \underbrace{\KL[q(\eta | \pi) || p^*(\eta | \pi)]}_{\text{Bound}} \\
&= \ln p^*(\pi) \numberthis
\end{align*}
where the last line follows because the bound is always 0 since we have defined the variational and true posteriors to be the same. Importantly, we see that the particular free energy is then equal to the log of the NESS density over the sensory, internal, and active states. As such, we can rewrite the dynamics of the autonomous states directly in terms of the particular free energy,
\begin{align*}
f_\alpha(x)= -(Q - \Gamma) \nabla_\alpha \mathcal{F}_{particular}(s, \alpha) \numberthis
\end{align*}

While this may seem like just a mathematical sleight of hand, it demonstrates how systems which maintain the statistical structure of a Markov Blanket at equilibrium can in fact be interpreted as performing variational Bayesian inference with a correct posterior distribution. If, conversely, we relax this assumption somewhat, so that, as is typical for variational inference when the class of distributions represented under the variational density does not include the true posterior, then we retain an approximate relationship. That is, when $q(\eta | \pi;\theta) \approx p(\eta | \pi)$, we obtain,
\begin{align*}
\mathcal{F} &= \KL[q(\eta |\pi) || p^*(\eta,\pi)] \\
&= \ln p^*(\pi) + \KL[q(\eta | \pi) || p^*(\eta | \pi)] \\
&\approx \ln p^*(\pi) \\
&\implies f_\alpha(x) \approx -(Q - \Gamma) \nabla_\alpha \mathcal{F}(s, \alpha)
\end{align*}

So we can see that in this case, we can interpret the dynamics of the autonomous states as \emph{approximating} approximate Bayesian inference. This is perhaps the most general statement of the FEP -- that the dynamics of a system which maintains the statistical structure of a Markov Blanket at NESS against external dissipative perturbations, can be interpreted as performing approximate variational Bayesian inference to optimize a distribution over the external states of the environment, parametrized by its own internal states. The distinction between variational and particular free energy, with the particular free energy always using the stipulatively correct posterior, while being somewhat a mathematical trick, is also a useful philosophical distinction to draw. In effect, we can think of the system as always performing correct Bayesian inference, simply because the inference is over the system itself, where the generative model of the system is simply its NESS density. Conversely, we can see the approximation arising from the approximate variational distribution as being related to the imperfection of our own understanding of the system as an exogenous modeller. The system is perfectly happy using its Bayes-optimal posterior at all times. A variational distribution distinct from this posterior must be, in some sense, the creature and creation of the modeller, not of the system, and as such the approximations to the dynamics that arise from this approximation is due to the approximations implicit in modelling rather than in the dynamics of the system per-se. It is also important to note that while we have used an approximation sign, in reality the variational free energy is an \emph{upper bound} upon the log model evidence or the particular free energy -- i.e. $\mathcal{F} \geq \mathcal{F}_{particular}$ and the approximate dynamics can be interpreted as driving the system towards the minimization of this bound, and thus increasing the accuracy of the approximation in a manner analogous to the similar process inherent in variational inference.

While in the general case above, the relationship between the dynamics of the system and variational inference is only approximate, if we are only interested in the\emph{mode} of the external states -- i.e. the most likely external state configuration -- instead of the full distribution, then the approximation becomes exact and we can directly see that the dynamics of the system do perform variational inference upon the mode of the external states. Here we can see that, in a sense, the maximum-a-posteriori (MAP) modes for the internal states precisely track the MAP modes for the external states and thus, under the Laplace approximation, can be seen as directly performing a minimization of the variational free energy.

Firstly, recall from previously that we had defined the smooth mapping between the modes of the external and internal states given the blanket state, $\bm{\eta}(b) = \sigma(\bm{\mu}(b))$. By applying the chain rule to this function, it is straightforward to derive the flow of the external mode with respect to the internal mode,
\begin{align*}
\label{2_2_4}
f_{\bm{\eta}}(b) = \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)} f_{\bm{\mu}}(b)  \numberthis
\end{align*}
Then, assuming that the mapping is invertible (requiring that the internal states and external states have the same dimensionality), or rather in the general case that it has a Moore-Penrose pseudoinverse, we can express the dynamics of the internal mode in terms of the dynamics of the external mode,
\begin{align*}
f_{\bm{\mu}}(b)  = \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)}^{-1} f_{\bm{\eta}}(b)  \numberthis
\end{align*}
Similarly, we can derive the expression of the NESS density over the external mode in terms of the mode of the internal states, which provides a precise mapping, called the \emph{synchronization manifold}, between the two densities, even though they are in fact separated by the Markov Blanket,
\begin{align*}
\label{2_2_6}
\frac{\partial \ln p(\bm{\eta}(b) | b)}{\partial \mu} = \frac{\partial \ln p(\bm{\eta}(b) | b)}{\partial \bm{\eta}(b)}\frac{\partial \sigma(\bm{\mu}(b))}{\partial \mu} \numberthis
\end{align*}
Combining Equation \ref{2_2_4} and Equation \ref{2_2_6} and using the fact that the flow of the external mode, by the marginal flow lemma is, $f_{\bm{\eta}}(b)  = (\Gamma_\eta - Q_\eta) \nabla_\eta \ln p(\bm{\eta}(b) | b)$, we can express the flow of the internal mode in terms of the marginal NESS density over the external states, thus understanding how the internal states probabilistically track changes in their environment,
\begin{align*}
f_{\bm{\mu}}(b)  &= \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)}^{-1} \frac{d \bm{\eta}(b)}{dt} \\
&= \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)}^{-1} (\Gamma_\eta - Q_\eta) \nabla_\eta \ln p(\bm{\eta}(b) | b) \\
&= \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)}^{-1} (\Gamma_\eta - Q_\eta) \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)}^{-1} \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)} \nabla_\eta \ln p(\bm{\eta}(b) | b) \\
 &= (\Gamma_\sigma - Q_\sigma) \nabla_\mu \ln p(\sigma(\bm{\mu}(b))) \numberthis
\end{align*}
where $(\Gamma_\sigma - Q_\sigma) = \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)}^{-1} (\Gamma_\eta - Q_\eta) \frac{\partial \sigma(\bm{\mu}(b))}{\partial \bm{\mu}(b)}^{-1}$. Crucially, this expression allows us to write the flow of the internal mode as a gradient descent on the NESS density of the external mode as a function of the internal mode, given the blanket, with respect to the internal states. Fascinatingly, this relationship takes the same general form of the Helmholtz decomposition with separate dissipative $\Gamma_\sigma$ and solenoidal $Q_\sigma$ components which are simply the original dissipative and solenoidal components with respect to the internal states modulated by the inverse of the mapping function $\sigma$. In effect, this implements a coordinate transform between the coordinates of the flow of the external states to the coordinates of the flow of the mode of the external states, as a function of internal states.

Now we demonstrate how we can interpret this gradient descent on the NESS density of the mode over external states in terms of a direct descent on the variational free energy, and thus as directly and exactly performing variational inference. First, we must define our variational distribution $q(\bm{\eta} | b; \bm{\mu})$ which is a distribution over the modes of external states, given the blanket states, parametrized by the mode of the internal states. Since we are only interested now in distributions over the \emph{mode} of the external states, a reasonable assumption is that it is approximately Gaussian distributed due to the central limit theorem. This means that a Laplace approximation, which is a Gaussian approximation where the covariance is simply a function of the mean, derived via a second order Taylor-expansion of the density at the mode, is a good approximation to use here. We thus define the variational density as,
\begin{align*}
& q(\bm{\eta} | b; \bm{\mu}) = \mathcal{N}(\bm{\eta}; \bm{\mu}, \Sigma(\bm{\mu})) \\
& \text{where} \, \, \Sigma(\bm{\mu}) = \frac{\partial^2 \sigma(\bm{\mu})}{\partial \sigma^2}^{-1} \numberthis
\end{align*}
Importantly, if we substitute this definition of $q$ into the variational free energy and drop constants unrelated to the variational parameters $\bm{\mu}$, we obtain,
\begin{align*}
\mathcal{F} &= \ln p(\bm{\mu}, b) + \frac{1}{2}tr(\Sigma(\bm{\mu})) \frac{\partial^2 \sigma(\bm{\mu})}{\partial \sigma^2}^{-1} + \ln | \Sigma(\bm{\mu}) | \\
&\implies \frac{\partial \mathcal{F}}{\partial \mu} = \frac{\partial \ln p(\bm{\mu}, b)}{\partial \mu}
\end{align*}
The second line follows since this is the only term where $i$ is directly utilized. Then, from this definition, we can see that the variational free energy is actually precisely the gradient term we see in the expression for the flow of the internal state mode, thus allowing us to rewrite it as,
\begin{align*}
\label{Free_energy_descent}
f_{\bm{\mu}}(b)  = (\Gamma_\sigma - Q_\sigma) \nabla_\mu \mathcal{F} \numberthis
\end{align*}
After this thicket of mathematics, we thus see a crucial result for the FEP. That, with a Laplace-encoded variational density, we can see that the mode of the internal states precisely tracks the mode of the external states, and the dynamics that allows it to do so are precisely those of a gradient descent on the variational free energy, thus enabling an exact interpretation of the flow of the internal states as performing Bayesian inference on the external states. This proof demonstrates the fundamentally Ashbyan nature of self-organization at non-equilibrium steady state, where systems, in order to maintain their steady state, and thus existence as distinct systems, are necessarily forced to engage in some degree of modelling or tracking external states of the environment, in order to counter their dissipative perturbations. Interestingly, this exact relationship to variational inference only emerges when considering the \emph{modes} of the system, not the full distribution over environmental and internal states as was done previously, where we only obtained an approximation to variational inference. Perhaps this is because, in some sense, the system need not perform inference on full distributions, but only on modes. This perhaps makes more intuitive sense within the cybernetic Ashbyan paradigm where, in general, the system is seen as significantly smaller than the environment, and thus simply cannot be expected to encode a fully accurate model of the entire environment which, in the extreme case, includes the entire rest of the universe. Instead, the system simply models and tracks coarse-grained environmental variables such as the mode.

\section{The Expected Free Energy and Active Inference}
So far, we have only considered the relationship between internal and external states, and observed that the flow of the internal state can be considered to be performing a variational gradient descent on the parameters of the variational density over external states. The internal state dynamics exactly follow a variational gradient descent if we assume that the internal states parametrize a Laplacian approximate posterior, or they approximately follow a variational gradient descent if we assume a broader class of variational posteriors. From this, we can interpret the flow of the internal states as performing some kind of `perceptual' inference about the causes of fluctuations in the blanket states -- namely, the external states. But what about the active states? How do they fit into this picture? 

First, we recall from the approximate Bayesian inference lemma that we can express the flow of the autonomous states (active and internal) in terms of an approximate gradient descent on the variational free energy (Equation \ref{Free_energy_descent}). By the marginal flow lemma, if we ignore solenoidal coupling between internal and active states, we can partition this descent into separate (marginal) descents on the internal and the active states, allowing us to write the flow of the active states as
\begin{align*}
   f_a(x) \approx (\Gamma_{aa} - Q_{aa}) \nabla_a \mathcal{F}(s, \alpha) \numberthis
\end{align*}
where $\Gamma_{aa}$ and $Q_{aa}$ are the block matrices corresponding solely to the interactions between active states in the larger $\Gamma$ and $Q$ matrices. Crucially, if we recall the definition of the variational free energy,
\begin{align*}
  \mathcal{F}(\pi) &= \KL[q(\eta | \pi; \bm{\mu})||p^*(\eta, \pi)] \\
  &= -\underbrace{\E_{q(\pi | \bm{\mu})}[ -\ln p^*(\pi | \eta)]}_{\text{Inaccuracy}} + \underbrace{\KL[q(\eta | \pi ; \bm{\mu})||p^*(\eta)]}_{\text{Complexity}} \numberthis
\end{align*}
Crucially, the only term in this decomposition that depends on the active states $a$ is the first \emph{inaccuracy} term. Thus, we can straightforwardly write down the flow of the active states as,
\begin{align}
  f_a(x) \approx (\Gamma_{aa} - Q_{aa}) \nabla_a \E_{q(\eta | \bm{\mu})}[ -\ln p^*(\pi | \eta)] \numberthis
\end{align}
Where we can intuitively see that the flow of the active states effectively \emph{minimize} inaccuracy (or maximize accuracy). In effect, we can interpret the flow of the active states at the NESS density to try to ensure that the variational `beliefs' encoded by the blanket and internal states of the system are as accurate as possible. Since active states can only influence external states and \emph{not} internal states, the way this is achieved is by acting upon the external states to bring them into alignment with the beliefs represented by the internal states -- hence \emph{active inference}.

While this provides a good characterisation of the flow of the system at equilibrium, we are often also interested in the properties of dynamical systems as the self-organize \emph{towards} equilibrium. Specifically, we wish to characterise the nature of the active states during this process of self-organization, so that we can understand the necessary kinds of active behaviour any self-organizing system must evince. To begin to understand the nature of this self-organization we first define another information theoretic quantity, the \emph{Expected Free Energy} (EFE) which serves as an upper-bound on surprisal throughout the entire process of self-organization, with equality only at the equilibrium itself. Since we have this upper-bound, we can interpret self-organizing systems away from equilibrium, by following their surprisal dynamics as approximating expected free energy minimization, using logic directly analogous to the approximate Bayesian inference lemma. Conversely, turning this logic around lets us \emph{construct} self-organizing systems by defining some desired NESS density, and then prescribing dynamics which simply minimize the EFE.

To handle systems away from equilibrium, we define some new terminology. We define $p(\eta_t, \mu_t, s_t, a_t | \eta_0, \mu_0, s_0, a_0)$ to be the probability density over the variables of the system at some time $t$, which depends on some set of initial conditions $e_0, \mu_0, s_0, a_0$. To simplify, we average over the external initial condition and only represent the particular initial condition $\pi_0 = (\mu_0, s_0, a_0)$. Next we define the expected free energy $\mathcal{G}(\pi)$ similarly to the variational free energy, but with the current-time predictive density taking the place of the approximate variational posterior, and the NESS density taking the place of the generative model.
\begin{align*}
  \mathcal{G}(\pi) &= \E_{p(\eta_t, \pi_t) | \pi_t)}[\ln p(\eta_t | \pi_t, \pi_0) - \ln p^*(\eta, \pi)] \\
  &= \underbrace{\E_{p(\eta_t, \pi_t) | \pi_t)}[-\ln p^*(\pi | \eta)]}_{\text{Ambiguity}}+ \underbrace{\KL[p(\eta_t | \pi_t, \pi_0)||p^*(\eta)]}_{\text{Risk}} \numberthis
\end{align*}
We see that the EFE mandates the minimization of both ambiguity (i.e. avoiding situations which are heavily uncertain) and risk (avoiding large divergences between the current state density and the equilibrium state. It is straightforward to see that the EFE is an upper bound on the expected predictive surprisal at any time-point, by using the fact that the KL-divergence is always greater than or equal to 0,
\begin{align*}
  &\KL[p(\eta_t, \pi_t | \pi_0)||p^*(\eta, \pi)] \geq 0 \\
  &\implies \mathcal{G}(\pi_t) + \E_{p(\eta_t, \pi_t) | \pi_t)}\ln p(\pi_t | \pi_0)] \geq 0 \\
  &\implies \mathcal{G}(\pi_t) \geq - \E_{p(\eta_t, \pi_t) | \pi_t)}[\ln p(\pi_t | \pi_0)]
\end{align*}
Similarly, it is straightforward to see that at equilibrium, the EFE simply becomes the surprisal.
\begin{align*}
  \KL[p(\eta_t, \pi_t | \pi_0)||p^*(\eta, \pi)] &=  \mathcal{G}(\pi_t) + \E_{p(\eta_t, \pi_t) | \pi_t)}[\ln p(\pi_t | \pi_0)] =0 \\
  &\implies \mathcal{G}(\pi_t) = - \E_{p(\eta_t, \pi_t) | \pi_t)}[\ln p(\pi_t | \pi_0)] \numberthis
\end{align*}
Since this is the case, we can understand the EFE as effectively quantifying the discrepancy between the current predictive density and the equilibrium. Because of this, we can see that the EFE is necessarily a Lyapunov function of self-organizing dynamics, and it makes sense to interpret self-organizing dynamics under a Markov blanket as minimizing the EFE. Conversely, if one wants to define a set of dynamics that self-organize to some given attractor $p^*(\eta,\pi)$ then one simply needs to define dynamics that minimize the EFE to achieve convergence to the equilibrium (in the case where there are no local minima). 

Taking this converse approach allows us to move from simply providing an interpretative characterisation of given dynamics in terms of inference, and move instead to constructing or defining systems, or agents, which can achieve specific goals. This approach is taken in the literature on active inference process theories \citep{friston2012active,friston2015active,friston2017active,da2020active} where instead of simply describing a given stochastic differential equation, we instead consider the NESS density to be the \emph{preferences} or \emph{desires} of the agent often represented as a Boltzmann distribution over environmental rewards $p^*(\eta,\pi) = exp(-r(\eta))$ and the active states (the agent's actions) being computed through a minimization of the EFE, with this minimization either taking place directly as a gradient descent in continuous time and space \citep{friston2009reinforcement} or else as an explicit model-based planning algorithm as in the discrete-time and discrete-space formulation \citep{friston2017process,tschantz2020reinforcement,millidge_deep_2019,millidge2020relationship}.

\section{Philosophical Status of the FEP}
It is worth stepping back from the mathematical morass, at this point, to try to define at a high level what kind of theory, philosophically speaking the FEP is, and what kind of claims it makes. There have been numerous debates in the literature about whether the FEP is `falsifiable', or whether it is `correct', and whether or not it makes any specific, empirical claims \citep{williams2020brain,andrews2020math}. However often debates on this matter are obscured or confused by the challenging and deep mathematical background required for a full understanding of the specifics of the FEP. It is clear from the mathematics that the FEP offers only an `interpretation' of already extant dynamics. In short, FEP presupposes the existence of the kinds of dynamics it wishes to make sense of -- dynamical systems which organize themselves into a non-equilibrium steady state, and which maintain the requisite statistical independency structure of the Markov Blanket condition. Once these conditions are satisfied, the FEP gives an interpretation of the dynamical evolution of such a system as performing a kind of variational Bayesian inference whereby the internal states of the system (defined by the Markov Blanket partition) can be seen as inferring or representing external states which are otherwise statistically isolated behind the Markov Blanket. Crucially, the FEP, in its most general formulation does not make any specific predictions about the flow of the system. It offers an interpretation only. While systems that implement the FEP can be derived, and several process theories have been explicitly derived from within the FEP framework \citep{friston2005theory,friston2015active}, all such theories necessitate making specific and ultimately arbitrary modelling choices, such as of the generative model and variational density. Such choices sit below the level of abstraction that the mathematical theory of the FEP exists at. The FEP offers a mathematical interpretation only of certain dynamical structures.

The FEP is often compared and analogised to the principle of least action in physics \citep{lanczos2012variational} which allows one to describe many physical processes (although not all) as minimizing the path integral of a functional called the `action' over a trajectory of motion \citep{sussman2015structure}. This argument is often used to claim, in my opinion correctly, that the FEP is a mathematical `principle' or interpretation and therefore cannot be falsified or empirically tested. In my opinion, however, the principle of least action is, in its philosophical status, not directly analogous to the FEP. While the relationship between the path integral of the action and the dynamics prescribed by the Euler-Lagrange equations is simply a mathematical truth, the principle of least action itself, as applied to physics contains a fundamentally empirical and falsifiable claim -- that physical systems in the real world can be well described through its own mathematical apparatus -- that is of dynamics derived from minimizing an action. This claim is in principle falsifiable. Not all dynamical systems can be derived from least action principles. If physical systems predominantly came from the class that cannot be so derived, the principle of least action in physics would be effectively falsified, and the mathematical apparatus underlying it would have become nothing more than an arcane mathematical curiosity. So far as we know, there is no a-priori reason why much of physics can be so well understood through action principles, and indeed there are areas of physics -- such as statistical mechanics and thermodynamics, and dissipative non-conservative systems in general -- which \emph{cannot} (so far) be described straightforwardly in these terms.

It appears a closer physics analogy to the FEP might be one direction of Noether's theorem. Noether's theorem proves a direct correspondences between symmetries or invariances in a given system, and conservation laws. For instance, in physical systems, time-translation symmetry implies the conservation of energy, and rotational symmetry (of the underlying euclidean space, not any given object within it) implies the conservation of angular momentum. The FEP, similarly, can be thought to show a correspondence between the dynamics of a certain kind of system (NESS density, Markov Blanket conditions) and the dynamics of variational Bayesian inference. Interestingly, while the `forward' direction from the NESS density and Markov Blanket conditions is treated in the FEP, any reverse conditions -- i.e. whether the presence of Bayesian inference dynamics implies any kind of statistical structure upon the dynamics of the system remains unclear, and this is likely a fruitful direction for further theoretical work. Noether's theorem, unlike the principle of least action, matches more closely than the principle of least action since it only specifies correspondences between certain kinds of mathematical objects (symmetries and conservation laws) just as the FEP only specifies a correspondence between dynamical flows at NESS of a system with a Markov Blanket, and the gradient flows on the variational free energy.

While its status as a mathematical principle and interpretation only can shield the FEP from the possibility of an empirical `falsification', this does not mean that the theory is not subject to some kind of implicit intellectual review. Much of the core motivation behind the FEP has been to try to derive universal properties of the kind of biological self-organizing systems which give rise to structured behaviour including relatively `high level' processes such as the perception-action-loop, explicit perception and inference about the causes of the external world and, ultimately, prospective inference and planning. For instance, much of the FEP literature has been focused on and applied to understanding brain function \citep{friston2008hierarchical,friston2015active,friston2017process}. This ambition renders the FEP open to questions about its `applicability', if not its falsifiability. The FEP imposes relatively stringent conditions that dynamical systems must satisfy for the logical steps in the FEP to hold. In the next section, we present a detailed itemized list and critical discussion of all the assumptions required. Some especially key assumptions, which substantially restrict the potential class of systems the FEP can apply to are:
\begin{itemize}
\item That the system in question can be adequately represented as a Langevin equation (i.e. the system is Markov and does not depend on history) with additive white Gaussian noise.
\item that the dynamical system as a whole have a well-defined NESS density (including over the external states).
\item that the system obey the Markov Blanket conditions, which are, in general, relatively restrictive about the kinds of flows that are possible, and appear to have become more restrictive in \citet{friston2020some}, which precludes any solenoidal coupling between active and sensory states (indeed the didactic treatments of the free energy lemma typically require a block-diagonal Q matrix, meaning \emph{no} solenoidal coupling between subsets of states). If this assumption is relaxed, then there are additional solenoidal coupling terms in the flow of the internal states, so at best one can say that gradient ascent upon the surprisal is a \emph{component of the flow}.
\item That there be an injective mapping between the most-likely internal state given the blanket and the mode of the distribution of external states given the blanket states, which is additionally smooth and differentiable (this is required for the dual-aspect information geometry, and thus the identification with Bayesian inference).
\end{itemize}
These conditions are quite strict about the class of systems that the FEP can apply to, and it is unclear if `real systems' of the kind that FEP desires to explain -- such as biological self-organization, and especially brains, can fulfil them. If it turns out that such systems flagrantly violate the conditions for the FEP, then the FEP cannot be said to apply to them and thus cannot be of use in understanding them, even as an interpretatory device. In this case, the FEP would fail the applicability criterion, and would cease to be particularly useful for its original goals of neuroscience, even if it remains not technically falsified and does, in fact, apply to some obscure mathematical class of dynamical systems. Importantly, many of the assumptions of the FEP, when interpreted strictly, do not appear to hold in general for complex biological systems such as brains. For instance, to take extreme but illustrative examples, it is clear that no biological system is ever in a true non-equilibrium steady state, since eventually all such organisms will age and die, and indeed eventually the entire universe will likely decay to a thermodynamic equilibrium state. Additionally, the Markov Blanket assumption is directly violated by things such as x-rays (and indeed gravity) which can directly interact with `internal states' of the brain, such as neurons, without first passing through the Markov Blanket of the physical boundaries of the brain and the sensory epithelium. As such, for a real physical system, we must take the assumptions of the FEP to be only approximations, which hold locally, or approximately, but not for all time and with complete perfection. It remains to be seen, and empirically investigated if possible, the extent to which the mathematical interpretations and logical statements of the FEP remain robust to such slight relaxations of its core assumptions.

While the FEP provides a mathematical interpretation of certain kinds of dynamics in terms of inference, it also, largely, remains to be seen whether such an interpretation is useful for spurring new ideas, questions, and developments within the fields the FEP hopes to influence -- such as neuroscience, cognitive science, and dynamical systems theory. Returning to our anaologies of the least action principle and Noether's theorem, while both of these mathematical results only provide interpretations of known dynamics, by operating at a high level of abstraction they provide powerful capabilities for generalization. For instance the principle of least action allows for dynamics to be derived, via the Euler-Lagrange equations, directly from the high level specification of the action. For instance, the potentially new or counterfactual laws of physics can be derived simply by postulating a given Lagrangian or Hamiltonian and then working through the mathematical machinery of the principle of least action to derive the ensuing dynamics. Additionally, by investigating invariances in the action, one can often understand the kinds of invariances and degrees of freedom that exist in the actually realized dynamics. Similarly, Noether's theorem allows one to play with setting up certain conserved quantities or symmetries a-priori, and then work out precisely the consequences that these entail for the dynamics. 

It is currently unclear to what extent the FEP offers such powerful advantages of abstraction and generalization. This is largely due to the FEP being immature as a field compared to the cornerstones of classical physics, and the majority of the research effort so far has gone into making the theory precise rather than deriving consequences and generalizations from it, but there are some promising initial signs which have just begun to emerge in the literature of the power the FEP perspective offers. From a practical perspective, the FEP appears to offer a number of novel techniques. Firstly, given a desired NESS density, the free energy lemma provides a straightforward way of deriving dynamics which will necessarily reach that density, due to the fact that the variational free energy becomes a Lyapunov function of the system as a whole. This approach has strong potential links to Markov-Chain-Monte-Carlo methods in machine learning and statistics, which aim to approximate an intractable posterior distribution by the time evolution of a Markov process \citep{metropolis1953equation,neal2011MCMC,betancourt2017conceptual,chen2014stochastic,brooks2011handbook}. The FEP provides a new perspective on such systems as fundamentally performing variational Bayesian inference, and may in future be used to develop improved algorithms in this domain, akin to the developments of Hamiltonian \citep{betancourt2013generalizing} and Riemannian MCMC \citep{girolami2011riemann} methods. For instance, there is much potential in the idea of solenoidal flow speeding up convergence to the desired equilibrium density \citep{ma2015complete}. Conversely, the FEP, through the Helmholtz decomposition, may additionally provide tools for \emph{inferring the eventual NESS density} given a specific set of dynamics \citep{ma2015complete,friston2019particularphysics}. This would allow, again, for an analytical or empirical characterisation of the ultimate fate of a system, and allow for characterising different kinds of systems purely by their dynamics far from equilibrium. 

A second strand of potentially directly useful research which has begun to arise from the FEP is empirical and statistical methodologies for defining, computing, and approximating Markov Blankets. This implies the ability to infer the statistical independency structure of the dynamics purely either from analytical knowledge of the dynamics or, alternatively, from purely observed trajectories. There are already two approaches to achieve this in the literature. One which utilizes graph theory in the form of the graph Laplacian to infer nodes of the Markov blanket based on the parents, and children of parents of the largest eigenstates of the Jacobian \citep{palacios2017biological,friston2013life, friston2020parcels}. A second approach directly uses the Hessian of the dynamics to attempt to read off the conditional independency requirements it implies \citep{friston2020parcels}. These approaches may have substantial merit and utility in understanding the effective statistical independency structure of complex dynamical processes, especially questions regarding functional independence in the brain. This strand of research heavily relates to the question of \emph{abstraction} in dynamical systems -- namely, whether complex systems can or cannot be straightforwardly partitioned into independent subsystems which can then be abstracted over. For instance, the ideal would be the ability to, given a complex high-dimensional dynamical system, parse this system into individual `entities' (separated by Markov blankets) which interact with each other according to another set of (hopefully simpler) dynamical rules. This would allow for an automatic procedure to transform a high dimensional complex system into a simpler, low-dimensional approximate system more amenable for analysis and, ultimately understanding \citep{friston2013life,parr2020modules,friston2007parcels}.

\section{Discussion of Assumptions required for the FEP}
Here we provide a general overview and short discussion of every assumption required at each stage of the FEP. Ultimately, the overall picture that emerges is that the FEP requires many assumptions to work, and it is unlikely that all of them can be fulfilled by the kinds of complex self-organizing systems that the FEP ultimately `wants' to be about -- such as biological self organization and, ultimately, brains. However, this is not necessarily overly problematic for the FEP as many of its assumptions may be approximately, or locally true over small enough time periods. This is not necessarily a bad thing -- almost all of the sciences ultimately use simplified models to try to understand their ultimate objects of study in a more tractable way. The FEP is simply continuing that tradition, but if we do this, we need to make explicit the key distinction between the model and the reality or, more memorably, the map and the territory.

The first set of key assumptions that the FEP makes comes through the definition of the kinds of stochastic dynamical systems that it works with. Specifically, we make the following assumptions about the form of the dynamics we deal with,
\begin{itemize}
  \item The system as a whole can be modelled as a Langevin SDE of the form $\frac{dx}{dt} = f(x) + \omega$
  \item The noise $\omega$ is Gaussian with 0 mean and a covariance matrix $2\Gamma$.
  \item The noise is \emph{additive} to the dynamics
  \item $\Gamma$ does not change with time
  \item $\Gamma$ has no state dependence (no heteroscedastic noise)
  \item $\Gamma$ is a diagonal matrix (each state dimension has independent noise)
  \item The dynamics $f(x)$ do not themselves change with time.
\end{itemize}
We also must make the following assumptions about the system as a whole,
\begin{itemize}
  \item The system is \emph{ergodic}, which means that state and time averages coincide or, alternatively, that there must be some probability of ultimately reaching every part of the system from every other part.
  \item The system possesses a well characterized nonequilibrium-steady-state density (NESS), which does not change over time
  \item Once the system reaches this NESS density it cannot escape it -- there is no metastability or multiple competing attractors.
\end{itemize}
These assumptions setup the basic formalism we wish to consider. From here, we then apply the Ao decomposition to rewrite the dynamics in the form of a gradient descent on the log of the potential function with dissipative and solenoidal components $f(x)= (Q - \Gamma)\nabla_x \ln p^*(x)$. To be able to implement this decomposition requires,
\begin{itemize}
  \item The dynamics function $f$ be smooth and differentiable
\end{itemize}

Now, we apply the Markov Blanket conditions at the NESS density,
\begin{itemize}
  \item The state space $x$ can be partitioned into a set of four states -- internal $i$, external $e$, active $a$ and sensory $s$ which, at the NESS density fulfill the following conditional independence relationships:
  $p^*(x) = p^*(\eta | s,a)p^*(\mu | s,a)p^*(s,a)$.
  \item We thus require \emph{all partitions} to be at NESS, including the \emph{external states}. This means that the environment also has to be at steady state, not just the system.
  \item We often assume no solenoidal coupling between internal and sensory states (internal states do not directly act on sensory states -- only the external states do), nor between active and external states (active states drive the external state but are not driven by it). Mathematically this corresponds to $Q_{s, \mu,} = 0$,$Q_{\eta,a} = 0$. 
  \item We may even require that $Q$ be block diagonal -- thus allowing for \emph{no} solenoidal coupling between subsets of the Markov Blanket at all.
\end{itemize}
Given the Markov Blanket conditions hold, we can then begin to move towards the free energy lemma. To begin with, we must first assume,
\begin{itemize}
  \item There is a unique argmax $\bm{\eta}, \bm{\mu}$ exists for both internal and external states for every blanket state $b$.
  \item That there exists a function $\sigma$ which maps from $\bm{\mu}$ to $\bm{\eta}$
  \item That $\sigma$ is invertible
  \item That $\sigma$ is differentiable  
  \item For the particular free energy, we assume that the variational posterior $q(\eta ; \bm{\mu})$ is equal to the true posterior, and thus that the true posterior can be represented by a vector of sufficient statistics ($\bm{\mu}$).
\end{itemize}
These assumptions on $\sigma$ are quite restrictive. A more detailed discussion of what these assumptions require can be found in the next section of this chapter, where every restriction is listed and discussed in some depth.

Finally, to reach the free energy lemma, we must make the following assumptions,
\begin{itemize}
  \item The flow of the sufficient statistic of external states $\bm{\eta}$ follows the same (Ao-decomposition) dynamics as the external states themselves
  \item The variational distribution $q(\eta;\bm{\mu})$ is a Laplace distribution (Gaussian) with a fixed covariance $\Sigma$ as a function of $\bm{\mu}$.
  %\item The variational covariance $\Sigma$ is not an implicit function of the blanket states
\end{itemize}
This first assumption has come under heavy controversy and is discussed in more detail later. These additional assumptions pertain to the Laplace approximation, but the final assumption here appears to go beyond what is typically required by variational Laplace where, since the conditional distribution is a function of the blanket, one would expect the conditional covariance to be one too.

\subsection{Assumptions on the Form of the Langevin Dynamics}

The FEP formulation makes reasonably strong assumptions about the nature of the dynamics that it models -- restricting them to the form of stochastic dynamics which can be written as a Langevin equation with additive Gaussian noise. While the assumptions on the dynamics function are not that strong, only requiring differentiability and time-independence, the restrictions on the noise in the system are quite severe.

Firstly, it is important to note that using additive white noise, while a common modelling assumption due to its mathematical simplicity, nevertheless imposes some restrictions on the kind of systems that can be modelled -- especially as complex self organizing systems typically evince some kind of colored smooth noise, as well as often power-law noise distributions which are associated with self-organized criticality \citep{ovchinnikov2016introduction}.

However, the further assumptions on the $\Gamma$ covariance matrix -- that it is diagonal, state-independent, and time-independent -- are also strong additional restrictions. Specifically, this means that the noise to every dimension in the system is completely independent of any other dimension, and that the noise is constant at every point throughout the state space and throughout time.
\subsubsection{Ergodicity and the Ao Decomposition}

The Ao decomposition requires both that the dynamics possess a consistent non-equilibrium steady state density (which forms the potential function) and also that the dynamics are ergodic. Additionally, this ergodicity assumption is implicitly used in the Bayesian mechanics, which allows expectations of the surprisal to be taken and interpreted as entropies, and thus to ultimately derive an interpretation of the dynamics in terms of accuracy and complexity. In general, for many biological and self-organizing systems, ergodicity does not hold and such systems typically exhibit substantial amounts of path dependence and irreversibility. This means that on a strict reading, for most systems the FEP desires to model, the ergodicity assumption does not hold. However, it may still be possible to describe ergodicity as holding locally in the small region of the state space around the NESS density and this may be sufficient for an approximate version of the FEP to hold, although the resistance of the FEP to slight perturbations of its assumptions remains unclear.

\subsection{The Markov Blanket Condition}
\subsubsection{Is Information Retained Behind the Blanket? -- The Time Synchronous Markov Blanket Condition}

A potentially substantial problem, which has been raised by Martin Biehl and Nathaniel Virgo, for the FEP is that the Markov Blanket conditions would appear to very strongly imply that the internal states cannot store any more information about the external states than the blanket states. This fact can be derived from a straightforward application of the data processing inequality. Translated into the terminology of biological systems like brains, this would mean that the state of the brain could contain no more information about the environment than the state of the sensory epithelia and actuators at the current time. In effect, this would rule out systems obeying the FEP from exhibiting any sort of long term memory or learning -- clearly a very undesirable side-effect. 

In discussions within the community, there have been many attempts to finesse this apparent difficulty with appeals to notion of nested temporal scales and the local applicability of the FEP. The intuitive argument is that if the Markov Blanket conditions rule out information storage on the macroscale where they apply locally, they may nevertheless allow for the slow accumulation of information over a longer timescale. Effectively, if we can imagine that there are two kinds of variables -- `fast' variables which can change over the a given timescale and `slow' variables which do not. Then, if we can consider the slow variables fixed over some timescale, then we can consider the fast variables to reach a NESS density over that timescale, however over longer timescales, the values of the fast variables can influence the slow variables leading to them changing over time, and thus inducing a different NESS density over among the fast variables. The change in the slow variables can be considered to be learning, and could allow for the accumulation of information over time. This process of timescale separation is directly analogous to the classical distinction between inference (fast) and learning (slow) in machine learning and control theory, and can also be expressed physically in terms of an adiabatic reduction \citep{friston2019particularphysics} which explicitly separates out the dynamics of the system into fast and slow eigenmodes. This construction, however, does require a notion of `approximate' NESS for a timescale which is long enough for the `fast' variables but also short enough for the `slow' variables to appear fixed.


\subsubsection{The Real Constraints on Solenoidal Coupling?}

While the Markov blanket conditions only explicitly disallow solenoidal coupling directly between the internal and external states -- $Q_{\mu,\eta} = 0$, the free energy lemma appears to require a significantly greater reduction of solenoidal coupling. Specifically, the free energy lemma requires that, for a straightforward identification of the surprisal with the free energy, that the form of the dynamics for each marginal subset of states in the partition take the same form as the dynamics of the full set of states $x$. Specifically, this means that \emph{all} solenoidal coupling between the subsets must be suppressed, since if they were not then, by the marginal flow lemma, there would be additional solenoidal coupling terms in Equation \ref{Free_energy_descent}, which would complicate the relation to free energy minimization with additional solenoidal terms. As such, for the free energy lemma, as currently presented, we appear to have the extremely strong condition of the diagonality of $Q$, where each subset in the Markov Blanket is only allowed solenoidal interactions with itself. 

It is important to note that this restriction is significantly stronger than those required just by the Markov Blanket condition, and indeed is stronger even than the flow constraints proposed in \citet{friston2020some}. While this does not entirely rule out any interactions between different subsets of the Markov blanket, it does mean that all interactions have to be mediated through the gradient term, since both the $\Gamma$ and $Q$ matrices are assumed to be diagonal. However, it may be that the additional solenoidal terms in the free energy lemma as a result of non-diagonal Q are not that deleterious to the theory since as these are purely solenoidal terms, they are orthogonal to the flow and do not affect the ultimate minima of the system.

\subsection{Assumptions of the free energy Lemma}
\subsubsection{The $\sigma$ function}

The existence and general properties of the $\sigma$ function have also recently elicited much discussion and debate within the community. Specifically, it is not at all clear that this function exists in the general case, for arbitrary dynamics functions $f$ and conditional NESS distributions $p^*(\eta | b)$ and $p^*(\mu | b)$. In later papers it is assumed to exist under the condition of injectivity between $\bm{\eta}$ and $\bm{\mu}$. In effect, this means that there must be a unique mapping between $\bm{\eta}$ and $\bm{\mu}$ for all blanket states -- i.e. that for every blanket state, if the argmax of the internal states is $\bm{\mu}$, then the argmax of the external states must be $\bm{\eta}$. Additionally, there must be a corresponding (and separate) external argmax for every internal argmax. There may, however, be some external argmaxes with no corresponding internal argmaxes (although the converse condition does not hold). This requires that the dimensionality of the external states be greater than or equal to the dimensionality of the internal states -- which should generally hold for most reasonable systems where we can safely assume that the environment is larger than the system itself. This injectivity condition also guarantees invertibility in the case that the internal and external state spaces are of the same dimension. It is also possible to use the Moore-Penrose pseudoinverse for the case where the external state space is larger, at the cost of the free energy lemma becoming approximate instead of exact.

The differentiability of the $\sigma$ function is a more stringent condition. In many cases this is unlikely to be met, since the argmax functions which the $\sigma$ function maps between are generally nondifferentiable. It remains unclear to what extent differentiable $\sigma$ functions can exist in systems of interest.
\subsubsection{The flow of the Sufficient Statistics $\eta$}

An additional important assumption necessary for the free energy lemma, is that the flow of the sufficient statistics of the external mode follow the same flow as the external states generally. This assumption turns out to be crucial to the free energy lemma which relies heavily in the fact that the flow of the sufficient statistic $\bm{\eta}$ can be written as a gradient descent on the log surprisal -- which can then be expressed in terms of a free energy under the Laplace approximation.

This assumption is also problematic and has been the source of much discussion within the community. The extent to which this assumption is justified remains unclear. Specifically, it appears to rule out the use of arbitrary functions $\xi$ (to be discussed in the next section) to parametrize the external sufficient statistic (although not the internal sufficient statistic). The assumption effectively holds to the extent to which one can describe the sufficient statistic as equal to some external state $\bm{\eta}(b) \approx \eta$, which may occur often for the argmax but not necessarily always. It remains to be seen whether the argmax is in fact the optimal such function -- which is dependent on the blanket, but which can identify a consistent $\eta$ to identify with and thus partake in the same dynamics.

%Interestingly, one can also directly compute the dynamics of the sufficient statistic $\bm{\eta}$ through the chain rule in terms of the dynamics of the blanket states, which do follow the Ao decomposition. If we do this, we obtain,
%\begin{align*}
%  \dot{\bm{\eta}}(b) &= \frac{\partial \bm{\eta}(b)}{\partial b} \frac{db}{dt} \\
%  &= \frac{\partial \bm{\eta}(b)}{\partial b} (Q_{bb} - \Gamma_{bb}) \nabla_b \ln p^*(\mu,s,a)
%\end{align*}
%which is significantly different from the required dynamics as it is a gradient descent on the blanket states $b$ rather than the most likely external state. It is unclear under what conditions we should expect these dynamics to coincide. 

\subsubsection{Potential and Optimal $\xi$ Functions}

%A further interesting question concerns the degree to which it is necessary to define the sufficient statistics $\bm{\eta}$ and $\bm{\mu}$ through the argmax over the conditional distribution over the external or internal states given the blanket. While the assumption that the dynamics of $\bm{\eta}$ equal the dynamics of $\eta$ may impose some constraints for this function for $\ bm{\eta}$, 

While the didactic treatment of the FEP in \citep{friston2019particularphysics, parr2020Markov}, it is assumed that the $\sigma$ function relates the \emph{argmax} of $\eta$ and of $\mu$, this is a simple assumption and is not particularly required by the theory. It only requires that there be \emph{some function} not that it necessarily be an argmax. This means that we could, in theory use an arbitrary function $\bm{\mu}(b) = \xi(b)$ instead of the argmax. Indeed, we might desire to make this function contain \emph{as much information as possible} about the true conditional distribution of the internal states given the external states, so that when the $\sigma$ function maps this to the sufficient statistic of the external density it can be seen as performing inference with the most information possible between the external and internal states. An additional benefit of defining an arbitrary function for $\xi$ instead of using $\xi(b) = argmax \, p(\mu| b)$ is that we can make $\xi$ differentiable, which alleviates much of the difficulty of making $\sigma$ differentiable as well.

While this approach brings many benefits, it also has the drawback of the necessity to choose a suitable function $\xi$ which introduces another degree of freedom into the modelling process. One possible condition is that we could chose the optimal $\xi$ to be the one that contains the most information about the internal state or, alternatively minimizes the KL between the approximate conditional distribution over the internal states parametrized vy $\xi$ and the true conditional over the blanket states. That is, we could define,
\begin{align*}
  \xi^* = \underset{\xi}{argmin} \, \KL[q(\mu; \xi(b)) || p(\mu | b)]
\end{align*}

This would reduce the number of degrees of freedom of $\xi$ and provide a valid modelling target, although the actual computability of this minimization process is potentially a problem, as is whether this objective is actually optimal. Nevertheless, the use of an arbitrary $\xi$ function for the sufficient statistics of the internal states may yet resolve or ameliorate some of the difficulties with the free energy lemma, and is an interesting inroad to begin understanding various relaxations or extensions to the current incarnation of the free energy principle.

\section{Active Inference}

In the previous section, we have covered the very general and abstract form of the FEP, here we elucidate the central process theory that has emerged from the FEP literature in theoretical neuroscience -- Active Inference \citep{friston2012active,friston2009reinforcement}. Active inference is a normative theory of perception, decision-making, and learning which ties these three core cognitive processes together under the general paradigm of variational inference via the minimization of the variational free energy \citep{friston2015active,friston2017process}. Specifically, it views all of these processes as emerging out of a central imperative of the system to minimize its free energy over time, and thus perform inference. Perception can be quite clearly stated as an inference problem of inferring the hidden states and causes of the world from sensory observations. Learning too can be interpreted as inference over the parameters of the generative model, which takes place on a slower timescale than perceptual inference. Finally, action selection, decision-making, and planning can be described as inference on policies over trajectories into the future. While there are numerous methods to perform this inference, active inference chooses to minimize an expected free energy functional which encodes goals in terms of a prior over future states \citep{da2020active}.

Active inference has been applied widely and productively in theoretical neuroscience, and active inference models have been proposed for planning and navigation \citep{kaplan2018planning}, saccadic eye movements \citep{parr2017uncertainty,parr2018active,parr2018anatomy} and visual foraging \citep{parr2019computational,heins2020deep}, and general planning problems in reinforcement learning and machine learning \citep{ueltzhoffer_deep_2018,tschantz2020reinforcement,tschantz2020control,millidge_deep_2019}. Additionally, by simulating various lesions or incorrect update rules in the active inference scheme, one may obtain interesting behavioural anomalies or shortfalls which one can then analogize to known psychiatric disorders -- an approach known as computational psychiatry \citep{parr2019computational,cullen2018active}. By drawing correspondences between disorders of behaviour in tractable artificial systems and the psychiatric symptoms of disorders in humans or other animals, one may be able to shed new light upon the actual mechanistic underpinnings of such disorders, which may lead to novel hypotheses, experimental protocols and, ultimately, treatments. Computational psychiatric approaches using active inference have pioneered statistical, mechanistic models of impulsivity \citep{mirza2019impulsivity}, visual neglect \citep{parr2018computational}, autism \citep{lawson2014aberrant}, schizophrenia \citep{adams2012smooth} substance use disorder and addiction \citep{schwartenbeck2015optimal}, and rumination \citep{hesp2020sophisticated}. Finally, the epistemic imperatives that arise from the minimization of the expected free energy functional have given rise to a number of simulation studies applying the approach to exploration tasks \citep{schwartenbeck2013exploration,friston2015active,friston2017curiosity}, visual foraging and other information-seeking saccade behaviour \citep{heins2020deep,parr2017active}, and exploration in complex sparse-reward environments from reinforcement learning \citep{tschantz2020reinforcement}, which will be significantly expanded upon in later chapters of this thesis.

Broadly, there are two main classes of active inference models in the literature -- continuous-time, continuous-state models, which are an extension of predictive coding models of brain function \citep{friston2009reinforcement,friston2010action,pio2016active,baltieri2017active,baltieri2019pid,millidge2019combining}, and discrete-time discrete-state-space active inference models which have been heavily developed in the literature in the past decade, and perhaps now form the main theory of active inference applied to the brain \citep{da2020active,friston2017process}. All of these models, however, ultimately are derived from the same mathematical apparatus. As such, an advantage of active inference for modelling behaviour is that due to its developed and shared mathematical apparatus, different models are specified simply through the generative model and variational distribution, and can be directly compared through Bayesian model comparison techniques. This can be used to fit active inference models to empirical behavioural data in a straightforward fashion. Continuous time, continuous state based models are explained in depth in Chapter 3, where I discuss my work with these models in the context of predictive coding. Here, we present an introduction to discrete-state-space active inference which shall form the basis of my work in Chapters 4 and 5 of the thesis. 

Here we introduce a more standard notation which shall be used for the rest of the thesis. We consider our agent to be situated in a Partially Observed Markov Decision Process (POMDP) \citep{sutton1990integrated,kaelbling1996reinforcement}. The agent is given observations $o$, and must infer the hidden states of the world $x$ that gave rise to the observations. The agent may additionally possess models with parameters $\theta$, which can also be optimized. Finally, action selection consists of inferring actions $a$, or policies $\pi = [a_0, a_1, \dots a_N]$ which are simply sequences of actions in order to achieve some desired goal. Active inference is based around the fundamental imperative of minimizing the variational free energy (VFE). We may recall from Equation \ref{VFE_decomp} that the VFE consists of the KL divergence between a variational distribution $q(x | o)$ and a generative model $p(o,x)$. 

\begin{align*}
\mathcal{F}(o) = \KL[q(x | o) || p(o,x)] \numberthis
\end{align*}

If we additionally want to infer the parameters $\theta$, we can extend the generative model and variational density to include a distribution over the parameters -- this provides a fully Bayesian treatment of parameters in contrast to many machine learning schemes which treat them effectively as point distributions,
\begin{align*}
\mathcal{F}(o) = \KL[q(x, \theta | o) || p(o,x,\theta)] \numberthis
\end{align*}

In order to implement a specific active inference scheme, the key thing to specify is the nature of the generative model, and the nature of the variational distribution. These two distributions suffice to completely specify the model, and with these distributions set, the processes of learning, inference, and action selection can be handled by the standard mathematical apparatus of the theory. Specifically, given a specific variational distribution and a generative model, we can implement perception as a minimization of the VFE with respect to the variational distribution with respect to the hidden states, and we can implement learning as the minimization of the VFE with respect to the parameters
\begin{align*}
\text{Perception: } &\underset{q(x | o)}{argmin} \, \mathcal{F}(o) \\
\text{Learning: } &\underset{q(\theta | x,o)}{argmin} \, \mathcal{F}(o) \numberthis
\end{align*}
There are then two separate ways to implement action. The most straightforward approach, which is utilized in the continuous time version of active inference is to similarly implement action as a gradient descent on the VFE with respect to action,
\begin{align*}
\text{Action: } &\underset{a}{argmin} \, \mathcal{F}(o(a)) \numberthis
\end{align*}
Where we have made the implicit dependence of the observations, and hence the VFE on action explicit, which makes such a minimization non-trivial. A second approach, which is typically used in the discrete-state-space paradigm is to assume a specific functional form for the variational posterior over policies -- that of a softmax distribution over the Expected Free Energy (EFE) $\mathcal{G}(o,x)$ \citep{friston2015active},
\begin{align*}
\label{EFE_softmax}
\text{Action (discrete-state-space): } Q(\pi) = \sigma(-\mathcal{G}(o,x)) \numberthis
\end{align*}
where $\sigma$ is a softmax function. Effectively, what this states is that the optimal policy is a softmax distributions over the path-integrals of the EFE into the future. Effectively, the optimal distribution over policies is simply one that selects policies in proportion with the exponentiated EFE resulting from executing that policy in the future. This means that the policy with the greatest EFE is most likely, while policies with lesser EFE are exponentially less likely to be selected based on the difference between their EFE and that of the best policy. 

Discrete state-space active inference therefore optimizes two complementary objective functions. Optimizing the variational free energy, which is used for perception and learning, ensures that the agent learns an accurate world model, and is able to accurately infer the hidden states of the world from current observations. The second objective, the expected free energy, is used to score potential plans or action policies, to allow the agent to make decisions which are adaptive relative to its goals. To successfully predict and infer with trajectories in the future requires a highly developed and accurate world-model, able to make accurate multi-step predictions of the consequences of action. Such a world model is provided by the minimization of the VFE in the inference and learning steps. This separation of inference and action selection into two separate objectives -- the VFE and the EFE -- introduces a measure of complexity into the theory which may or may not be unavoidable. In Chapter 5, we focus especially on this question and investigate the nature of the EFE, and whether all facets of inference, learning, and action selection can be subsumed under a \emph{single} unified objective.

\subsection{Discrete State-space models and Perception}

The core component of the discrete-state-space model is the discrete generative models and variational densities it is based upon. Specifically, we split the generative model into a likelihood and prior distribution $p(o,x) = p(o|x)p(x)$, and then represent each of these distributions as a categorical distribution,
\begin{align*}
p(o,x ) &= p(o|x)p(x) \\
p(o|x) &= Cat(o; \hat{o}) = \bm{A} \\
p(x) &= Cat(x; \hat{x}) = \bm{B} \numberthis
\end{align*}


%\begin{figure}
%  \centering
%  \includegraphics[scale=1]{chapter_2_figures/discrete_state_space_AIG.jpg}
%  \caption{A graphical representation of a generic discrete-state-space active inference generative model. On the %right is the graphical model itself. We see that it conforms to a POMDP structure with a policy which generates states which themselves generate observations. On the left is the mathematical detail of all of the distributions for both the generative model and the approximate posterior (variational distribution). We see that all key distributions are categorical in this case, due to the discrete state space. Credit for the figure goes to \citet{da2020active}}
%\end{figure}

A categorical distribution is one that simply directly assigns some probability value to every possible discrete contingency. The parameters $\hat{o}$ and $\hat{x}$ of these distributions are simply these probability values, which can be represented straightforwardly in terms of matrices. $\bm{A} \in \mathcal{R}^{O} \times \mathcal{R}^{X}$ is simply a normalized matrix of probabilities representing the likelihood contingencies -- that is, for every hidden state $x$, what is the probability of each potential outcome. Similarly, the transition matrix $\bm{B} \in \mathcal{R}^{X} \times \mathcal{R}^{X}$ is a matrix of probabilities representing the probability of transitioning from any one hidden state to any other hidden state. Similarly, we define our variational distribution $q(x | o = o_\mu;\hat{x}_q) \in \mathcal{R}^{X}$ to be a categorical distribution of the probability of each discrete hidden state as a function of the observed observation $o_\mu$. With our variational and generative model set, we can explicitly write out and evaluate the VFE,
\begin{align*}
\mathcal{F} &= \KL[q(x | o) || p(o,x)] \\
&= \E{q(x | o; \hat{x}_q)}[\ln q(x | o; \hat{x}_q)] - \E_{q(x | o; \hat{x}_q)}[\ln p(o|x; \hat{o})] - \E_{q(x | o; \hat{x}_q)}[\ln p(x; \hat{x})] \\
&= \hat{x}_q \ln \hat{x}_q - \hat{x}_q \ln \bm{A} - \hat{x}_q \ln \bm{B} \numberthis
\end{align*}
Where we have simply explicitly written out the variational free energy in terms of the parameters of the categorical distributions. The expectation operator $\E[]$ can be computed as a simple dot product instead of an integral due to the discrete state space. Importantly, because both our variational density and generative models are categorical distributions, we can derive an analytical expression for the minimum of $\mathcal{F}$ with respect to the variational parameters $\hat{x}_q$, allowing for an exact Bayes-optimal single-step update for perception,
\begin{align*}
\frac{\partial \mathcal{F}}{\partial \hat{x}_q} &= \frac{\partial}{\partial \hat{x}_q}[\hat{x}_q \ln \hat{x}_q - \hat{x}_q \ln \bm{A} - \hat{x}_q \ln \bm{B}]\\
&= \ln \hat{x}_q + \bm{1} - \ln \bm{A} - \ln \bm{B} \\
& \frac{\partial \mathcal{F}}{\partial \hat{x}_q} = 0 \implies \hat{x}_q^* = \sigma(-\ln \bm{A} - \ln \bm{B}) \numberthis
\end{align*}

Learning can be approached similarly, by placing suitable hyperpriors (typically dirichlet \citep{schwartenbeck_computational_2019}) upon the parameters of the $\bm{A}$ and $\bm{B}$ matrices and then minimizing the VFE with respect to these parameters. For more information on how learning is implemented see \citet{da2020active,friston2017process}.


\subsection{Action Selection and the Expected Free Energy}

%\begin{figure}
%  \centering
%  \includegraphics[scale=1]{chapter_2_figures/EFE_\munspirations.jpg}
%  \caption{Active Inference and Free Energy Minimization. Top: We see that discrete state space active inference requires two separate minimizations -- one of variational free energy for perception, and one of expected free energy for action selection. Bottom: We see that the EFE functional can be decomposed in various ways to yield a variety of influential objectives which have previously been proposed in the literature. Figure originally in \citet{da2020active}}
%  \label{fig:my_label}
%\end{figure}

Action selection is then handled via the variational posterior being equal to the softmaxed path integral of the EFE through time (Equation \ref{EFE_softmax}). Typically, in small discrete state spaces, this path integral can be computed exactly, by simply computing the EFE for every single policy and every single possible trajectory through the state-space. Unfortunately, this approach scales exponentially in the time horizon, and is thus not suitable for long, open-ended tasks, although it remains a highly effective method for simulating short tasks, such as single trials in a psychophysical, or simple decision-making, paradigm \citep{friston_active_2015,schwartenbeck2015optimal,friston2020sophisticated}. Various methods have been proposed to handle this exponential complexity. One commonly proposed method is to simply prune potential trajectories which become too unlikely (i.e. have too low an EFE) to be worth considering further. Typically, such methods, however, do not reduce the algorithm to a smaller (polynomial) complexity class, but instead simply reduce the exponential coefficient which allows the method to scale to slightly larger tasks but does not remove the fundamental exponential complexity of the algorithm. Other approaches involve approximating the path integral with either bootstrapping value-function methods \citep{millidge_deep_2019}, which take advantage of the recursive temporal decomposition of the EFE, or alternatively Monte-Carlo techniques which approximate the EFE through a random sampling of trajectories, which corresponds to classical model-predictive control algorithms \citep{kappen2012optimal}. An additional consideration in the EFE is the need to specify a desired or goal state for the action selection mechanism to achieve. This can be considered to be a probabilistic description of rewards in reinforcement learning and psychology, or of utility in economics. Mathematically, this specification is achieved by defining a \emph{biased} generative model $\tilde{p}(o,x)$ which contains a desired distribution $\tilde{p}$ which encodes the rewards or utility as effectively priors in the inference procedure.

Since action selection is dependent entirely on the path-integral of the EFE, the properties of the EFE functional essentially determines the kind of behaviour that finding trajectories that minimize the EFE will induce. Here, we showcase two decompositions of the EFE, and discuss its intrinsic exploratory drive.

\begin{align*}
\mathcal{G}(o,x) &= \E_{q(o,x)}[\ln q(x) - \ln \tilde{p}(o,x)] \\
&= \underbrace{\E_{q(o,x)}[\ln p(o|x)]}_{\text{Ambiguity}} + \underbrace{\KL[q(x) || \tilde{p}(x)]}_{\text{Risk}} \\
&= \underbrace{\E_{q(o,x)}[\ln \tilde{p}(o)]}_{\text{Extrinsic Value}} -\underbrace{\E_{q(o)}\KL[q(x | o) || q(x)]}_{\text{Information Gain}} + \underbrace{\E_{q(o)}\KL[q(x |o) || p(x|o)]}_{\text{Posterior Divergence}} \numberthis
\end{align*}
The first decomposition into \emph{risk} and \emph{ambiguity} obtains when the goal distribution is specified in terms of the hidden states of the world $\tilde{p}(x)$. In this case, EFE minimization can be thought of as directly trying to match the expected states of the world to the desired states, and thus achieving one's goals, while simultaneously trying to minimize the \emph{ambiguity} of the observations one receives. The second decomposition into \emph{extrinsic} and \emph{intrinsic} value (information gain) occurs when the goal distribution is specified in terms of the observations $\tilde{p}(o)$. The extrinsic value term can be thought of as the expected reward or expected utility, since it is the average amount of reward expected under the predicted observation distribution. Most interestingly in this decomposition, however, is the information gain term which encourages the agent to maximize the divergence between the variational prior and the variational posterior. Effectively this term encourages the agent to seek out information in the environment which will maximally update its beliefs about the world. In effect, this term encourages a specific kind of information-seeking exploration, where agents that minimize the EFE are effectively driven to seek out and integrate resolvable uncertainty about the world into their world model.

This intriguing property of active inference agents which minimize the EFE has been extensively investigated in the literature -- from simple tasks such as the T-maze which require deciding whether to gain information by seeking out a cue or not \citep{friston2015active}, to planning visual saccades in a way which maximizes the information about the scene gained \citep{parr2017uncertainty,heins2020deep} and to using directed exploration to develop highly sample efficient and powerful general reinforcement learning algorithms for sparse-reward environments \citep{millidge2019deep}. Moreover, the fact that the EFE naturally gives rise to an information-seeking exploration term offers a promising and fascinating avenue for resolving the exploration-exploitation tradeoff and deriving optimal exploration strategies directly from variational Bayesian inference algorithms.

\section{Discussion}

In this chapter, we have already covered a substantial amount of ground. We have reviewed the core tenets of the free energy principle, provided a mathematically detailed walk-through of the core results, and discussed their philosophical implications and meaning. We have additionally provided a short review of a core process theory -- discrete state space active inference -- which we will fundamentally build upon in various ways in the rest of this thesis. Chapter 3 will focus on applying the free energy principle to perception -- and will focus on the implementation and extension of the process theory of predictive coding. Chapter 4 will focus on merging active inference as presented here with modern deep reinforcement learning methods to allow active inference approaches, which are currently bottlenecked due to their discrete explicit tabular representations and the exponential complexity of the action selection algorithm, to be extended to challenging machine learning problems. Chapter 5 will focus especially on the Expected Free Energy term and will seek to unravel the origin of its information seeking properties and in the process will reveal deep connections between active inference and other variational Bayesian approaches to action such as control as inference, as well as revealing a substantially richer landscape of potential variational functionals for control than has been previously realized.