@article{millidge2020deep,
  title={Deep active inference as variational policy gradients},
  author={Millidge, Beren},
  journal={Journal of Mathematical Psychology},
  volume={96},
  pages={102348},
  year={2020},
  publisher={Elsevier},
  keywords={deep},
  url={https://www.sciencedirect.com/science/article/pii/S0022249620300298?casa_token=GQLxvJzk3zMAAAAA:uotM5EqPWP9SIUV-5N8vvNnkVWSqFlS8W03MZ_W9GYCoyhWGRAhN9YmGjiTIaxCGHd4iwrjzElg}
}
@article{da2020relationship,
  title={The relationship between dynamic programming and active inference: The discrete, finite-horizon case},
  author={Da Costa, Lancelot and Sajid, Noor and Parr, Thomas and Friston, Karl and Smith, Ryan},
  journal={arXiv preprint arXiv:2009.08111},
  year={2020}
}
@inproceedings{hesp2020sophisticated,
  title={Sophisticated Affective Inference: Simulating Anticipatory Affective Dynamics of Imagining Future Events},
  author={Hesp, Casper and Tschantz, Alexander and Millidge, Beren and Ramstead, Maxwell and Friston, Karl and Smith, Ryan},
  booktitle={International Workshop on Active Inference},
  pages={179--186},
  year={2020},
  organization={Springer}
}
@article{millidge2020reinforcement,
  title={Reinforcement Learning as Iterative and Amortised Inference},
  author={Millidge, Beren and Tschantz, Alexander and Seth, Anil K and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2006.10524},
  year={2020}
}
@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}
@article{such2017deep,
  title={Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning},
  author={Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1712.06567},
  year={2017}
}

@article{millidge2020whence,
  title={Whence the Expected Free Energy?},
  author={Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2004.08128},
  year={2020}
}

@article{wolpert1997computational,
  title={Computational approaches to motor control},
  author={Wolpert, Daniel M},
  journal={Trends in cognitive sciences},
  volume={1},
  number={6},
  pages={209--216},
  year={1997},
  publisher={Elsevier}
}

@book{kirk2004optimal,
  title={Optimal control theory: an introduction},
  author={Kirk, Donald E},
  year={2004},
  publisher={Courier Corporation}
}

@book{kwakernaak1972linear,
  title={Linear optimal control systems},
  author={Kwakernaak, Huibert and Sivan, Raphael},
  volume={1},
  year={1972},
  publisher={Wiley-interscience New York}
}

@inproceedings{feng2014optimization,
  title={Optimization based full body control for the atlas robot},
  author={Feng, Siyuan and Whitman, Eric and Xinjilefu, X and Atkeson, Christopher G},
  booktitle={2014 IEEE-RAS International Conference on Humanoid Robots},
  pages={120--127},
  year={2014},
  organization={IEEE}
}

@incollection{kopp1962pontryagin,
  title={Pontryagin maximum principle},
  author={Kopp, Richard E},
  booktitle={Mathematics in Science and Engineering},
  volume={5},
  pages={255--279},
  year={1962},
  publisher={Elsevier}
}

@article{bellman1952theory,
  title={On the theory of dynamic programming},
  author={Bellman, Richard},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  volume={38},
  number={8},
  pages={716},
  year={1952},
  publisher={National Academy of Sciences}
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007}
}

@article{kaiser2020synaptic,
  title={Synaptic plasticity dynamics for deep continuous local learning (DECOLLE)},
  author={Kaiser, Jacques and Mostafa, Hesham and Neftci, Emre},
  journal={Frontiers in Neuroscience},
  volume={14},
  pages={424},
  year={2020},
  publisher={Frontiers}
}

@article{neftci2019surrogate,
  title={Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks},
  author={Neftci, Emre O and Mostafa, Hesham and Zenke, Friedemann},
  journal={IEEE Signal Processing Magazine},
  volume={36},
  number={6},
  pages={51--63},
  year={2019},
  publisher={IEEE}
}

@book{fodor1983modularity,
  title={The modularity of mind},
  author={Fodor, Jerry A},
  year={1983},
  publisher={MIT press}
}

@book{pinker2003language,
  title={The language instinct: How the mind creates language},
  author={Pinker, Steven},
  year={2003},
  publisher={Penguin UK}
}

@book{bostrom2017superintelligence,
  title={Superintelligence},
  author={Bostrom, Nick},
  year={2017},
  publisher={Dunod}
}
@article{seifert2008stochastic,
  title={Stochastic thermodynamics: principles and perspectives},
  author={Seifert, Udo},
  journal={The European Physical Journal B},
  volume={64},
  number={3},
  pages={423--431},
  year={2008},
  publisher={Springer}
}
@article{seifert2012stochastic,
  title={Stochastic thermodynamics, fluctuation theorems and molecular machines},
  author={Seifert, Udo},
  journal={Reports on progress in physics},
  volume={75},
  number={12},
  pages={126001},
  year={2012},
  publisher={IOP Publishing}
}
@article{esposito2010three1,
  title={Three faces of the second law. I. Master equation formulation},
  author={Esposito, Massimiliano and Van den Broeck, Christian},
  journal={Physical Review E},
  volume={82},
  number={1},
  pages={011143},
  year={2010},
  publisher={APS}
}
@article{van2010three2,
  title={Three faces of the second law. II. Fokker-Planck formulation},
  author={Van den Broeck, Christian and Esposito, Massimiliano},
  journal={Physical Review E},
  volume={82},
  number={1},
  pages={011144},
  year={2010},
  publisher={APS}
}
@inproceedings{caticha2015basics,
  title={The basics of information geometry},
  author={Caticha, Ariel},
  booktitle={AIP Conference Proceedings},
  volume={1641},
  number={1},
  pages={15--26},
  year={2015},
  organization={American Institute of Physics}
}
@article{biehl2020technical,
  title={A technical critique of the free energy principle as presented in" Life as we know it" and related works},
  author={Biehl, Martin and Pollock, Felix A and Kanai, Ryota},
  journal={arXiv preprint arXiv:2001.06408},
  year={2020}
}
@article{friston2020some,
  title={Some interesting observations on the free energy principle},
  author={Friston, Karl and Da Costa, Lancelot and Parr, Thomas},
  journal={arXiv preprint arXiv:2002.04501},
  year={2020}
}
@article{pearl2011bayesian,
  title={Bayesian networks},
  author={Pearl, Judea},
  year={2011}
}
@book{kondepudi2014modern,
  title={Modern thermodynamics: from heat engines to dissipative structures},
  author={Kondepudi, Dilip and Prigogine, Ilya},
  year={2014},
  publisher={John Wiley \& Sons}
}
@incollection{prigogine1973theory,
  title={Theory of dissipative structures},
  author={Prigogine, Ilya and Lefever, Ren{\'e}},
  booktitle={Synergetics},
  pages={124--135},
  year={1973},
  publisher={Springer}
}
@book{zwanzig2001nonequilibrium,
  title={Nonequilibrium statistical mechanics},
  author={Zwanzig, Robert},
  year={2001},
  publisher={Oxford University Press}
}
@book{prigogine2017non,
  title={Non-equilibrium statistical mechanics},
  author={Prigogine, Ilya},
  year={2017},
  publisher={Courier Dover Publications}
}
@article{ollivier2017information,
  title={Information-geometric optimization algorithms: A unifying picture via invariance principles},
  author={Ollivier, Yann and Arnold, Ludovic and Auger, Anne and Hansen, Nikolaus},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={18},
  pages={1--65},
  year={2017}
}
@book{lanczos2012variational,
  title={The variational principles of mechanics},
  author={Lanczos, Cornelius},
  year={2012},
  publisher={Courier Corporation}
}
@book{sussman2015structure,
  title={Structure and interpretation of classical mechanics},
  author={Sussman, Gerald Jay and Wisdom, Jack},
  year={2015},
  publisher={The MIT Press}
}
@article{betancourt2017conceptual,
  title={A conceptual introduction to Hamiltonian Monte Carlo},
  author={Betancourt, Michael},
  journal={arXiv preprint arXiv:1701.02434},
  year={2017}
}
@inproceedings{chen2014stochastic,
  title={Stochastic gradient hamiltonian monte carlo},
  author={Chen, Tianqi and Fox, Emily and Guestrin, Carlos},
  booktitle={International conference on machine learning},
  pages={1683--1691},
  year={2014},
  organization={PMLR}
}
@book{brooks2011handbook,
  title={Handbook of markov chain monte carlo},
  author={Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year={2011},
  publisher={CRC press}
}
@article{ma2015complete,
  title={A complete recipe for stochastic gradient MCMC},
  author={Ma, Yi-An and Chen, Tianqi and Fox, Emily B},
  journal={arXiv preprint arXiv:1506.04696},
  year={2015}
}
@article{betancourt2013generalizing,
  title={Generalizing the no-U-turn sampler to Riemannian manifolds},
  author={Betancourt, Michael J},
  journal={arXiv preprint arXiv:1304.1920},
  year={2013}
}
@article{girolami2011riemann,
  title={Riemann manifold langevin and hamiltonian monte carlo methods},
  author={Girolami, Mark and Calderhead, Ben},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={73},
  number={2},
  pages={123--214},
  year={2011},
  publisher={Wiley Online Library}
}
@article{friston2018bayesian,
  title={Bayesian model reduction},
  author={Friston, Karl and Parr, Thomas and Zeidman, Peter},
  journal={arXiv preprint arXiv:1805.07092},
  year={2018}
}
@article{geweke2007bayesian,
  title={Bayesian model comparison and validation},
  author={Geweke, John},
  journal={American Economic Review},
  volume={97},
  number={2},
  pages={60--64},
  year={2007}
}
@article{hohwy2016self,
  title={The self-evidencing brain},
  author={Hohwy, Jakob},
  journal={No{\^u}s},
  volume={50},
  number={2},
  pages={259--285},
  year={2016},
  publisher={Wiley Online Library}
}
@article{yuan2012beyond,
  title={Beyond it{\^o} versus stratonovich},
  author={Yuan, Ruoshi and Ao, Ping},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2012},
  number={07},
  pages={P07010},
  year={2012},
  publisher={IOP Publishing}
}
@book{jazwinski2007stochastic,
  title={Stochastic processes and filtering theory},
  author={Jazwinski, Andrew H},
  year={2007},
  publisher={Courier Corporation}
}
@inproceedings{yuan2011potential,
  title={Potential function in dynamical systems and the relation with Lyapunov function},
  author={Yuan, Ruoshi and Ma, Yian and Yuan, Bo and Ao, Ping},
  booktitle={Proceedings of the 30th Chinese Control Conference},
  pages={6573--6580},
  year={2011},
  organization={IEEE}
}
@article{yuan2010constructive,
  title={Constructive proof of global lyapunov function as potential function},
  author={Yuan, Ruoshi and Ma, Yian and Yuan, Bo and Ao, Ping},
  journal={arXiv preprint arXiv:1012.2721},
  year={2010}
}
@article{yuan2017sde,
  title={SDE decomposition and A-type stochastic interpretation in nonequilibrium processes},
  author={Yuan, Ruoshi and Tang, Ying and Ao, Ping},
  journal={Frontiers of Physics},
  volume={12},
  number={6},
  pages={1--9},
  year={2017},
  publisher={Springer}
}
@article{bruineberg2020emperor,
  title={The Emperor’s New Markov Blankets},
  author={Bruineberg, Jelle and Dolega, Krzysztof and Dewhurst, Joe and Baltieri, Manuel},
  year={2020}
}


@article{bengio2020deriving,
  title={Deriving differential target propagation from iterating approximate inverses},
  author={Bengio, Yoshua},
  journal={arXiv preprint arXiv:2007.15139},
  year={2020}
}

@article{seung2003learning,
  title={Learning in spiking neural networks by reinforcement of stochastic synaptic transmission},
  author={Seung, H Sebastian},
  journal={Neuron},
  volume={40},
  number={6},
  pages={1063--1073},
  year={2003},
  publisher={Elsevier}
}

@article{roelfsema2005attention,
  title={Attention-gated reinforcement learning of internal representations for classification},
  author={Roelfsema, Pieter R and Ooyen, Arjen van},
  journal={Neural computation},
  volume={17},
  number={10},
  pages={2176--2214},
  year={2005},
  publisher={MIT Press}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{hinton2012neural,
  title={Neural networks for machine learning lecture 6a overview of mini-batch gradient descent},
  author={Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
  journal={Cited on},
  volume={14},
  number={8},
  year={2012}
}

@inproceedings{nesterov27method,
  title={A method of solving a convex programming problem with convergence rate O (1/k\^{} 2) O (1/k2)},
  author={Nesterov, Yu},
  booktitle={Sov. Math. Dokl},
  volume={27},
  number={2},
  year={1983}
}

@article{neal2011mcmc,
  title={MCMC using Hamiltonian dynamics},
  author={Neal, Radford M and others},
  journal={Handbook of markov chain monte carlo},
  volume={2},
  number={11},
  pages={2},
  year={2011}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011},
  organization={Citeseer}
}

@article{aitchison2017or,
  title={With or without you: predictive coding and Bayesian inference in the brain},
  author={Aitchison, Laurence and Lengyel, M{\'a}t{\'e}},
  journal={Current opinion in neurobiology},
  volume={46},
  pages={219--227},
  year={2017},
  publisher={Elsevier}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@inproceedings{gupta2015deep,
  title={Deep learning with limited numerical precision},
  author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  booktitle={International conference on machine learning},
  pages={1737--1746},
  year={2015},
  organization={PMLR}
}

@article{friston2008variational,
  title={Variational filtering},
  author={Friston, Karl J},
  journal={NeuroImage},
  volume={41},
  number={3},
  pages={747--766},
  year={2008},
  publisher={Elsevier}
}

@article{knill2004bayesian,
  title={The Bayesian brain: the role of uncertainty in neural coding and computation},
  author={Knill, David C and Pouget, Alexandre},
  journal={TRENDS in Neurosciences},
  volume={27},
  number={12},
  pages={712--719},
  year={2004},
  publisher={Elsevier}
}

@book{doya2007bayesian,
  title={Bayesian brain: Probabilistic approaches to neural coding},
  author={Doya, Kenji and Ishii, Shin and Pouget, Alexandre and Rao, Rajesh PN},
  year={2007},
  publisher={MIT press}
}

@article{pouget2013probabilistic,
  title={Probabilistic brains: knowns and unknowns},
  author={Pouget, Alexandre and Beck, Jeffrey M and Ma, Wei Ji and Latham, Peter E},
  journal={Nature neuroscience},
  volume={16},
  number={9},
  pages={1170},
  year={2013},
  publisher={Nature Publishing Group}
}

@article{kording2004bayesian,
  title={Bayesian integration in sensorimotor learning},
  author={K{\"o}rding, Konrad P and Wolpert, Daniel M},
  journal={Nature},
  volume={427},
  number={6971},
  pages={244},
  year={2004},
  publisher={Nature Publishing Group}
}

@article{kersten2004object,
  title={Object perception as Bayesian inference},
  author={Kersten, Daniel and Mamassian, Pascal and Yuille, Alan},
  journal={Annu. Rev. Psychol.},
  volume={55},
  pages={271--304},
  year={2004},
  publisher={Annual Reviews}
}

@article{tenenbaum2006theory,
  title={Theory-based Bayesian models of inductive learning and reasoning},
  author={Tenenbaum, Joshua B and Griffiths, Thomas L and Kemp, Charles},
  journal={Trends in cognitive sciences},
  volume={10},
  number={7},
  pages={309--318},
  year={2006},
  publisher={Elsevier}
}

@article{angelaki2009multisensory,
  title={Multisensory integration: psychophysics, neurophysiology, and computation},
  author={Angelaki, Dora E and Gu, Yong and DeAngelis, Gregory C},
  journal={Current opinion in neurobiology},
  volume={19},
  number={4},
  pages={452--458},
  year={2009},
  publisher={Elsevier}
}

@article{ernst2002humans,
  title={Humans integrate visual and haptic information in a statistically optimal fashion},
  author={Ernst, Marc O and Banks, Martin S},
  journal={Nature},
  volume={415},
  number={6870},
  pages={429},
  year={2002},
  publisher={Nature Publishing Group}
}

@article{sanborn2016bayesian,
  title={Bayesian brains without probabilities},
  author={Sanborn, Adam N and Chater, Nick},
  journal={Trends in cognitive sciences},
  volume={20},
  number={12},
  pages={883--893},
  year={2016},
  publisher={Elsevier}
}

@article{ma2006bayesian,
  title={Bayesian inference with probabilistic population codes},
  author={Ma, Wei Ji and Beck, Jeffrey M and Latham, Peter E and Pouget, Alexandre},
  journal={Nature neuroscience},
  volume={9},
  number={11},
  pages={1432},
  year={2006},
  publisher={Nature Publishing Group}
}

@article{ma2008spiking,
  title={Spiking networks for Bayesian inference and choice},
  author={Ma, Wei Ji and Beck, Jeffrey M and Pouget, Alexandre},
  journal={Current opinion in neurobiology},
  volume={18},
  number={2},
  pages={217--222},
  year={2008},
  publisher={Elsevier}
}
@article{ovchinnikov2016introduction,
  title={Introduction to supersymmetric theory of stochastics},
  author={Ovchinnikov, Igor V},
  journal={Entropy},
  volume={18},
  number={4},
  pages={108},
  year={2016},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}
@article{osband2015bootstrapped,
  title={Bootstrapped thompson sampling and deep exploration},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1507.00300},
  year={2015}
}
@article{osband2019deep,
  title={Deep Exploration via Randomized Value Functions.},
  author={Osband, Ian and Van Roy, Benjamin and Russo, Daniel J and Wen, Zheng},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={124},
  pages={1--62},
  year={2019}
}
@incollection{tishby2011information,
  title={Information theory of decisions and actions},
  author={Tishby, Naftali and Polani, Daniel},
  booktitle={Perception-action cycle},
  pages={601--636},
  year={2011},
  publisher={Springer}
}
@inproceedings{garivier2011upper,
  title={On upper-confidence bound policies for switching bandit problems},
  author={Garivier, Aur{\'e}lien and Moulines, Eric},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={174--188},
  year={2011},
  organization={Springer}
}
@inproceedings{kocsis2006bandit,
  title={Bandit based monte-carlo planning},
  author={Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle={European conference on machine learning},
  pages={282--293},
  year={2006},
  organization={Springer}
}
@article{bastos2020layer,
  title={Layer and rhythm specificity for predictive routing},
  author={Bastos, Andr{\'e} M and Lundqvist, Mikael and Waite, Ayan S and Kopell, Nancy and Miller, Earl K},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={49},
  pages={31459--31469},
  year={2020},
  publisher={National Acad Sciences}
}
@article{bastos2015visual,
  title={Visual areas exert feedforward and feedback influences through distinct frequency channels},
  author={Bastos, Andre Moraes and Vezoli, Julien and Bosman, Conrado Arturo and Schoffelen, Jan-Mathijs and Oostenveld, Robert and Dowdall, Jarrod Robert and De Weerd, Peter and Kennedy, Henry and Fries, Pascal},
  journal={Neuron},
  volume={85},
  number={2},
  pages={390--401},
  year={2015},
  publisher={Elsevier}
}
@article{pozzi2018biologically,
  title={A biologically plausible learning rule for deep learning in the brain},
  author={Pozzi, Isabella and Boht{\'e}, Sander and Roelfsema, Pieter},
  journal={arXiv preprint arXiv:1811.01768},
  year={2018}
}
@article{schultz1998reward,
  title={Reward prediction in primate basal ganglia and frontal cortex},
  author={Schultz, Wolfram and Tremblay, L{\'e}on and Hollerman, Jeffrey R},
  journal={Neuropharmacology},
  volume={37},
  number={4-5},
  pages={421--429},
  year={1998},
  publisher={Elsevier}
}
@article{russo2016information,
  title={An information-theoretic analysis of thompson sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2442--2471},
  year={2016},
  publisher={JMLR. org}
}

@misc{jaswinskistochastic,
  title={Stochastic Processes and Filtering Theory, 1970},
  author={Jaswinski, AH},
  publisher={Academic Press},
  year={1970},
}

@book{stengel1994optimal,
  title={Optimal control and estimation},
  author={Stengel, Robert F},
  year={1994},
  publisher={Courier Corporation}
}

@article{grewal2010applications,
  title={Applications of Kalman filtering in aerospace 1960 to the present [historical perspectives]},
  author={Grewal, Mohinder S and Andrews, Angus P},
  journal={IEEE Control Systems Magazine},
  volume={30},
  number={3},
  pages={69--78},
  year={2010},
  publisher={IEEE}
}

@techreport{leondes1970theory,
  title={Theory and applications of Kalman filtering},
  author={Leondes, Cornelius T},
  year={1970},
  institution={ADVISORY GROUP FOR AEROSPACE RESEARCH AND DEVELOPMENT NEUILLY-SUR-SEINE (FRANCE)}
}

@article{schneider1988analytical,
  title={Analytical uses of Kalman filtering in econometrics—A survey},
  author={Schneider, Wolfgang},
  journal={Statistical Papers},
  volume={29},
  number={1},
  pages={3--33},
  year={1988},
  publisher={Springer}
}

@book{harvey1990forecasting,
  title={Forecasting, structural time series models and the Kalman filter},
  author={Harvey, Andrew C},
  year={1990},
  publisher={Cambridge university press}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, Rudolph Emil},
  year={1960}
}

@article{kalman1961new,
  title={New results in linear filtering and prediction theory},
  author={Kalman, Rudolph E and Bucy, Richard S},
  journal={Journal of basic engineering},
  volume={83},
  number={1},
  pages={95--108},
  year={1961},
  publisher={American Society of Mechanical Engineers}
}

@article{friston2005theory,
  title={A theory of cortical responses},
  author={Friston, Karl},
  journal={Philosophical transactions of the Royal Society B: Biological sciences},
  volume={360},
  number={1456},
  pages={815--836},
  year={2005},
  publisher={The Royal Society London}
}
@article{friston2020sentience,
  title={Sentience and the origins of consciousness: From Cartesian duality to Markovian monism},
  author={Friston, Karl J and Wiese, Wanja and Hobson, J Allan},
  journal={Entropy},
  volume={22},
  number={5},
  pages={516},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{rao1999predictive,
  title={Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
  author={Rao, Rajesh PN and Ballard, Dana H},
  journal={Nature neuroscience},
  volume={2},
  number={1},
  pages={79--87},
  year={1999},
  publisher={Nature Publishing Group}
}

@article{spratling2017review,
  title={A review of predictive coding algorithms},
  author={Spratling, Michael W},
  journal={Brain and cognition},
  volume={112},
  pages={92--97},
  year={2017},
  publisher={Elsevier},
  keywords={survey},
  url={https://www.sciencedirect.com/science/article/pii/S027826261530035X?casa_token=zzTchZsrFesAAAAA:5bJNguAnRfn4BOjlCtmGvjiQT0Mkk3CE1By9JsrGrDIT0qY-CUKLUwVROkHB9S_kUx6mtH-nc74}
}

@article{spratling2008reconciling,
  title={Reconciling predictive coding and biased competition models of cortical function},
  author={Spratling, Michael W},
  journal={Frontiers in computational neuroscience},
  volume={2},
  pages={4},
  year={2008},
  publisher={Frontiers}
}

@inproceedings{wilson2009neural,
  title={A neural implementation of the Kalman filter},
  author={Wilson, Robert and Finkel, Leif},
  booktitle={Advances in neural information processing systems},
  pages={2062--2070},
  year={2009}
}

@article{bastos2012canonical,
  title={Canonical microcircuits for predictive coding},
  author={Bastos, Andre M and Usrey, W Martin and Adams, Rick A and Mangun, George R and Fries, Pascal and Friston, Karl J},
  journal={Neuron},
  volume={76},
  number={4},
  pages={695--711},
  year={2012},
  publisher={Elsevier}
}

@article{deneve2007optimal,
  title={Optimal sensorimotor integration in recurrent cortical networks: a neural implementation of Kalman filters},
  author={Deneve, Sophie and Duhamel, Jean-Ren{\'e} and Pouget, Alexandre},
  journal={Journal of Neuroscience},
  volume={27},
  number={21},
  pages={5744--5756},
  year={2007},
  publisher={Soc Neuroscience}
}

@article{pouget2000information,
  title={Information processing with population codes},
  author={Pouget, Alexandre and Dayan, Peter and Zemel, Richard},
  journal={Nature Reviews Neuroscience},
  volume={1},
  number={2},
  pages={125},
  year={2000},
  publisher={Nature Publishing Group}
}

@article{beck2007probabilistic,
  title={Probabilistic population codes and the exponential family of distributions},
  author={Beck, J and Ma, WJ and Latham, PE and Pouget, A},
  journal={Progress in brain research},
  volume={165},
  pages={509--519},
  year={2007},
  publisher={Elsevier}
}

@article{de2013kalman,
  title={Kalman filtering naturally accounts for visually guided and predictive smooth pursuit dynamics},
  author={de Xivry, Jean-Jacques Orban and Coppe, S{\'e}bastien and Blohm, Gunnar and Lefevre, Philippe},
  journal={Journal of Neuroscience},
  volume={33},
  number={44},
  pages={17301--17313},
  year={2013},
  publisher={Soc Neuroscience}
}

@article{munuera2009optimal,
  title={Optimal sensorimotor control in eye movement sequences},
  author={Munuera, J{\'e}r{\^o}me and Morel, Pierre and Duhamel, Jean-Ren{\'e} and Deneve, Sophie},
  journal={Journal of Neuroscience},
  volume={29},
  number={10},
  pages={3026--3035},
  year={2009},
  publisher={Soc Neuroscience}
}

@article{gold2003influence,
  title={The influence of behavioral context on the representation of a perceptual decision in developing oculomotor commands},
  author={Gold, Joshua I and Shadlen, Michael N},
  journal={Journal of Neuroscience},
  volume={23},
  number={2},
  pages={632--651},
  year={2003},
  publisher={Soc Neuroscience}
}

@article{todorov2004optimality,
  title={Optimality principles in sensorimotor control},
  author={Todorov, Emanuel},
  journal={Nature neuroscience},
  volume={7},
  number={9},
  pages={907},
  year={2004},
  publisher={Nature Publishing Group}
}

@article{zago2008internal,
  title={Internal models and prediction of visual gravitational motion},
  author={Zago, Myrka and McIntyre, Joseph and Senot, Patrice and Lacquaniti, Francesco},
  journal={Vision research},
  volume={48},
  number={14},
  pages={1532--1538},
  year={2008},
  publisher={Elsevier}
}

@article{simoncelli2009optimal,
  title={Optimal estimation in sensory systems},
  author={Simoncelli, Eero P},
  journal={The Cognitive Neurosciences, IV},
  pages={525--535},
  year={2009},
  publisher={MIT Press}
}

@phdthesis{kutschireiter2018nonlinear,
  title={Nonlinear filtering in neuroscience: theory and application},
  author={Kutschireiter, Anna},
  year={2018},
  school={University of Zurich}
}

@article{arulampalam2002tutorial,
  title={A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking},
  author={Arulampalam, M Sanjeev and Maskell, Simon and Gordon, Neil and Clapp, Tim},
  journal={IEEE Transactions on signal processing},
  volume={50},
  number={2},
  pages={174--188},
  year={2002},
  publisher={Ieee}
}

@inproceedings{gordon1993novel,
  title={Novel approach to nonlinear/non-Gaussian Bayesian state estimation},
  author={Gordon, Neil J and Salmond, David J and Smith, Adrian FM},
  booktitle={IEE proceedings F (radar and signal processing)},
  volume={140},
  number={2},
  pages={107--113},
  year={1993},
  organization={IET}
}

@article{doucet2000sequential,
  title={On sequential Monte Carlo sampling methods for Bayesian filtering},
  author={Doucet, Arnaud and Godsill, Simon and Andrieu, Christophe},
  journal={Statistics and computing},
  volume={10},
  number={3},
  pages={197--208},
  year={2000},
  publisher={Springer}
}

@article{kutschireiter2015neural,
  title={The neural particle filter},
  author={Kutschireiter, Anna and Surace, Simone Carlo and Sprekeler, Henning and Pfister, Jean-Pascal},
  journal={arXiv preprint arXiv:1508.06818},
  year={2015}
}

@article{friston2008hierarchical,
  title={Hierarchical models in the brain},
  author={Friston, Karl},
  journal={PLoS computational biology},
  volume={4},
  number={11},
  year={2008},
  publisher={Public Library of Science}
}

@article{baltieri2020kalman,
  title={On Kalman-Bucy filters, linear quadratic control and active inference},
  author={Baltieri, Manuel and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2005.06269},
  year={2020},
  keywords={continuous},
  url={https://arxiv.org/abs/2005.06269}
}

@inproceedings{wan2000unscented,
  title={The unscented Kalman filter for nonlinear estimation},
  author={Wan, Eric A and Van Der Merwe, Rudolph},
  booktitle={Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and Control Symposium (Cat. No. 00EX373)},
  pages={153--158},
  year={2000},
  organization={Ieee}
}

@article{ribeiro2004kalman,
  title={Kalman and extended kalman filters: Concept, derivation and properties},
  author={Ribeiro, Maria Isabel},
  journal={Institute for Systems and Robotics},
  volume={43},
  pages={46},
  year={2004},
  publisher={Citeseer}
}

@article{millidge2020relaxing,
  title={Relaxing the constraints on predictive coding models},
  author={Millidge, Beren and Tschantz, Alexander and Seth, Anil and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2010.01047},
  year={2020}
}

@article{tschantz2020control,
  title={Control as hybrid inference},
  author={Tschantz, Alexander and Millidge, Beren and Seth, Anil K and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2007.05838},
  year={2020}
}

@article{de2005tutorial,
  title={A tutorial on the cross-entropy method},
  author={De Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
  journal={Annals of operations research},
  volume={134},
  number={1},
  pages={19--67},
  year={2005},
  publisher={Springer}
}

@article{tesauro1994td,
  title={TD-Gammon, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@book{sethi2000optimal,
  title={What is optimal control theory?},
  author={Sethi, Suresh P and Thompson, Gerald L},
  year={2000},
  publisher={Springer}
}

@article{kalman1960contributions,
  title={Contributions to the theory of optimal control},
  author={Kalman, Rudolf Emil and others},
  journal={Bol. soc. mat. mexicana},
  volume={5},
  number={2},
  pages={102--119},
  year={1960},
  publisher={Citeseer}
}

@article{tschantz2020reinforcement,
  title={Reinforcement Learning through Active Inference},
  author={Tschantz, Alexander and Millidge, Beren and Seth, Anil K and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2002.12636},
  year={2020}
}

@article{millidge2019combining,
  title={Combining active inference and hierarchical predictive coding: A tutorial introduction and case study},
  author={Millidge, Beren},
  year={2019},
  publisher={PsyArXiv}
}

@article{tschantz2019scaling,
  title={Scaling active inference},
  author={Tschantz, Alexander and Baltieri, Manuel and Seth, Anil and Buckley, Christopher L and others},
  journal={arXiv preprint arXiv:1911.10601},
  year={2019}
}

@article{tschantz2020learning,
  title={Learning action-oriented models through active inference},
  author={Tschantz, Alexander and Seth, Anil K and Buckley, Christopher L},
  journal={PLoS computational biology},
  volume={16},
  number={4},
  pages={e1007805},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{ueltzhoffer2018deep,
  title={Deep active inference},
  author={Ueltzh{\"o}ffer, Kai},
  journal={Biological cybernetics},
  volume={112},
  number={6},
  pages={547--573},
  year={2018},
  publisher={Springer}
}

@article{fountas2020deep,
  title={Deep active inference agents using Monte-Carlo methods},
  author={Fountas, Zafeirios and Sajid, Noor and Mediano, Pedro AM and Friston, Karl},
  journal={arXiv preprint arXiv:2006.04176},
  year={2020}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{toussaint2009robot,
  title={Robot trajectory optimization using approximate inference},
  author={Toussaint, Marc},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={1049--1056},
  year={2009}
}

@inproceedings{attias2003planning,
  title={Planning by Probabilistic Inference.},
  author={Attias, Hagai},
  booktitle={AISTATS},
  year={2003},
  organization={Citeseer}
}

@inproceedings{rawlik2013stochastic,
  title={On stochastic optimal control and reinforcement learning by approximate inference},
  author={Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
  booktitle={Twenty-Third International Joint Conference on Artificial Intelligence},
  year={2013}
}

@article{rawlik2010approximate,
  title={Approximate inference and stochastic optimal control},
  author={Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
  journal={arXiv preprint arXiv:1009.3958},
  year={2010}
}

@article{rawlik2013probabilistic,
  title={On probabilistic inference approaches to stochastic optimal control},
  author={Rawlik, Konrad Cyrus},
  year={2013},
  publisher={The University of Edinburgh}
}

@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{haarnoja2018applications,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{friston2015active,
  title={Active inference and epistemic value},
  author={Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
  journal={Cognitive neuroscience},
  volume={6},
  number={4},
  pages={187--214},
  year={2015},
  publisher={Taylor \& Francis}
}

@article{friston2017active,
  title={Active inference: a process theory},
  author={Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},
  journal={Neural computation},
  volume={29},
  number={1},
  pages={1--49},
  year={2017},
  publisher={MIT Press}
}

@article{da2020active,
  title={Active inference on discrete state-spaces: a synthesis},
  author={Da Costa, Lancelot and Parr, Thomas and Sajid, Noor and Veselic, Sebastijan and Neacsu, Victorita and Friston, Karl},
  journal={arXiv preprint arXiv:2001.07203},
  year={2020}
}

@article{parr2019neuronal,
  title={Neuronal message passing using Mean-field, Bethe, and Marginal approximations},
  author={Parr, Thomas and Markovic, Dimitrije and Kiebel, Stefan J and Friston, Karl J},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--18},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{friston2017graphical,
  title={The graphical brain: belief propagation and active inference},
  author={Friston, Karl J and Parr, Thomas and de Vries, Bert},
  journal={Network Neuroscience},
  volume={1},
  number={4},
  pages={381--414},
  year={2017},
  publisher={MIT Press}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{parr2019generalised,
  title={Generalised free energy and active inference},
  author={Parr, Thomas and Friston, Karl J},
  journal={Biological cybernetics},
  volume={113},
  number={5-6},
  pages={495--513},
  year={2019},
  publisher={Springer}
}

@inproceedings{baltieri2018modularity,
  title={The modularity of action and perception revisited using control theory and active inference},
  author={Baltieri, Manuel and Buckley, Christopher L},
  booktitle={Artificial Life Conference Proceedings},
  pages={121--128},
  year={2018},
  organization={MIT Press}
}

@article{baltieri2019generative,
  title={Generative models as parsimonious descriptions of sensorimotor loops},
  author={Baltieri, Manuel and Buckley, Christopher L},
  journal={arXiv preprint arXiv:1904.12937},
  year={2019}
}

@article{badia2020agent57,
  title={Agent57: Outperforming the atari human benchmark},
  author={Badia, Adri{\`a} Puigdom{\`e}nech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Blundell, Charles},
  journal={arXiv preprint arXiv:2003.13350},
  year={2020}
}

@article{clark2015radical,
  title={Radical predictive processing},
  author={Clark, Andy},
  journal={The Southern Journal of Philosophy},
  volume={53},
  pages={3--27},
  year={2015},
  publisher={Wiley Online Library}
}

@article{friston2010free,
  title={The free-energy principle: a unified brain theory?},
  author={Friston, Karl},
  journal={Nature reviews neuroscience},
  volume={11},
  number={2},
  pages={127--138},
  year={2010},
  publisher={Nature Publishing Group}
}

@article{friston2006free,
  title={A free energy principle for the brain},
  author={Friston, Karl and Kilner, James and Harrison, Lee},
  journal={Journal of Physiology-Paris},
  volume={100},
  number={1-3},
  pages={70--87},
  year={2006},
  publisher={Elsevier}
}

@article{friston2009reinforcement,
  title={Reinforcement learning or active inference?},
  author={Friston, Karl J and Daunizeau, Jean and Kiebel, Stefan J},
  journal={PloS one},
  volume={4},
  number={7},
  year={2009},
  publisher={Public Library of Science}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{lee2019efficient,
  title={Efficient exploration via state marginal matching},
  author={Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1906.05274},
  year={2019}
}

@article{ziebart2010modeling,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010}
}

@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@article{shyam2018model,
  title={Model-based active exploration},
  author={Shyam, Pranav and Ja{\'s}kowski, Wojciech and Gomez, Faustino},
  journal={arXiv preprint arXiv:1810.12162},
  year={2018}
}

@article{walsh2020evaluating,
  title={Evaluating the neurophysiological evidence for predictive processing as a model of perception},
  author={Walsh, Kevin S and McGovern, David P and Clark, Andy and O'Connell, Redmond G},
  journal={Annals of the New York Academy of Sciences},
  volume={1464},
  number={1},
  pages={242},
  year={2020},
  publisher={Wiley-Blackwell}
}

@phdthesis{beal2003variational,
  title={Variational algorithms for approximate Bayesian inference},
  author={Beal, Matthew J},
  year={2003},
  school={UCL (University College London)}
}

@book{wainwright2008graphical,
  title={Graphical models, exponential families, and variational inference},
  author={Wainwright, Martin J and Jordan, Michael Irwin},
  year={2008},
  publisher={Now Publishers Inc}
}

@article{millidge2019implementing,
  title={Implementing Predictive Processing and Active Inference: Preliminary Steps and Results},
  author={Millidge, Beren},
  year={2019},
  publisher={PsyArXiv}
}

@article{van2010risk,
  title={Risk sensitive path integral control},
  author={van den Broek, LJ and Wiegerinck, WAJJ and Kappen, Hilbert J},
  year={2010},
  publisher={Catalina Island, California: AUAI Press}
}

@inproceedings{todorov2008general,
  title={General duality between optimal control and estimation},
  author={Todorov, Emanuel},
  booktitle={2008 47th IEEE Conference on Decision and Control},
  pages={4286--4292},
  year={2008},
  organization={IEEE}
}

@article{blackmore1995duality,
  title={Duality between the discrete-time Kalman filter and LQ control law},
  author={Blackmore, Perry A and Bitmead, Robert R},
  journal={IEEE transactions on automatic control},
  volume={40},
  number={8},
  pages={1442--1444},
  year={1995},
  publisher={IEEE}
}

@inproceedings{theodorou2012relative,
  title={Relative entropy and free energy dualities: Connections to path integral and kl control},
  author={Theodorou, Evangelos A and Todorov, Emanuel},
  booktitle={2012 IEEE 51st IEEE Conference on Decision and Control (CDC)},
  pages={1466--1473},
  year={2012},
  organization={IEEE}
}

@article{sancaktar2019end,
  title={End-to-end pixel-based deep active inference for body perception and action},
  author={Sancaktar, Cansu and Lanillos, Pablo},
  journal={arXiv preprint arXiv:2001.05847},
  year={2019}
}

@article{pio2016active,
  title={Active inference and robot control: a case study},
  author={Pio-Lopez, L{\'e}o and Nizard, Ange and Friston, Karl and Pezzulo, Giovanni},
  journal={Journal of The Royal Society Interface},
  volume={13},
  number={122},
  pages={20160616},
  year={2016},
  publisher={The Royal Society}
}

@article{botvinick2012planning,
  title={Planning as inference},
  author={Botvinick, Matthew and Toussaint, Marc},
  journal={Trends in cognitive sciences},
  volume={16},
  number={10},
  pages={485--488},
  year={2012},
  publisher={Elsevier}
}

@article{friston2003learning,
  title={Learning and inference in the brain},
  author={Friston, Karl},
  journal={Neural Networks},
  volume={16},
  number={9},
  pages={1325--1352},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{deneve2005bayesian,
  title={Bayesian inference in spiking neurons},
  author={Deneve, Sophie},
  booktitle={Advances in neural information processing systems},
  pages={353--360},
  year={2005}
}

@article{buckley2017free,
  title={The free energy principle for action and perception: A mathematical review},
  author={Buckley, Christopher L and Kim, Chang Sub and McGregor, Simon and Seth, Anil K},
  journal={Journal of Mathematical Psychology},
  volume={81},
  pages={55--79},
  year={2017},
  publisher={Elsevier}
}

@article{friston2011optimal,
  title={What is optimal about motor control?},
  author={Friston, Karl},
  journal={Neuron},
  volume={72},
  number={3},
  pages={488--498},
  year={2011},
  publisher={Elsevier}
}

@article{friston2012free,
  title={Free energy, value, and attractors},
  author={Friston, Karl and Ao, Ping},
  journal={Computational and mathematical methods in medicine},
  volume={2012},
  year={2012},
  publisher={Hindawi}
}

@inproceedings{baltieri2017active,
  title={An active inference implementation of phototaxis},
  author={Baltieri, Manuel and Buckley, Christopher L},
  booktitle={Artificial Life Conference Proceedings 14},
  pages={36--43},
  year={2017},
  organization={MIT Press}
}

@inproceedings{baltieri2018probabilistic,
  title={A probabilistic interpretation of PID controllers using active inference},
  author={Baltieri, Manuel and Buckley, Christopher L},
  booktitle={International Conference on Simulation of Adaptive Behavior},
  pages={15--26},
  year={2018},
  organization={Springer}
}

@article{calvo2017predicting,
  title={Predicting green: really radical (plant) predictive processing},
  author={Calvo, Paco and Friston, Karl},
  journal={Journal of The Royal Society Interface},
  volume={14},
  number={131},
  pages={20170096},
  year={2017},
  publisher={The Royal Society}
}

@article{friston2011action,
  title={Action understanding and active inference},
  author={Friston, Karl and Mattout, J{\'e}r{\'e}mie and Kilner, James},
  journal={Biological cybernetics},
  volume={104},
  number={1-2},
  pages={137--160},
  year={2011},
  publisher={Springer}
}

@article{friston2016active,
  title={Active inference and learning},
  author={Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni and others},
  journal={Neuroscience \& Biobehavioral Reviews},
  volume={68},
  pages={862--879},
  year={2016},
  publisher={Elsevier}
}

@article{friston2012active,
  title={Active inference and agency: optimal control without cost functions},
  author={Friston, Karl and Samothrakis, Spyridon and Montague, Read},
  journal={Biological cybernetics},
  volume={106},
  number={8-9},
  pages={523--541},
  year={2012},
  publisher={Springer}
}

@article{friston2017curiosity,
  title={Active inference, curiosity and insight},
  author={Friston, Karl J and Lin, Marco and Frith, Christopher D and Pezzulo, Giovanni and Hobson, J Allan and Ondobaka, Sasha},
  journal={Neural computation},
  volume={29},
  number={10},
  pages={2633--2683},
  year={2017},
  publisher={MIT Press}
}

@article{tschantz2019learning,
  title={Learning action-oriented models through active inference},
  author={Tschantz, Alexander and Seth, Anil K and Buckley, Christopher L},
  journal={bioRxiv},
  pages={764969},
  year={2019},
  publisher={Cold Spring Harbor Laboratory}
}

@article{itti2009bayesian,
  title={Bayesian surprise attracts human attention},
  author={Itti, Laurent and Baldi, Pierre},
  journal={Vision research},
  volume={49},
  number={10},
  pages={1295--1306},
  year={2009},
  publisher={Elsevier}
}

@article{baldi2010bits,
  title={Of bits and wows: A Bayesian theory of surprise with applications to attention},
  author={Baldi, Pierre and Itti, Laurent},
  journal={Neural Networks},
  volume={23},
  number={5},
  pages={649--666},
  year={2010},
  publisher={Elsevier}
}

@article{ostwald2012evidence,
  title={Evidence for neural encoding of Bayesian surprise in human somatosensation},
  author={Ostwald, Dirk and Spitzer, Bernhard and Guggenmos, Matthias and Schmidt, Timo T and Kiebel, Stefan J and Blankenburg, Felix},
  journal={NeuroImage},
  volume={62},
  number={1},
  pages={177--188},
  year={2012},
  publisher={Elsevier}
}

@article{still2012information,
  title={An information-theoretic approach to curiosity-driven reinforcement learning},
  author={Still, Susanne and Precup, Doina},
  journal={Theory in Biosciences},
  volume={131},
  number={3},
  pages={139--148},
  year={2012},
  publisher={Springer}
}

@inproceedings{sun2011planning,
  title={Planning to be surprised: Optimal bayesian exploration in dynamic environments},
  author={Sun, Yi and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Artificial General Intelligence},
  pages={41--51},
  year={2011},
  organization={Springer}
}

@article{houthooft2016variational,
  title={Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems (NIPS)},
  year={2016}
}

@article{parr2017uncertainty,
  title={Uncertainty, epistemics and active inference},
  author={Parr, Thomas and Friston, Karl J},
  journal={Journal of The Royal Society Interface},
  volume={14},
  number={136},
  pages={20170376},
  year={2017},
  publisher={The Royal Society}
}

@article{schwartenbeck2013exploration,
  title={Exploration, novelty, surprise, and free energy minimization},
  author={Schwartenbeck, Philipp and FitzGerald, Thomas and Dolan, Ray and Friston, Karl},
  journal={Frontiers in psychology},
  volume={4},
  pages={710},
  year={2013},
  publisher={Frontiers}
}

@article{schwartenbeck2019computational,
  title={Computational mechanisms of curiosity and goal-directed exploration},
  author={Schwartenbeck, Philipp and Passecker, Johannes and Hauser, Tobias U and FitzGerald, Thomas HB and Kronbichler, Martin and Friston, Karl J},
  journal={Elife},
  volume={8},
  pages={e41703},
  year={2019},
  publisher={eLife Sciences Publications Limited}
}

@article{oudeyer2009intrinsic,
  title={What is intrinsic motivation? A typology of computational approaches},
  author={Oudeyer, Pierre-Yves and Kaplan, Frederic},
  journal={Frontiers in neurorobotics},
  volume={1},
  pages={6},
  year={2009},
  publisher={Frontiers}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}

@inproceedings{mohamed2015variational,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Rezende, Danilo Jimenez},
  booktitle={Advances in neural information processing systems},
  pages={2125--2133},
  year={2015}
}

@article{burda2018large,
  title={Large-scale study of curiosity-driven learning},
  author={Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A},
  journal={arXiv preprint arXiv:1808.04355},
  year={2018}
}

@article{millidge2019deep,
  title={Deep active inference as variational policy gradients},
  author={Millidge, Beren},
  journal={arXiv preprint arXiv:1907.03876},
  year={2019}
}

@article{ccatal2020learning,
  title={Learning Perception and Planning with Deep Active Inference},
  author={{\c{C}}atal, Ozan and Verbelen, Tim and Nauta, Johannes and De Boom, Cedric and Dhoedt, Bart},
  journal={arXiv preprint arXiv:2001.11841},
  year={2020}
}

@article{van2019simulating,
  title={Simulating active inference processes by message passing},
  author={van de Laar, Thijs W and de Vries, Bert},
  journal={Frontiers in Robotics and AI},
  volume={6},
  number={20},
  year={2019},
  publisher={Frontiers Media}
}

@article{pezzulo2016active,
  title={Active Inference, epistemic value, and vicarious trial and error},
  author={Pezzulo, Giovanni and Cartoni, Emilio and Rigoli, Francesco and Pio-Lopez, L{\'e}o and Friston, Karl},
  journal={Learning \& Memory},
  volume={23},
  number={7},
  pages={322--338},
  year={2016},
  publisher={Cold Spring Harbor Lab}
}

@article{fitzgerald2015active,
  title={Active inference, evidence accumulation, and the urn task},
  author={FitzGerald, Thomas HB and Schwartenbeck, Philipp and Moutoussis, Michael and Dolan, Raymond J and Friston, Karl},
  journal={Neural computation},
  volume={27},
  number={2},
  pages={306--328},
  year={2015},
  publisher={MIT Press}
}

@article{mirza2016scene,
  title={Scene construction, visual foraging, and active inference},
  author={Mirza, M Berk and Adams, Rick A and Mathys, Christoph D and Friston, Karl J},
  journal={Frontiers in computational neuroscience},
  volume={10},
  pages={56},
  year={2016},
  publisher={Frontiers}
}

@article{parr2017active,
  title={The active construction of the visual world},
  author={Parr, Thomas and Friston, Karl J},
  journal={Neuropsychologia},
  volume={104},
  pages={92--101},
  year={2017},
  publisher={Elsevier}
}

@article{parr2018active,
  title={Active inference and the anatomy of oculomotion},
  author={Parr, Thomas and Friston, Karl J},
  journal={Neuropsychologia},
  volume={111},
  pages={334--343},
  year={2018},
  publisher={Elsevier}
}

@article{friston2018deep,
  title={Deep temporal models and active inference},
  author={Friston, Karl J and Rosch, Richard and Parr, Thomas and Price, Cathy and Bowman, Howard},
  journal={Neuroscience \& Biobehavioral Reviews},
  volume={90},
  pages={486--501},
  year={2018},
  publisher={Elsevier}
}

@article{cullen2018active,
  title={Active inference in openai gym: A paradigm for computational investigations into psychiatric illness},
  author={Cullen, Maell and Davey, Ben and Friston, Karl J and Moran, Rosalyn J},
  journal={Biological psychiatry: cognitive neuroscience and neuroimaging},
  volume={3},
  number={9},
  pages={809--818},
  year={2018},
  publisher={Elsevier}
}

@article{mirza2019impulsivity,
  title={Impulsivity and active inference},
  author={Mirza, M Berk and Adams, Rick A and Parr, Thomas and Friston, Karl},
  journal={Journal of cognitive neuroscience},
  volume={31},
  number={2},
  pages={202--220},
  year={2019},
  publisher={MIT Press}
}

@article{parr2018computational,
  title={The computational anatomy of visual neglect},
  author={Parr, Thomas and Friston, Karl J},
  journal={Cerebral Cortex},
  volume={28},
  number={2},
  pages={777--790},
  year={2018},
  publisher={Oxford University Press}
}

@article{friston2017process,
  title={Active inference: a process theory},
  author={Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},
  journal={Neural computation},
  volume={29},
  number={1},
  pages={1--49},
  year={2017},
  publisher={MIT Press}
}

@article{fox2012tutorial,
  title={A tutorial on variational Bayesian inference},
  author={Fox, Charles W and Roberts, Stephen J},
  journal={Artificial intelligence review},
  volume={38},
  number={2},
  pages={85--95},
  year={2012},
  publisher={Springer}
}

@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{friston2008DEM,
  title={DEM: a variational treatment of dynamic systems},
  author={Friston, Karl J and Trujillo-Barreto, N and Daunizeau, Jean},
  journal={Neuroimage},
  volume={41},
  number={3},
  pages={849--885},
  year={2008},
  publisher={Elsevier}
}

@article{friston2019physics,
  title={A free energy principle for a particular physics},
  author={Friston, Karl},
  journal={arXiv preprint arXiv:1906.10184},
  year={2019}
}

@article{parr2020markov,
  title={Markov blankets, information geometry and stochastic thermodynamics},
  author={Parr, Thomas and Da Costa, Lancelot and Friston, Karl},
  journal={Philosophical Transactions of the Royal Society A},
  volume={378},
  number={2164},
  pages={20190159},
  year={2020},
  publisher={The Royal Society Publishing}
}

@article{karl2012free,
  title={A free energy principle for biological systems},
  author={Karl, Friston},
  journal={Entropy},
  volume={14},
  number={11},
  pages={2100--2121},
  year={2012},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{friston2012ao,
  title={Free energy, value, and attractors},
  author={Friston, Karl and Ao, Ping},
  journal={Computational and mathematical methods in medicine},
  volume={2012},
  year={2012},
  publisher={Hindawi}
}

@article{theodorou2010generalized,
  title={A generalized path integral control approach to reinforcement learning},
  author={Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
  journal={journal of machine learning research},
  volume={11},
  number={Nov},
  pages={3137--3181},
  year={2010}
}

@inproceedings{kappen2007introduction,
  title={An introduction to stochastic control theory, path integrals and reinforcement learning},
  author={Kappen, Hilbert J},
  booktitle={AIP conference proceedings},
  volume={887},
  number={1},
  pages={149--181},
  year={2007},
  organization={American Institute of Physics}
}

@article{kappen2005path,
  title={Path integrals and symmetry breaking for optimal control theory},
  author={Kappen, Hilbert J},
  journal={Journal of statistical mechanics: theory and experiment},
  volume={2005},
  number={11},
  pages={P11011},
  year={2005},
  publisher={IOP Publishing}
}

@article{toussaint2009probabilistic,
  title={Probabilistic inference as a model of planned behavior.},
  author={Toussaint, Marc},
  journal={KI},
  volume={23},
  number={3},
  pages={23--29},
  year={2009}
}

@article{williams2017model,
  title={Model predictive path integral control: From theory to parallel computation},
  author={Williams, Grady and Aldrich, Andrew and Theodorou, Evangelos A},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={40},
  number={2},
  pages={344--357},
  year={2017},
  publisher={American Institute of Aeronautics and Astronautics}
}

@article{biehl2018expanding,
  title={Expanding the active inference landscape: more intrinsic motivations in the perception-action loop},
  author={Biehl, Martin and Guckelsberger, Christian and Salge, Christoph and Smith, Sim{\'o}n C and Polani, Daniel},
  journal={Frontiers in neurorobotics},
  volume={12},
  pages={45},
  year={2018},
  publisher={Frontiers}
}

@phdthesis{parr2019computational,
  title={The computational neurology of active vision},
  author={Parr, Thomas},
  year={2019},
  school={UCL (University College London)}
}

@article{schwobel2018active,
  title={Active inference, belief propagation, and the bethe approximation},
  author={Schw{\"o}bel, Sarah and Kiebel, Stefan and Markovi{\'c}, Dimitrije},
  journal={Neural computation},
  volume={30},
  number={9},
  pages={2530--2567},
  year={2018},
  publisher={MIT Press}
}

@inproceedings{yedidia2001generalized,
  title={Generalized belief propagation},
  author={Yedidia, Jonathan S and Freeman, William T and Weiss, Yair},
  booktitle={Advances in neural information processing systems},
  pages={689--695},
  year={2001}
}

@article{yedidia2005constructing,
  title={Constructing free-energy approximations and generalized belief propagation algorithms},
  author={Yedidia, Jonathan S and Freeman, William T and Weiss, Yair},
  journal={IEEE Transactions on information theory},
  volume={51},
  number={7},
  pages={2282--2312},
  year={2005},
  publisher={IEEE}
}

@article{kanai2015cerebral,
  title={Cerebral hierarchies: predictive processing, precision and the pulvinar},
  author={Kanai, Ryota and Komura, Yutaka and Shipp, Stewart and Friston, Karl},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={370},
  number={1668},
  pages={20140169},
  year={2015},
  publisher={The Royal Society}
}

@article{shipp2016neural,
  title={Neural elements for predictive coding},
  author={Shipp, Stewart},
  journal={Frontiers in psychology},
  volume={7},
  pages={1792},
  year={2016},
  publisher={Frontiers}
}

@article{millidge2020relationship,
  title={On the Relationship Between Active Inference and Control as Inference},
  author={Millidge, Beren and Tschantz, Alexander and Seth, Anil K and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2006.12964},
  year={2020}
}

@article{thorpe1996speed,
  title={Speed of processing in the human visual system},
  author={Thorpe, Simon and Fize, Denis and Marlot, Catherine},
  journal={nature},
  volume={381},
  number={6582},
  pages={520--522},
  year={1996},
  publisher={Nature Publishing Group}
}

@article{keysers2001speed,
  title={The speed of sight},
  author={Keysers, Christian and Xiao, D-K and F{\"o}ldi{\'a}k, Peter and Perrett, David I},
  journal={Journal of cognitive neuroscience},
  volume={13},
  number={1},
  pages={90--101},
  year={2001},
  publisher={MIT Press}
}

@article{carlson2013representational,
  title={Representational dynamics of object vision: the first 1000 ms},
  author={Carlson, Thomas and Tovar, David A and Alink, Arjen and Kriegeskorte, Nikolaus},
  journal={Journal of vision},
  volume={13},
  number={10},
  pages={1--1},
  year={2013},
  publisher={The Association for Research in Vision and Ophthalmology}
}

@article{dicarlo2012does,
  title={How does the brain solve visual object recognition?},
  author={DiCarlo, James J and Zoccolan, Davide and Rust, Nicole C},
  journal={Neuron},
  volume={73},
  number={3},
  pages={415--434},
  year={2012},
  publisher={Elsevier}
}

@article{johnson2005recognition,
  title={The recognition of partially visible natural objects in the presence and absence of their occluders},
  author={Johnson, Jeffrey S and Olshausen, Bruno A},
  journal={Vision research},
  volume={45},
  number={25-26},
  pages={3262--3276},
  year={2005},
  publisher={Elsevier}
}

@article{wyatte2012limits,
  title={The limits of feedforward vision: Recurrent processing promotes robust object recognition when objects are degraded},
  author={Wyatte, Dean and Curran, Tim and O'Reilly, Randall},
  journal={Journal of Cognitive Neuroscience},
  volume={24},
  number={11},
  pages={2248--2261},
  year={2012},
  publisher={MIT Press}
}

@article{rajaei2019beyond,
  title={Beyond core object recognition: Recurrent processes account for object recognition under occlusion},
  author={Rajaei, Karim and Mohsenzadeh, Yalda and Ebrahimpour, Reza and Khaligh-Razavi, Seyed-Mahdi},
  journal={PLoS computational biology},
  volume={15},
  number={5},
  pages={e1007001},
  year={2019},
  publisher={Public Library of Science}
}

@article{tang2018recurrent,
  title={Recurrent computations for visual pattern completion},
  author={Tang, Hanlin and Schrimpf, Martin and Lotter, William and Moerman, Charlotte and Paredes, Ana and Caro, Josue Ortega and Hardesty, Walter and Cox, David and Kreiman, Gabriel},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={35},
  pages={8835--8840},
  year={2018},
  publisher={National Acad Sciences}
}

@article{lamme2000distinct,
  title={The distinct modes of vision offered by feedforward and recurrent processing},
  author={Lamme, Victor AF and Roelfsema, Pieter R},
  journal={Trends in neurosciences},
  volume={23},
  number={11},
  pages={571--579},
  year={2000},
  publisher={Elsevier}
}

@article{kveraga2007top,
  title={Top-down predictions in the cognitive brain},
  author={Kveraga, Kestutis and Ghuman, Avniel S and Bar, Moshe},
  journal={Brain and cognition},
  volume={65},
  number={2},
  pages={145--168},
  year={2007},
  publisher={Elsevier}
}

@article{vanrullen2007power,
  title={The power of the feed-forward sweep},
  author={VanRullen, Rufin},
  journal={Advances in Cognitive Psychology},
  volume={3},
  number={1-2},
  pages={167},
  year={2007},
  publisher={University of Finance and Management in Warsaw}
}

@article{roland2010six,
  title={Six principles of visual cortical dynamics},
  author={Roland, Per E},
  journal={Frontiers in systems neuroscience},
  volume={4},
  pages={28},
  year={2010},
  publisher={Frontiers}
}

@article{kar2019evidence,
  title={Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior},
  author={Kar, Kohitij and Kubilius, Jonas and Schmidt, Kailyn and Issa, Elias B and DiCarlo, James J},
  journal={Nature neuroscience},
  volume={22},
  number={6},
  pages={974--983},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{den2012prediction,
  title={How prediction errors shape perception, attention, and motivation},
  author={Den Ouden, Hanneke EM and Kok, Peter and De Lange, Floris P},
  journal={Frontiers in psychology},
  volume={3},
  pages={548},
  year={2012},
  publisher={Frontiers}
}

@article{alink2010stimulus,
  title={Stimulus predictability reduces responses in primary visual cortex},
  author={Alink, Arjen and Schwiedrzik, Caspar M and Kohler, Axel and Singer, Wolf and Muckli, Lars},
  journal={Journal of Neuroscience},
  volume={30},
  number={8},
  pages={2960--2966},
  year={2010},
  publisher={Soc Neuroscience}
}

@article{gordon2017neural,
  title={Neural markers of predictive coding under perceptual uncertainty revealed with Hierarchical Frequency Tagging},
  author={Gordon, Noam and Koenig-Robert, Roger and Tsuchiya, Naotsugu and Van Boxtel, Jeroen JA and Hohwy, Jakob},
  journal={Elife},
  volume={6},
  pages={e22749},
  year={2017},
  publisher={eLife Sciences Publications Limited}
}

@article{murray2002shape,
  title={Shape perception reduces activity in human primary visual cortex},
  author={Murray, Scott O and Kersten, Daniel and Olshausen, Bruno A and Schrater, Paul and Woods, David L},
  journal={Proceedings of the National Academy of Sciences},
  volume={99},
  number={23},
  pages={15164--15169},
  year={2002},
  publisher={National Acad Sciences}
}

@article{summerfield2014expectation,
  title={Expectation in perceptual decision making: neural and computational mechanisms},
  author={Summerfield, Christopher and De Lange, Floris P},
  journal={Nature Reviews Neuroscience},
  volume={15},
  number={11},
  pages={745--756},
  year={2014},
  publisher={Nature Publishing Group}
}

@article{bar2003cortical,
  title={A cortical mechanism for triggering top-down facilitation in visual object recognition},
  author={Bar, Moshe},
  journal={Journal of cognitive neuroscience},
  volume={15},
  number={4},
  pages={600--609},
  year={2003},
  publisher={MIT Press}
}

@article{kreiman2020beyond,
  title={Beyond the feedforward sweep: feedback computations in the visual cortex},
  author={Kreiman, Gabriel and Serre, Thomas},
  journal={Annals of the New York Academy of Sciences},
  year={2020}
}

@article{serre2007feedforward,
  title={A feedforward architecture accounts for rapid categorization},
  author={Serre, Thomas and Oliva, Aude and Poggio, Tomaso},
  journal={Proceedings of the national academy of sciences},
  volume={104},
  number={15},
  pages={6424--6429},
  year={2007},
  publisher={National Acad Sciences}
}

@article{brincat2006dynamic,
  title={Dynamic shape synthesis in posterior inferotemporal cortex},
  author={Brincat, Scott L and Connor, Charles E},
  journal={Neuron},
  volume={49},
  number={1},
  pages={17--24},
  year={2006},
  publisher={Elsevier}
}

@article{rousselet2003animal,
  title={Is it an animal? Is it a human face? Fast processing in upright and inverted natural scenes},
  author={Rousselet, Guillaume A and Mac{\'e}, Marc J-M and Fabre-Thorpe, Mich{\`e}le},
  journal={Journal of vision},
  volume={3},
  number={6},
  pages={5--5},
  year={2003},
  publisher={The Association for Research in Vision and Ophthalmology}
}

@article{ringach1996spatial,
  title={Spatial and temporal properties of illusory contours and amodal boundary completion},
  author={Ringach, Dario L and Shapley, Robert},
  journal={Vision research},
  volume={36},
  number={19},
  pages={3037--3050},
  year={1996},
  publisher={Elsevier}
}

@article{sugase1999global,
  title={Global and fine information coded by single neurons in the temporal visual cortex},
  author={Sugase, Yasuko and Yamane, Shigeru and Ueno, Shoogo and Kawano, Kenji},
  journal={Nature},
  volume={400},
  number={6747},
  pages={869--873},
  year={1999},
  publisher={Nature Publishing Group}
}

@article{thunell2019memory,
  title={Memory for repeated images in rapid-serial-visual-presentation streams of thousands of images},
  author={Thunell, Evelina and Thorpe, Simon J},
  journal={Psychological science},
  volume={30},
  number={7},
  pages={989--1000},
  year={2019},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{whittington2017approximation,
  title={An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity},
  author={Whittington, James CR and Bogacz, Rafal},
  journal={Neural computation},
  volume={29},
  number={5},
  pages={1229--1262},
  year={2017},
  publisher={MIT Press}
}

@article{millidge2020predictive,
  title={Predictive Coding Approximates Backprop along Arbitrary Computation Graphs},
  author={Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2006.04182},
  year={2020}
}

@article{srinivas2020curl,
  title={CURL: Contrastive Unsupervised Representations for Reinforcement Learning},
  author={Srinivas, Aravind and Laskin, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2004.04136},
  year={2020}
}

@article{okada2019variational,
  title={Variational inference mpc for bayesian model-based reinforcement learning},
  author={Okada, Masashi and Taniguchi, Tadahiro},
  journal={arXiv preprint arXiv:1907.04202},
  year={2019}
}

@article{wang2019exploring,
  title={Exploring model-based planning with policy networks},
  author={Wang, Tingwu and Ba, Jimmy},
  journal={arXiv preprint arXiv:1906.08649},
  year={2019}
}

@article{sun2019tutorial,
  title={Tutorial and Survey on Probabilistic Graphical Model and Variational Inference in Deep Reinforcement Learning},
  author={Sun, Xudong and Bischl, Bernd},
  journal={arXiv preprint arXiv:1908.09381},
  year={2019}
}

@book{koller2009probabilistic,
  title={Probabilistic graphical models: principles and techniques},
  author={Koller, Daphne and Friedman, Nir},
  year={2009},
  publisher={MIT press}
}

@inproceedings{chebotar2017combining,
  title={Combining model-based and model-free updates for trajectory-centric reinforcement learning},
  author={Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={703--711},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{atkeson1997comparison,
  title={A comparison of direct and model-based reinforcement learning},
  author={Atkeson, Christopher G and Santamaria, Juan Carlos},
  booktitle={Proceedings of International Conference on Robotics and Automation},
  volume={4},
  pages={3557--3564},
  year={1997},
  organization={IEEE}
}

@book{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan},
  year={2013},
  publisher={now publishers}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{farshidian2014learning,
  title={Learning of closed-loop motion control},
  author={Farshidian, Farbod and Neunert, Michael and Buchli, Jonas},
  booktitle={2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={1441--1446},
  year={2014},
  organization={IEEE}
}

@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2829--2838},
  year={2016}
}

@incollection{sutton1990integrated,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning proceedings 1990},
  pages={216--224},
  year={1990},
  publisher={Elsevier}
}

@article{pezzulo2013mixed,
  title={The mixed instrumental controller: using value of information to combine habitual choice and mental simulation},
  author={Pezzulo, Giovanni and Rigoli, Francesco and Chersi, Fabian},
  journal={Frontiers in psychology},
  volume={4},
  pages={92},
  year={2013},
  publisher={Frontiers}
}

@article{daw2005uncertainty,
  title={Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control},
  author={Daw, Nathaniel D and Niv, Yael and Dayan, Peter},
  journal={Nature neuroscience},
  volume={8},
  number={12},
  pages={1704--1711},
  year={2005},
  publisher={Nature Publishing Group}
}

@article{balleine1998goal,
  title={Goal-directed instrumental action: contingency and incentive learning and their cortical substrates},
  author={Balleine, Bernard W and Dickinson, Anthony},
  journal={Neuropharmacology},
  volume={37},
  number={4-5},
  pages={407--419},
  year={1998},
  publisher={Elsevier}
}

@article{niv2006normative,
  title={A normative perspective on motivation},
  author={Niv, Yael and Joel, Daphna and Dayan, Peter},
  journal={Trends in cognitive sciences},
  volume={10},
  number={8},
  pages={375--381},
  year={2006},
  publisher={Elsevier}
}

@article{dayan2009goal,
  title={Goal-directed control and its antipodes},
  author={Dayan, Peter},
  journal={Neural Networks},
  volume={22},
  number={3},
  pages={213--219},
  year={2009},
  publisher={Elsevier}
}

@article{dolan2013goals,
  title={Goals and habits in the brain},
  author={Dolan, Ray J and Dayan, Peter},
  journal={Neuron},
  volume={80},
  number={2},
  pages={312--325},
  year={2013},
  publisher={Elsevier}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{dong2019bootstrapping,
  title={Bootstrapping the expressivity with model-based planning},
  author={Dong, Kefan and Luo, Yuping and Ma, Tengyu},
  journal={arXiv preprint arXiv:1910.05927},
  year={2019}
}

@article{li2020robot,
  title={Robot Playing Kendama with Model-Based and Model-Free Reinforcement Learning},
  author={Li, Shidi},
  journal={arXiv preprint arXiv:2003.06751},
  year={2020}
}

@inproceedings{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@article{bansal2017mbmf,
  title={Mbmf: Model-based priors for model-free reinforcement learning},
  author={Bansal, Somil and Calandra, Roberto and Chua, Kurtland and Levine, Sergey and Tomlin, Claire},
  journal={arXiv preprint arXiv:1709.03153},
  year={2017}
}

@article{deisenroth2013gaussian,
  title={Gaussian processes for data-efficient learning in robotics and control},
  author={Deisenroth, Marc Peter and Fox, Dieter and Rasmussen, Carl Edward},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={37},
  number={2},
  pages={408--423},
  year={2013},
  publisher={IEEE}
}

@article{hafner2018learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  journal={arXiv preprint arXiv:1811.04551},
  year={2018}
}

@article{glascher2010states,
  title={States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning},
  author={Gl{\"a}scher, Jan and Daw, Nathaniel and Dayan, Peter and O'Doherty, John P},
  journal={Neuron},
  volume={66},
  number={4},
  pages={585--595},
  year={2010},
  publisher={Elsevier}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@article{che2018combining,
  title={Combining Model-based and Model-free RL via Multi-step Control Variates},
  author={Che, Tong and Lu, Yuchen and Tucker, George and Bhupatiraju, Surya and Gu, Shane and Levine, Sergey and Bengio, Yoshua},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{ha2018recurrent,
  title={Recurrent world models facilitate policy evolution},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2450--2462},
  year={2018}
}

@article{hafner2019dream,
  title={Dream to Control: Learning Behaviors by Latent Imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@article{schrittwieser2019mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1911.08265},
  year={2019}
}

@article{dayan1997using,
  title={Using expectation-maximization for reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  journal={Neural Computation},
  volume={9},
  number={2},
  pages={271--278},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{toussaint2006probabilistic,
  title={Probabilistic inference for solving discrete and continuous state Markov Decision Processes},
  author={Toussaint, Marc and Storkey, Amos},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={945--952},
  year={2006}
}

@article{ziebart2013principle,
  title={The principle of maximum causal entropy for estimating interacting processes},
  author={Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
  journal={IEEE Transactions on Information Theory},
  volume={59},
  number={4},
  pages={1966--1980},
  year={2013},
  publisher={IEEE}
}

@inproceedings{levine2013variational,
  title={Variational policy search via trajectory optimization},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={Advances in neural information processing systems},
  pages={207--215},
  year={2013}
}

@article{kappen2012optimal,
  title={Optimal control as a graphical model inference problem},
  author={Kappen, Hilbert J and G{\'o}mez, Vicen{\c{c}} and Opper, Manfred},
  journal={Machine learning},
  volume={87},
  number={2},
  pages={159--182},
  year={2012},
  publisher={Springer}
}

@article{jordan1999introduction,
  title={An introduction to variational methods for graphical models},
  author={Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  journal={Machine learning},
  volume={37},
  number={2},
  pages={183--233},
  year={1999},
  publisher={Springer}
}

@article{eysenbach2019if,
  title={If MaxEnt RL is the Answer, What is the Question?},
  author={Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.01913},
  year={2019}
}

@inproceedings{neumann2011variational,
  title={Variational inference for policy search in changing situations},
  author={Neumann, Gerhard and others},
  booktitle={Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
  pages={817--824},
  year={2011}
}

@inproceedings{fellows2019virel,
  title={Virel: A variational inference framework for reinforcement learning},
  author={Fellows, Matthew and Mahajan, Anuj and Rudner, Tim GJ and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7120--7134},
  year={2019}
}

@article{o2020making,
  title={Making Sense of Reinforcement Learning and Probabilistic Inference},
  author={O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
  journal={arXiv preprint arXiv:2001.00805},
  year={2020}
}

@article{piche2018probabilistic,
  title={Probabilistic planning with sequential monte carlo methods},
  author={Pich{\'e}, Alexandre and Thomas, Valentin and Ibrahim, Cyril and Bengio, Yoshua and Pal, Chris},
  year={2018}
}

@article{mnih2014neural,
  title={Neural variational inference and learning in belief networks},
  author={Mnih, Andriy and Gregor, Karol},
  journal={arXiv preprint arXiv:1402.0030},
  year={2014}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{hoffman2013stochastic,
  title={Stochastic variational inference},
  author={Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={1303--1347},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{ghahramani2001propagation,
  title={Propagation algorithms for variational Bayesian learning},
  author={Ghahramani, Zoubin and Beal, Matthew J},
  booktitle={Advances in neural information processing systems},
  pages={507--513},
  year={2001}
}

@incollection{botev2013cross,
  title={The cross-entropy method for optimization},
  author={Botev, Zdravko I and Kroese, Dirk P and Rubinstein, Reuven Y and L’Ecuyer, Pierre},
  booktitle={Handbook of statistics},
  volume={31},
  pages={35--59},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{williams2016aggressive,
  title={Aggressive driving with model predictive path integral control},
  author={Williams, Grady and Drews, Paul and Goldfain, Brian and Rehg, James M and Theodorou, Evangelos A},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1433--1440},
  year={2016},
  organization={IEEE}
}

@inproceedings{williams2017information,
  title={Information theoretic MPC for model-based reinforcement learning},
  author={Williams, Grady and Wagener, Nolan and Goldfain, Brian and Drews, Paul and Rehg, James M and Boots, Byron and Theodorou, Evangelos A},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1714--1721},
  year={2017},
  organization={IEEE}
}

@article{hansen2003reducing,
  title={Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)},
  author={Hansen, Nikolaus and M{\"u}ller, Sibylle D and Koumoutsakos, Petros},
  journal={Evolutionary computation},
  volume={11},
  number={1},
  pages={1--18},
  year={2003},
  publisher={MIT Press}
}

@article{kim2018semi,
  title={Semi-amortized variational autoencoders},
  author={Kim, Yoon and Wiseman, Sam and Miller, Andrew C and Sontag, David and Rush, Alexander M},
  journal={arXiv preprint arXiv:1802.02550},
  year={2018}
}

@book{camacho2013model,
  title={Model predictive control},
  author={Camacho, Eduardo F and Alba, Carlos Bordons},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{depeweg2017decomposition,
  title={Decomposition of uncertainty in Bayesian deep learning for efficient and risk-sensitive learning},
  author={Depeweg, Stefan and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Doshi-Velez, Finale and Udluft, Steffen},
  journal={arXiv preprint arXiv:1710.07283},
  year={2017}
}

@inproceedings{satorras2019combining,
  title={Combining Generative and Discriminative Models for Hybrid Inference},
  author={Satorras, Victor Garcia and Akata, Zeynep and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13802--13812},
  year={2019}
}

@article{bubeck2014convex,
  title={Convex optimization: Algorithms and complexity},
  author={Bubeck, S{\'e}bastien},
  journal={arXiv preprint arXiv:1405.4980},
  year={2014}
}

@inproceedings{gershman2014amortized,
  title={Amortized inference in probabilistic reasoning},
  author={Gershman, Samuel and Goodman, Noah},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={36},
  number={36},
  year={2014}
}

@inproceedings{okada2018acceleration,
  title={Acceleration of gradient-based path integral method for efficient optimal and inverse optimal control},
  author={Okada, Masashi and Taniguchi, Tadahiro},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={3013--3020},
  year={2018},
  organization={IEEE}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{schulman2017equivalence,
  title={Equivalence between policy gradients and soft q-learning},
  author={Schulman, John and Chen, Xi and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1704.06440},
  year={2017}
}

@article{abdolmaleki2018relative,
  title={Relative entropy regularized policy iteration},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Degrave, Jonas and Bohez, Steven and Tassa, Yuval and Belov, Dan and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1812.02256},
  year={2018}
}

@article{song2019v,
  title={V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control},
  author={Song, H Francis and Abdolmaleki, Abbas and Springenberg, Jost Tobias and Clark, Aidan and Soyer, Hubert and Rae, Jack W and Noury, Seb and Ahuja, Arun and Liu, Siqi and Tirumala, Dhruva and others},
  journal={arXiv preprint arXiv:1909.12238},
  year={2019}
}

@article{galashov2019information,
  title={Information asymmetry in KL-regularized RL},
  author={Galashov, Alexandre and Jayakumar, Siddhant M and Hasenclever, Leonard and Tirumala, Dhruva and Schwarz, Jonathan and Desjardins, Guillaume and Czarnecki, Wojciech M and Teh, Yee Whye and Pascanu, Razvan and Heess, Nicolas},
  journal={arXiv preprint arXiv:1905.01240},
  year={2019}
}

@article{tirumala2019exploiting,
  title={Exploiting hierarchy for learning and transfer in kl-regularized rl},
  author={Tirumala, Dhruva and Noh, Hyeonwoo and Galashov, Alexandre and Hasenclever, Leonard and Ahuja, Arun and Wayne, Greg and Pascanu, Razvan and Teh, Yee Whye and Heess, Nicolas},
  journal={arXiv preprint arXiv:1903.07438},
  year={2019}
}

@inproceedings{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4496--4506},
  year={2017}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@article{kurutach2018model,
  title={Model-ensemble trust-region policy optimization},
  author={Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1802.10592},
  year={2018}
}

@inproceedings{hjelm2016iterative,
  title={Iterative refinement of the approximate posterior for directed belief networks},
  author={Hjelm, Devon and Salakhutdinov, Russ R and Cho, Kyunghyun and Jojic, Nebojsa and Calhoun, Vince and Chung, Junyoung},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4691--4699},
  year={2016}
}

@article{krishnan2017challenges,
  title={On the challenges of learning with inference networks on sparse, high-dimensional data},
  author={Krishnan, Rahul G and Liang, Dawen and Hoffman, Matthew},
  journal={arXiv preprint arXiv:1710.06085},
  year={2017}
}

@article{cremer2018inference,
  title={Inference suboptimality in variational autoencoders},
  author={Cremer, Chris and Li, Xuechen and Duvenaud, David},
  journal={arXiv preprint arXiv:1801.03558},
  year={2018}
}

@inproceedings{marino2018general,
  title={A general method for amortizing variational filtering},
  author={Marino, Joseph and Cvitkovic, Milan and Yue, Yisong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7857--7868},
  year={2018}
}

@article{shu2019training,
  title={Training Variational Autoencoders with Buffered Stochastic Variational Inference},
  author={Shu, Rui and Bui, Hung H and Whang, Jay and Ermon, Stefano},
  journal={arXiv preprint arXiv:1902.10294},
  year={2019}
}

@article{marino2019predictive,
  title={Predictive Coding, Variational Autoencoders, and Biological Connections},
  author={Marino, Joseph},
  year={2019}
}

@article{hausman2018learning,
  title={Learning an embedding space for transferable robot skills},
  author={Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  year={2018}
}

@inproceedings{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2775--2785},
  year={2017}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@article{ranganath2013black,
  title={Black box variational inference},
  author={Ranganath, Rajesh and Gerrish, Sean and Blei, David M},
  journal={arXiv preprint arXiv:1401.0118},
  year={2013}
}

@article{winn2005variational,
  title={Variational message passing},
  author={Winn, John and Bishop, Christopher M},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={661--694},
  year={2005}
}

@book{rubinstein2013cross,
  title={The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation and machine learning},
  author={Rubinstein, Reuven Y and Kroese, Dirk P},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{dempster1977maximum,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={39},
  number={1},
  pages={1--22},
  year={1977},
  publisher={Wiley Online Library}
}

@inproceedings{weiss2000correctness,
  title={Correctness of belief propagation in Gaussian graphical models of arbitrary topology},
  author={Weiss, Yair and Freeman, William T},
  booktitle={Advances in neural information processing systems},
  pages={673--679},
  year={2000}
}

@book{pearl2014probabilistic,
  title={Probabilistic reasoning in intelligent systems: networks of plausible inference},
  author={Pearl, Judea},
  year={2014},
  publisher={Elsevier}
}

@article{yedidia2011message,
  title={Message-passing algorithms for inference and optimization},
  author={Yedidia, Jonathan S},
  journal={Journal of Statistical Physics},
  volume={145},
  number={4},
  pages={860--890},
  year={2011},
  publisher={Springer}
}

@article{kappen2016adaptive,
  title={Adaptive importance sampling for control and inference},
  author={Kappen, Hilbert Johan and Ruiz, Hans Christian},
  journal={Journal of Statistical Physics},
  volume={162},
  number={5},
  pages={1244--1266},
  year={2016},
  publisher={Springer}
}

@article{kutschireiter2020hitchhiker,
  title={The Hitchhiker’s guide to nonlinear filtering},
  author={Kutschireiter, Anna and Surace, Simone Carlo and Pfister, Jean-Pascal},
  journal={Journal of Mathematical Psychology},
  volume={94},
  pages={102307},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{li2004iterative,
  title={Iterative linear quadratic regulator design for nonlinear biological movement systems.},
  author={Li, Weiwei and Todorov, Emanuel},
  booktitle={ICINCO (1)},
  pages={222--229},
  year={2004}
}

@article{okada2020planet,
  title={PlaNet of the Bayesians: Reconsidering and Improving Deep Planning Network by Incorporating Bayesian Inference},
  author={Okada, Masashi and Kosaka, Norio and Taniguchi, Tadahiro},
  journal={arXiv preprint arXiv:2003.00370},
  year={2020}
}

@article{srinivas2018universal,
  title={Universal planning networks},
  author={Srinivas, Aravind and Jabri, Allan and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1804.00645},
  year={2018}
}

@book{lorenz2013foundations,
  title={The foundations of ethology},
  author={Lorenz, Konrad},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{rubinstein1997optimization,
  title={Optimization of computer simulation models with rare events},
  author={Rubinstein, Reuven Y},
  journal={European Journal of Operational Research},
  volume={99},
  number={1},
  pages={89--112},
  year={1997},
  publisher={Elsevier}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{baltieri2019pid,
  title={PID control as a process of active inference with linear generative models},
  author={Baltieri, Manuel and Buckley, Christopher L},
  journal={Entropy},
  volume={21},
  number={3},
  pages={257},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute},
  keywords={continuous},
  url={https://www.mdpi.com/1099-4300/21/3/257}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{auger2005restart,
  title={A restart CMA evolution strategy with increasing population size},
  author={Auger, Anne and Hansen, Nikolaus},
  booktitle={2005 IEEE congress on evolutionary computation},
  volume={2},
  pages={1769--1776},
  year={2005},
  organization={IEEE}
}

@inproceedings{theodorou2010reinforcement,
  title={Reinforcement learning of motor skills in high dimensions: A path integral approach},
  author={Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
  booktitle={2010 IEEE International Conference on Robotics and Automation},
  pages={2397--2403},
  year={2010},
  organization={IEEE}
}

@article{marinodesign,
  title={On the Design of Variational RL Algorithms},
  author={Marino, Joseph and Pich{\'e}, Alexandre and Yue, Yisong},
  year={2019},
}

@article{marinoinference,
  title={An Inference Perspective on Model-Based Reinforcement Learning},
  year={2019},
  author={Marino, Joseph and Yue, Yisong}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{luo2017adaptive,
  title={Adaptive Bidirectional Backpropagation: Towards Biologically Plausible Error Signal Transmission in Neural Networks},
  author={Luo, Hongyin and Fu, Jie and Glass, James},
  journal={arXiv preprint arXiv:1702.07097},
  year={2017}
}

@article{scellier2016towards,
  title={Towards a biologically plausible backprop},
  author={Scellier, Benjamin and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1602.05179},
  volume={914},
  year={2016}
}

@article{betti2018backpropagation,
  title={Backpropagation and Biological Plausibility},
  author={Betti, Alessandro and Gori, Marco and Marra, Giuseppe},
  journal={arXiv preprint arXiv:1808.06934},
  year={2018}
}

@inproceedings{liao2016important,
  title={How important is weight symmetry in backpropagation?},
  author={Liao, Qianli and Leibo, Joel Z and Poggio, Tomaso},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@article{brown2011active,
  title={Active inference, attention, and motor preparation},
  author={Brown, Harriet and Friston, Karl J and Bestmann, Sven},
  journal={Frontiers in psychology},
  volume={2},
  pages={218},
  year={2011},
  publisher={Frontiers}
}

@article{adams2013predictions,
  title={Predictions not commands: active inference in the motor system},
  author={Adams, Rick A and Shipp, Stewart and Friston, Karl J},
  journal={Brain Structure and Function},
  volume={218},
  number={3},
  pages={611--643},
  year={2013},
  publisher={Springer}
}

@article{friston2013anatomy,
  title={The anatomy of choice: active inference and agency},
  author={Friston, Karl and Schwartenbeck, Philipp and FitzGerald, Thomas and Moutoussis, Michael and Behrens, Tim and Dolan, Raymond J},
  journal={Frontiers in human neuroscience},
  volume={7},
  pages={598},
  year={2013},
  publisher={Frontiers}
}

@article{friston2014anatomy,
  title={The anatomy of choice: dopamine and decision-making},
  author={Friston, Karl and Schwartenbeck, Philipp and FitzGerald, Thomas and Moutoussis, Michael and Behrens, Timothy and Dolan, Raymond J},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={369},
  number={1655},
  pages={20130481},
  year={2014},
  publisher={The Royal Society}
}

@article{friston2009predictive,
  title={Predictive coding under the free-energy principle},
  author={Friston, Karl and Kiebel, Stefan},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={364},
  number={1521},
  pages={1211--1221},
  year={2009},
  publisher={The Royal Society London}
}

@article{clark2013whatever,
  title={Whatever next? Predictive brains, situated agents, and the future of cognitive science},
  author={Clark, Andy},
  journal={Behavioral and brain sciences},
  volume={36},
  number={3},
  pages={181--204},
  year={2013},
  publisher={Cambridge University Press},
  keywords={philosophy},
  url={https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/whatever-next-predictive-brains-situated-agents-and-the-future-of-cognitive-science/33542C736E17E3D1D44E8D03BE5F4CD9}
}

@article{clark2012dreaming,
  title={Dreaming the whole cat: Generative models, predictive processing, and the enactivist conception of perceptual experience},
  author={Clark, Andy},
  journal={Mind},
  volume={121},
  number={483},
  pages={753--771},
  year={2012},
  publisher={Mind Association}
}

@book{clark2015surfing,
  title={Surfing uncertainty: Prediction, action, and the embodied mind},
  author={Clark, Andy},
  year={2015},
  publisher={Oxford University Press},
  keywords={classic},
  url={https://books.google.co.uk/books?hl=en&lr=&id=TnqECgAAQBAJ&oi=fnd&pg=PP1&dq=andy+clark+surfing+uncertainty&ots=aurm4jE3NO&sig=KxeHGJ6YJJdN9tKyr6snwDyBBKg&redir_esc=y#v=onepage&q=andy%20clark%20surfing%20uncertainty&f=false}
}

@article{friston2012history,
  title={The history of the future of the Bayesian brain},
  author={Friston, Karl},
  journal={NeuroImage},
  volume={62},
  number={2},
  pages={1230--1233},
  year={2012},
  publisher={Elsevier},
  keywords={classic},
  url={https://www.sciencedirect.com/science/article/pii/S1053811911011657}
}

@article{barrett2016active,
  title={An active inference theory of allostasis and interoception in depression},
  author={Barrett, Lisa Feldman and Quigley, Karen S and Hamilton, Paul},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={371},
  number={1708},
  pages={20160011},
  year={2016},
  publisher={The Royal Society}
}
@article{adams2012smooth,
  title={Smooth pursuit and visual occlusion: active inference and oculomotor control in schizophrenia},
  author={Adams, Rick A and Perrinet, Laurent U and Friston, Karl},
  journal={PloS one},
  volume={7},
  number={10},
  pages={e47502},
  year={2012},
  publisher={Public Library of Science}
}

@article{parr2018generalised,
  title={Generalised free energy and active inference: can the future cause the past?},
  author={Parr, Thomas and Friston, Karl J},
  journal={BioRxiv},
  pages={304782},
  year={2018},
  publisher={Cold Spring Harbor Laboratory}
}

@article{lazaro2003new,
  title={A new EM-based training algorithm for RBF networks},
  author={L{\'a}zaro, Marcelino and Santamar{\i}a, Ignacio and Pantale{\'o}n, Carlos},
  journal={Neural Networks},
  volume={16},
  number={1},
  pages={69--77},
  year={2003},
  publisher={Elsevier}
}

@article{sum1999kalman,
  title={On the Kalman filtering method in neural network training and pruning},
  author={Sum, John and Leung, Chi-Sing and Young, Gilbert H and Kan, Wing-Kay},
  journal={IEEE Transactions on Neural Networks},
  volume={10},
  number={1},
  pages={161--166},
  year={1999},
  publisher={IEEE}
}

@book{haykin2004kalman,
  title={Kalman filtering and neural networks},
  author={Haykin, Simon},
  volume={47},
  year={2004},
  publisher={John Wiley \& Sons}
}

@article{ng2004using,
  title={Using the EM algorithm to train neural networks: misconceptions and a new algorithm for multiclass classification},
  author={Ng, Shu-Kay and McLachlan, Geoffrey J},
  journal={IEEE transactions on neural networks},
  volume={15},
  number={3},
  pages={738--749},
  year={2004},
  publisher={IEEE}
}

@article{ma1998fast,
  title={Fast training of recurrent networks based on the EM algorithm},
  author={Ma, Sheng and Ji, Chuanyi},
  journal={IEEE Transactions on Neural Networks},
  volume={9},
  number={1},
  pages={11--26},
  year={1998},
  publisher={IEEE}
}

@article{friston2007free,
  title={Free-energy and the brain},
  author={Friston, Karl J and Stephan, Klaas E},
  journal={Synthese},
  volume={159},
  number={3},
  pages={417--458},
  year={2007},
  publisher={Springer}
}

@article{friston2009free,
  title={The free-energy principle: a rough guide to the brain?},
  author={Friston, Karl},
  journal={Trends in cognitive sciences},
  volume={13},
  number={7},
  pages={293--301},
  year={2009},
  publisher={Elsevier}
}

@article{bogacz2017tutorial,
  title={A tutorial on the free-energy framework for modelling perception and learning},
  author={Bogacz, Rafal},
  journal={Journal of mathematical psychology},
  volume={76},
  pages={198--211},
  year={2017},
  publisher={Elsevier},
  keywords={survey},
  url={https://www.sciencedirect.com/science/article/pii/S0022249615000759}
}

@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{doersch2016tutorial,
  title={Tutorial on variational autoencoders},
  author={Doersch, Carl},
  journal={arXiv preprint arXiv:1606.05908},
  year={2016}
}

@inproceedings{cesa2017boltzmann,
  title={Boltzmann exploration done right},
  author={Cesa-Bianchi, Nicol{\`o} and Gentile, Claudio and Lugosi, G{\'a}bor and Neu, Gergely},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6284--6293},
  year={2017}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@phdthesis{haarnoja2018acquiring,
  title={Acquiring Diverse Robot Skills via Maximum Entropy Deep Reinforcement Learning},
  author={Haarnoja, Tuomas},
  year={2018},
  school={UC Berkeley}
}

@article{fellows2018virel,
  title={VIREL: A Variational Inference Framework for Reinforcement Learning},
  author={Fellows, Matthew and Mahajan, Anuj and Rudner, Tim GJ and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1811.01132},
  year={2018}
}

@article{song2015off,
  title={Off-policy actor-critic structure for optimal control of unknown systems with disturbances},
  author={Song, Ruizhuo and Lewis, Frank L and Wei, Qinglai and Zhang, Huaguang},
  journal={IEEE Transactions on Cybernetics},
  volume={46},
  number={5},
  pages={1041--1050},
  year={2015},
  publisher={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{asadi2017mean,
  title={Mean actor critic},
  author={Asadi, Kavosh and Allen, Cameron and Roderick, Melrose and Mohamed, Abdel-rahman and Konidaris, George and Littman, Michael and Amazon, Brown University},
  journal={stat},
  volume={1050},
  pages={1},
  year={2017}
}

@inproceedings{ciosek2018expected,
  title={Expected policy gradients},
  author={Ciosek, Kamil and Whiteson, Shimon},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{catal2019bayesian,
  title={Bayesian policy selection using active inference},
  author={Catal, Ozan and Nauta, Johannes and Verbelen, Tim and Simoens, Pieter and Dhoedt, Bart},
  journal={arXiv preprint arXiv:1904.08149},
  year={2019}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{wayne2018unsupervised,
  title={Unsupervised predictive memory in a goal-directed agent},
  author={Wayne, Greg and Hung, Chia-Chun and Amos, David and Mirza, Mehdi and Ahuja, Arun and Grabska-Barwinska, Agnieszka and Rae, Jack and Mirowski, Piotr and Leibo, Joel Z and Santoro, Adam and others},
  journal={arXiv preprint arXiv:1803.10760},
  year={2018}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

@article{houthooft2016curiosity,
  title={Curiosity-driven exploration in deep reinforcement learning via bayesian neural networks},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1605.09674},
  year={2016}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@article{moulin2015active,
  title={An active inference and epistemic value view of metacognition},
  author={Moulin, Chris and Souchay, Celine},
  journal={Cognitive neuroscience},
  volume={6},
  number={4},
  pages={221--222},
  year={2015},
  publisher={Taylor \& Francis}
}

@article{parr2018anatomy,
  title={The anatomy of inference: Generative models and brain structure},
  author={Parr, Thomas and Friston, Karl J},
  journal={Frontiers in computational neuroscience},
  volume={12},
  year={2018},
  publisher={Frontiers Media SA}
}

@article{smith2019active,
  title={An active inference approach to modeling concept learning},
  author={Smith, Ryan and Schwartenbeck, Philipp and Parr, Thomas and Friston, Karl J},
  journal={bioRxiv},
  pages={633677},
  year={2019},
  publisher={Cold Spring Harbor Laboratory}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{gershman2018deconstructing,
  title={Deconstructing the human algorithms for exploration},
  author={Gershman, Samuel J},
  journal={Cognition},
  volume={173},
  pages={34--42},
  year={2018},
  publisher={Elsevier}
}

@article{gershman2018uncertainty,
  title={Uncertainty and exploration},
  author={Gershman, Samuel J},
  journal={bioRxiv},
  pages={265504},
  year={2018},
  publisher={Cold Spring Harbor Laboratory}
}

@article{feldman2010attention,
  title={Attention, uncertainty, and free-energy},
  author={Feldman, Harriet and Friston, Karl},
  journal={Frontiers in human neuroscience},
  volume={4},
  pages={215},
  year={2010},
  publisher={Frontiers},
  keywords={classic},
  url={https://www.frontiersin.org/articles/10.3389/fnhum.2010.00215/full}
}

@article{daw2006cortical,
  title={Cortical substrates for exploratory decisions in humans},
  author={Daw, Nathaniel D and O'doherty, John P and Dayan, Peter and Seymour, Ben and Dolan, Raymond J},
  journal={Nature},
  volume={441},
  number={7095},
  pages={876--879},
  year={2006},
  publisher={Nature Publishing Group}
}

@article{whittington2019theories,
  title={Theories of error back-propagation in the brain},
  author={Whittington, James CR and Bogacz, Rafal},
  journal={Trends in cognitive sciences},
  year={2019},
  publisher={Elsevier}
}

@article{friston2019free,
  title={A free energy principle for a particular physics},
  author={Friston, Karl},
  journal={arXiv preprint arXiv:1906.10184},
  year={2019},
  keywords={classic},
  url={https://arxiv.org/pdf/1906.10184.pdf},
}

@inproceedings{itti2006bayesian,
  title={Bayesian surprise attracts human attention},
  author={Itti, Laurent and Baldi, Pierre F},
  booktitle={Advances in neural information processing systems},
  pages={547--554},
  year={2006}
}

@article{lillicrap2014random,
  title={Random feedback weights support learning in deep neural networks},
  author={Lillicrap, Timothy P and Cownden, Daniel and Tweed, Douglas B and Akerman, Colin J},
  journal={arXiv preprint arXiv:1411.0247},
  year={2014}
}

@article{lillicrap2016random,
  title={Random synaptic feedback weights support error backpropagation for deep learning},
  author={Lillicrap, Timothy P and Cownden, Daniel and Tweed, Douglas B and Akerman, Colin J},
  journal={Nature communications},
  volume={7},
  number={1},
  pages={1--10},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{nokland2016direct,
  title={Direct feedback alignment provides learning in deep neural networks},
  author={N{\o}kland, Arild},
  booktitle={Advances in neural information processing systems},
  pages={1037--1045},
  year={2016}
}

@article{ororbia2020continual,
  title={Continual learning of recurrent neural networks by locally aligning distributed representations},
  author={Ororbia, Alexander and Mali, Ankur and Giles, C Lee and Kifer, Daniel},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2020},
  publisher={IEEE}
}

@inproceedings{ororbia2019biologically,
  title={Biologically motivated algorithms for propagating local target representations},
  author={Ororbia, Alexander G and Mali, Ankur},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={4651--4658},
  year={2019}
}

@inproceedings{balduzzi2015kickback,
  title={Kickback cuts backprop's red-tape: biologically plausible credit assignment in neural networks},
  author={Balduzzi, David and Vanchinathan, Hastagiri and Buhmann, Joachim},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}

@inproceedings{lee2015difference,
  title={Difference target propagation},
  author={Lee, Dong-Hyun and Zhang, Saizheng and Fischer, Asja and Bengio, Yoshua},
  booktitle={Joint european conference on machine learning and knowledge discovery in databases},
  pages={498--515},
  year={2015},
  organization={Springer}
}

@article{zenke2018superspike,
  title={Superspike: Supervised learning in multilayer spiking neural networks},
  author={Zenke, Friedemann and Ganguli, Surya},
  journal={Neural computation},
  volume={30},
  number={6},
  pages={1514--1541},
  year={2018},
  publisher={MIT Press}
}

@article{mostafa2018deep,
  title={Deep supervised learning using local errors},
  author={Mostafa, Hesham and Ramesh, Vishwajith and Cauwenberghs, Gert},
  journal={Frontiers in neuroscience},
  volume={12},
  pages={608},
  year={2018},
  publisher={Frontiers}
}

@article{scellier2018generalization,
  title={Generalization of equilibrium propagation to vector field dynamics},
  author={Scellier, Benjamin and Goyal, Anirudh and Binas, Jonathan and Mesnard, Thomas and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1808.04873},
  year={2018}
}

@article{scellier2018extending,
  title={Extending the framework of equilibrium propagation to general dynamics},
  author={Scellier, Benjamin and Goyal, Anirudh and Binas, Jonathan and Mesnard, Thomas and Bengio, Yoshua},
  year={2018}
}

@article{bengio2015early,
  title={Early inference in energy-based models approximates back-propagation},
  author={Bengio, Yoshua and Fischer, Asja},
  journal={arXiv preprint arXiv:1510.02777},
  year={2015}
}

@article{baldi2016theory,
  title={A theory of local learning, the learning channel, and the optimality of backpropagation},
  author={Baldi, Pierre and Sadowski, Peter},
  journal={Neural Networks},
  volume={83},
  pages={51--74},
  year={2016},
  publisher={Elsevier}
}

@article{sporea2013supervised,
  title={Supervised learning in multilayer spiking neural networks},
  author={Sporea, Ioana and Gr{\"u}ning, Andr{\'e}},
  journal={Neural computation},
  volume={25},
  number={2},
  pages={473--509},
  year={2013},
  publisher={MIT Press}
}

@article{schiess2016somato,
  title={Somato-dendritic synaptic plasticity and error-backpropagation in active dendrites},
  author={Schiess, Mathieu and Urbanczik, Robert and Senn, Walter},
  journal={PLoS computational biology},
  volume={12},
  number={2},
  year={2016},
  publisher={Public Library of Science}
}

@inproceedings{sacramento2018dendritic,
  title={Dendritic cortical microcircuits approximate the backpropagation algorithm},
  author={Sacramento, Jo{\~a}o and Costa, Rui Ponte and Bengio, Yoshua and Senn, Walter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8721--8732},
  year={2018}
}

@article{bengio2017stdp,
  title={STDP-compatible approximation of backpropagation in an energy-based model},
  author={Bengio, Yoshua and Mesnard, Thomas and Fischer, Asja and Zhang, Saizheng and Wu, Yuhuai},
  journal={Neural computation},
  volume={29},
  number={3},
  pages={555--577},
  year={2017},
  publisher={MIT Press}
}

@article{o1996biologically,
  title={Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm},
  author={O'Reilly, Randall C},
  journal={Neural computation},
  volume={8},
  number={5},
  pages={895--938},
  year={1996},
  publisher={MIT Press}
}

@article{guerguiev2017towards,
  title={Towards deep learning with segregated dendrites},
  author={Guerguiev, Jordan and Lillicrap, Timothy P and Richards, Blake A},
  journal={Elife},
  volume={6},
  pages={e22901},
  year={2017},
  publisher={eLife Sciences Publications Limited}
}

@article{marblestone2016toward,
  title={Toward an integration of deep learning and neuroscience},
  author={Marblestone, Adam H and Wayne, Greg and Kording, Konrad P},
  journal={Frontiers in computational neuroscience},
  volume={10},
  pages={94},
  year={2016},
  publisher={Frontiers}
}

@article{hassabis2017neuroscience,
  title={Neuroscience-inspired artificial intelligence},
  author={Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
  journal={Neuron},
  volume={95},
  number={2},
  pages={245--258},
  year={2017},
  publisher={Elsevier}
}

@book{hawkins2007intelligence,
  title={On intelligence: How a new understanding of the brain will lead to the creation of truly intelligent machines},
  author={Hawkins, Jeff and Blakeslee, Sandra},
  year={2007},
  publisher={Macmillan}
}

@article{george2009towards,
  title={Towards a mathematical theory of cortical micro-circuits},
  author={George, Dileep and Hawkins, Jeff},
  journal={PLoS computational biology},
  volume={5},
  number={10},
  year={2009},
  publisher={Public Library of Science}
}

@inproceedings{han2018deep,
  title={Deep predictive coding network with local recurrent processing for object recognition},
  author={Han, Kuan and Wen, Haiguang and Zhang, Yizhen and Fu, Di and Culurciello, Eugenio and Liu, Zhongming},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9201--9213},
  year={2018}
}

@article{wen2018deep,
  title={Deep predictive coding network for object recognition},
  author={Wen, Haiguang and Han, Kuan and Shi, Junxing and Zhang, Yizhen and Culurciello, Eugenio and Liu, Zhongming},
  journal={arXiv preprint arXiv:1802.04762},
  year={2018}
}

@article{chalasani2013deep,
  title={Deep predictive coding networks},
  author={Chalasani, Rakesh and Principe, Jose C},
  journal={arXiv preprint arXiv:1301.3541},
  year={2013}
}

@article{lotter2016deep,
  title={Deep predictive coding networks for video prediction and unsupervised learning},
  author={Lotter, William and Kreiman, Gabriel and Cox, David},
  journal={arXiv preprint arXiv:1605.08104},
  year={2016}
}

@article{o2017deep,
  title={Deep predictive learning: a comprehensive model of three visual streams},
  author={O'Reilly, Randall C and Wyatte, Dean R and Rohrlich, John},
  journal={arXiv preprint arXiv:1709.04654},
  year={2017}
}

@article{shipp2013reflections,
  title={Reflections on agranular architecture: predictive coding in the motor cortex},
  author={Shipp, Stewart and Adams, Rick A and Friston, Karl J},
  journal={Trends in neurosciences},
  volume={36},
  number={12},
  pages={706--716},
  year={2013},
  publisher={Elsevier}
}

@article{mazzoni1991more,
  title={A more biologically plausible learning rule for neural networks.},
  author={Mazzoni, Pietro and Andersen, Richard A and Jordan, Michael I},
  journal={Proceedings of the National Academy of Sciences},
  volume={88},
  number={10},
  pages={4433--4437},
  year={1991},
  publisher={National Acad Sciences}
}

@article{amit2019deep,
  title={Deep learning with asymmetric connections and Hebbian updates},
  author={Amit, Yali},
  journal={Frontiers in computational neuroscience},
  volume={13},
  pages={18},
  year={2019},
  publisher={Frontiers}
}

@article{crick1989recent,
  title={The recent excitement about neural networks},
  author={Crick, Francis},
  journal={Nature},
  volume={337},
  number={6203},
  pages={129--132},
  year={1989},
  publisher={Springer}
}

@article{rumelhart1985feature,
  title={Feature discovery by competitive learning},
  author={Rumelhart, David E and Zipser, David},
  journal={Cognitive science},
  volume={9},
  number={1},
  pages={75--112},
  year={1985},
  publisher={Wiley Online Library}
}

@incollection{werbos1982applications,
  title={Applications of advances in nonlinear sensitivity analysis},
  author={Werbos, Paul J},
  booktitle={System modeling and optimization},
  pages={762--770},
  year={1982},
  publisher={Springer}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{griewank1989automatic,
  title={On automatic differentiation},
  author={Griewank, Andreas and others},
  journal={Mathematical Programming: recent developments and applications},
  volume={6},
  number={6},
  pages={83--107},
  year={1989},
  publisher={Amsterdam}
}

@article{baydin2017automatic,
  title={Automatic differentiation in machine learning: a survey},
  author={Baydin, At{\i}l{\i}m G{\"u}nes and Pearlmutter, Barak A and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={5595--5637},
  year={2017},
  publisher={JMLR. org}
}

@article{elliott2017compiling,
  title={Compiling to categories},
  author={Elliott, Conal},
  journal={Proceedings of the ACM on Programming Languages},
  volume={1},
  number={ICFP},
  pages={1--27},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{revels2016forward,
  title={Forward-mode automatic differentiation in Julia},
  author={Revels, Jarrett and Lubin, Miles and Papamarkou, Theodore},
  journal={arXiv preprint arXiv:1607.07892},
  year={2016}
}

@article{innes2019zygote,
  title={Zygote: A differentiable programming system to bridge machine learning and scientific computing},
  author={Innes, Mike and Edelman, Alan and Fischer, Keno and Rackauckus, Chris and Saba, Elliot and Shah, Viral B and Tebbutt, Will},
  journal={arXiv preprint arXiv:1907.07587},
  year={2019}
}

@inproceedings{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle={Advances in neural information processing systems},
  pages={6571--6583},
  year={2018}
}

@article{tzen2019neural,
  title={Neural stochastic differential equations: Deep latent gaussian models in the diffusion limit},
  author={Tzen, Belinda and Raginsky, Maxim},
  journal={arXiv preprint arXiv:1905.09883},
  year={2019}
}

@article{rackauckas2019diffeqflux,
  title={Diffeqflux. jl-A julia library for neural differential equations},
  author={Rackauckas, Chris and Innes, Mike and Ma, Yingbo and Bettencourt, Jesse and White, Lyndon and Dixit, Vaibhav},
  journal={arXiv preprint arXiv:1902.02376},
  year={2019}
}

@article{degrave2019differentiable,
  title={A differentiable physics engine for deep learning in robotics},
  author={Degrave, Jonas and Hermans, Michiel and Dambre, Joni and Wyffels, Francis},
  journal={Frontiers in neurorobotics},
  volume={13},
  pages={6},
  year={2019},
  publisher={Frontiers}
}

@inproceedings{heiden2019real2sim,
  title={Real2sim transfer using differentiable physics},
  author={Heiden, Eric and Millard, David and Sukhatme, Gaurav},
  booktitle={Workshop on Closing the Reality Gap in Sim2real Transfer for Robotic Manipulation},
  year={2019}
}

@article{pal2019raytracer,
  title={RayTracer. jl: A Differentiable Renderer that supports Parameter Optimization for Scene Reconstruction},
  author={Pal, Avik},
  journal={arXiv preprint arXiv:1907.07198},
  year={2019}
}

@article{amos2019differentiable,
  title={The Differentiable Cross-Entropy Method},
  author={Amos, Brandon and Yarats, Denis},
  journal={arXiv preprint arXiv:1909.12830},
  year={2019}
}

@article{okada2017path,
  title={Path integral networks: End-to-end differentiable optimal control},
  author={Okada, Masashi and Rigazio, Luca and Aoshima, Takenobu},
  journal={arXiv preprint arXiv:1706.09597},
  year={2017}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{paszke2017automatic,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{auksztulewicz2016repetition,
  title={Repetition suppression and its contextual determinants in predictive coding},
  author={Auksztulewicz, Ryszard and Friston, Karl},
  journal={cortex},
  volume={80},
  pages={125--140},
  year={2016},
  publisher={Elsevier}
}

@article{weilnhammer2017predictive,
  title={A predictive coding account of bistable perception-a model-based fMRI study},
  author={Weilnhammer, Veith and Stuke, Heiner and Hesselmann, Guido and Sterzer, Philipp and Schmack, Katharina},
  journal={PLoS computational biology},
  volume={13},
  number={5},
  pages={e1005536},
  year={2017},
  publisher={Public Library of Science}
}

@article{watanabe2018illusory,
  title={Illusory motion reproduced by deep neural networks trained for prediction},
  author={Watanabe, Eiji and Kitaoka, Akiyoshi and Sakamoto, Kiwako and Yasugi, Masaki and Tanaka, Kenta},
  journal={Frontiers in psychology},
  volume={9},
  pages={345},
  year={2018},
  publisher={Frontiers}
}

@article{hohwy2008predictive,
  title={Predictive coding explains binocular rivalry: An epistemological review},
  author={Hohwy, Jakob and Roepstorff, Andreas and Friston, Karl},
  journal={Cognition},
  volume={108},
  number={3},
  pages={687--701},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{akrout2019deep,
  title={Deep learning without weight transport},
  author={Akrout, Mohamed and Wilson, Collin and Humphreys, Peter and Lillicrap, Timothy and Tweed, Douglas B},
  booktitle={Advances in Neural Information Processing Systems},
  pages={974--982},
  year={2019}
}

@article{scellier2017equilibrium,
  title={Equilibrium propagation: Bridging the gap between energy-based models and backpropagation},
  author={Scellier, Benjamin and Bengio, Yoshua},
  journal={Frontiers in computational neuroscience},
  volume={11},
  pages={24},
  year={2017},
  publisher={Frontiers}
}

@article{lillicrap2020backpropagation,
  title={Backpropagation and the brain},
  author={Lillicrap, Timothy P and Santoro, Adam and Marris, Luke and Akerman, Colin J and Hinton, Geoffrey},
  journal={Nature Reviews Neuroscience},
  pages={1--12},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{tallec2017unbiased,
  title={Unbiased online recurrent optimization},
  author={Tallec, Corentin and Ollivier, Yann},
  journal={arXiv preprint arXiv:1702.05043},
  year={2017}
}

@article{ollivier2015training,
  title={Training recurrent networks online without backtracking},
  author={Ollivier, Yann and Tallec, Corentin and Charpiat, Guillaume},
  journal={arXiv preprint arXiv:1507.07680},
  year={2015}
}

@inproceedings{steil2004backpropagation,
  title={Backpropagation-decorrelation: online recurrent learning with O (N) complexity},
  author={Steil, Jochen J},
  booktitle={2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No. 04CH37541)},
  volume={2},
  pages={843--848},
  year={2004},
  organization={IEEE}
}

@article{williams1989learning,
  title={A learning algorithm for continually running fully recurrent neural networks},
  author={Williams, Ronald J and Zipser, David},
  journal={Neural computation},
  volume={1},
  number={2},
  pages={270--280},
  year={1989},
  publisher={MIT Press}
}

@article{lillicrap2019backpropagation,
  title={Backpropagation through time and the brain},
  author={Lillicrap, Timothy P and Santoro, Adam},
  journal={Current opinion in neurobiology},
  volume={55},
  pages={82--89},
  year={2019},
  publisher={Elsevier}
}

@article{bullier2001integrated,
  title={Integrated model of visual processing},
  author={Bullier, Jean},
  journal={Brain research reviews},
  volume={36},
  number={2-3},
  pages={96--107},
  year={2001},
  publisher={Elsevier}
}

@article{hung2005fast,
  title={Fast readout of object identity from macaque inferior temporal cortex},
  author={Hung, Chou P and Kreiman, Gabriel and Poggio, Tomaso and DiCarlo, James J},
  journal={Science},
  volume={310},
  number={5749},
  pages={863--866},
  year={2005},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{yamins2014performance,
  title={Performance-optimized hierarchical models predict neural responses in higher visual cortex},
  author={Yamins, Daniel LK and Hong, Ha and Cadieu, Charles F and Solomon, Ethan A and Seibert, Darren and DiCarlo, James J},
  journal={Proceedings of the National Academy of Sciences},
  volume={111},
  number={23},
  pages={8619--8624},
  year={2014},
  publisher={National Acad Sciences}
}

@article{tacchetti2017invariant,
  title={Invariant recognition drives neural representations of action sequences},
  author={Tacchetti, Andrea and Isik, Leyla and Poggio, Tomaso},
  journal={PLoS computational biology},
  volume={13},
  number={12},
  pages={e1005859},
  year={2017},
  publisher={Public Library of Science}
}

@article{eickenberg2017seeing,
  title={Seeing it all: Convolutional network layers map the function of the human visual system},
  author={Eickenberg, Michael and Gramfort, Alexandre and Varoquaux, Ga{\"e}l and Thirion, Bertrand},
  journal={NeuroImage},
  volume={152},
  pages={184--194},
  year={2017},
  publisher={Elsevier}
}

@article{khaligh2014deep,
  title={Deep supervised, but not unsupervised, models may explain IT cortical representation},
  author={Khaligh-Razavi, Seyed-Mahdi and Kriegeskorte, Nikolaus},
  journal={PLoS computational biology},
  volume={10},
  number={11},
  year={2014},
  publisher={Public Library of Science}
}

@article{lindsay2020convolutional,
  title={Convolutional neural networks as a model of the visual system: past, present, and future},
  author={Lindsay, Grace},
  journal={Journal of Cognitive Neuroscience},
  pages={1--15},
  year={2020},
  publisher={MIT Press}
}

@article{merolla2014million,
  title={A million spiking-neuron integrated circuit with a scalable communication network and interface},
  author={Merolla, Paul A and Arthur, John V and Alvarez-Icaza, Rodrigo and Cassidy, Andrew S and Sawada, Jun and Akopyan, Filipp and Jackson, Bryan L and Imam, Nabil and Guo, Chen and Nakamura, Yutaka and others},
  journal={Science},
  volume={345},
  number={6197},
  pages={668--673},
  year={2014},
  publisher={American Association for the Advancement of Science}
}

@article{furber2014spinnaker,
  title={The spinnaker project},
  author={Furber, Steve B and Galluppi, Francesco and Temple, Steve and Plana, Luis A},
  journal={Proceedings of the IEEE},
  volume={102},
  number={5},
  pages={652--665},
  year={2014},
  publisher={IEEE}
}

@article{davies2018loihi,
  title={Loihi: A neuromorphic manycore processor with on-chip learning},
  author={Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain, Shweta and others},
  journal={IEEE Micro},
  volume={38},
  number={1},
  pages={82--99},
  year={2018},
  publisher={IEEE}
}

@article{ruck1992comparative,
  title={Comparative analysis of backpropagation and the extended Kalman filter for training multilayer perceptrons},
  author={Ruck, Dennis W. and Rogers, Steven K. and Kabrisky, Matthew and Maybeck, Peter S. and Oxley, Mark E.},
  journal={IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  number={6},
  pages={686--691},
  year={1992},
  publisher={IEEE}
}

@article{ollivier2019extended,
  title={The Extended Kalman Filter is a Natural Gradient Descent in Trajectory Space},
  author={Ollivier, Yann},
  journal={arXiv preprint arXiv:1901.00696},
  year={2019}
}

@article{mandt2017stochastic,
  title={Stochastic gradient descent as approximate bayesian inference},
  author={Mandt, Stephan and Hoffman, Matthew D and Blei, David M},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={4873--4907},
  year={2017},
  publisher={JMLR. org}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  pages={2672--2680},
  year={2014}
}

@article{salimans2017pixelcnn++,
  title={Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications},
  author={Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik P},
  journal={arXiv preprint arXiv:1701.05517},
  year={2017}
}

@article{jing2019neural,
  title={Neural style transfer: A review},
  author={Jing, Yongcheng and Yang, Yezhou and Feng, Zunlei and Ye, Jingwen and Yu, Yizhou and Song, Mingli},
  journal={IEEE transactions on visualization and computer graphics},
  year={2019},
  publisher={IEEE}
}

@article{oord2016wavenet,
  title={Wavenet: A generative model for raw audio},
  author={Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1609.03499},
  year={2016}
}

@article{dhariwal2020jukebox,
  title={Jukebox: A generative model for music},
  author={Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2005.00341},
  year={2020}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International Conference on Machine Learning},
  pages={2555--2565},
  year={2019}
}

@article{meulemans2020theoretical,
  title={A Theoretical Framework for Target Propagation},
  author={Meulemans, Alexander and Carzaniga, Francesco S and Suykens, Johan AK and Sacramento, Jo{\~a}o and Grewe, Benjamin F},
  journal={arXiv preprint arXiv:2006.14331},
  year={2020}
}

@article{linnainmaa1970representation,
  title={The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors},
  author={Linnainmaa, Seppo},
  journal={Master's Thesis (in Finnish), Univ. Helsinki},
  pages={6--7},
  year={1970}
}

@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}

@article{xie2003equivalence,
  title={Equivalence of backpropagation and contrastive Hebbian learning in a layered network},
  author={Xie, Xiaohui and Seung, H Sebastian},
  journal={Neural computation},
  volume={15},
  number={2},
  pages={441--454},
  year={2003},
  publisher={MIT Press}
}

@article{mesnard2019ghost,
  title={Ghost Units Yield Biologically Plausible Backprop in Deep Neural Networks},
  author={Mesnard, Thomas and Vignoud, Ga{\"e}tan and Sacramento, Joao and Senn, Walter and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1911.08585},
  year={2019}
}

@article{urbanczik2014learning,
  title={Learning by the dendritic prediction of somatic spiking},
  author={Urbanczik, Robert and Senn, Walter},
  journal={Neuron},
  volume={81},
  number={3},
  pages={521--528},
  year={2014},
  publisher={Elsevier}
}

@article{rockland1989terminal,
  title={Terminal arbors of individual “Feedback” axons projecting from area V2 to V1 in the macaque monkey: a study using immunohistochemistry of anterogradely transported Phaseolus vulgaris-leucoagglutinin},
  author={Rockland, Kathleen S and Virga, Agnes},
  journal={Journal of Comparative Neurology},
  volume={285},
  number={1},
  pages={54--72},
  year={1989},
  publisher={Wiley Online Library}
}

@article{ohno2012morphological,
  title={A morphological analysis of thalamocortical axon fibers of rat posterior thalamic nuclei: a single neuron tracing study with viral vectors},
  author={Ohno, Sachi and Kuramoto, Eriko and Furuta, Takahiro and Hioki, Hiroyuki and Tanaka, Yasuhiro R and Fujiyama, Fumino and Sonomura, Takahiro and Uemura, Masanori and Sugiyama, Kazuna and Kaneko, Takeshi},
  journal={Cerebral cortex},
  volume={22},
  number={12},
  pages={2840--2857},
  year={2012},
  publisher={Oxford University Press}
}

@article{megias2001total,
  title={Total number and distribution of inhibitory and excitatory synapses on hippocampal CA1 pyramidal cells},
  author={Meg{\i}as, M and Emri, ZS and Freund, TF and Gulyas, AI},
  journal={Neuroscience},
  volume={102},
  number={3},
  pages={527--540},
  year={2001},
  publisher={Elsevier}
}

@article{larkum2007dendritic,
  title={Dendritic spikes in apical dendrites of neocortical layer 2/3 pyramidal neurons},
  author={Larkum, Matthew Evan and Waters, Jack and Sakmann, Bert and Helmchen, Fritjof},
  journal={Journal of Neuroscience},
  volume={27},
  number={34},
  pages={8999--9008},
  year={2007},
  publisher={Soc Neuroscience}
}

@article{larkum2013cellular,
  title={A cellular mechanism for cortical associations: an organizing principle for the cerebral cortex},
  author={Larkum, Matthew},
  journal={Trends in neurosciences},
  volume={36},
  number={3},
  pages={141--151},
  year={2013},
  publisher={Elsevier}
}

@article{kording2001supervised,
  title={Supervised and unsupervised learning with two sites of synaptic integration},
  author={K{\"o}rding, Konrad P and K{\"o}nig, Peter},
  journal={Journal of computational neuroscience},
  volume={11},
  number={3},
  pages={207--215},
  year={2001},
  publisher={Springer}
}

@book{martens2016second,
  title={Second-order optimization for neural networks},
  author={Martens, James},
  year={2016},
  publisher={University of Toronto (Canada)}
}

@book{buzsaki2006rhythms,
  title={Rhythms of the Brain},
  author={Buzsaki, Gyorgy},
  year={2006},
  publisher={Oxford University Press}
}

@article{cadieu2014deep,
  title={Deep neural networks rival the representation of primate IT cortex for core visual object recognition},
  author={Cadieu, Charles F and Hong, Ha and Yamins, Daniel LK and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan A and Majaj, Najib J and DiCarlo, James J},
  journal={PLoS Comput Biol},
  volume={10},
  number={12},
  pages={e1003963},
  year={2014},
  publisher={Public Library of Science}
}

@article{kriegeskorte2015deep,
  title={Deep neural networks: a new framework for modeling biological vision and brain information processing},
  author={Kriegeskorte, Nikolaus},
  journal={Annual review of vision science},
  volume={1},
  pages={417--446},
  year={2015},
  publisher={Annual Reviews}
}

@article{xiao2017online,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  date         = {2017-08-28},
  year         = {2017},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  eprint       = {cs.LG/1708.07747},
}

@inproceedings{van2018automatic,
  title={Automatic differentiation in ML: Where we are and where we should be going},
  author={Van Merri{\"e}nboer, Bart and Breuleux, Olivier and Bergeron, Arnaud and Lamblin, Pascal},
  booktitle={Advances in neural information processing systems},
  pages={8757--8767},
  year={2018}
}

@article{margossian2019review,
  title={A review of automatic differentiation and its efficient implementation},
  author={Margossian, Charles C},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={9},
  number={4},
  pages={e1305},
  year={2019},
  publisher={Wiley Online Library}
}

@article{schultz2000neuronal,
  title={Neuronal coding of prediction errors},
  author={Schultz, Wolfram and Dickinson, Anthony},
  journal={Annual review of neuroscience},
  volume={23},
  number={1},
  pages={473--500},
  year={2000},
  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}
}

@article{bayer2005midbrain,
  title={Midbrain dopamine neurons encode a quantitative reward prediction error signal},
  author={Bayer, Hannah M and Glimcher, Paul W},
  journal={Neuron},
  volume={47},
  number={1},
  pages={129--141},
  year={2005},
  publisher={Elsevier}
}

@article{glimcher2011understanding,
  title={Understanding dopamine and reinforcement learning: the dopamine reward prediction error hypothesis},
  author={Glimcher, Paul W},
  journal={Proceedings of the National Academy of Sciences},
  volume={108},
  number={Supplement 3},
  pages={15647--15654},
  year={2011},
  publisher={National Acad Sciences}
}

@article{schultz1998predictive,
  title={Predictive reward signal of dopamine neurons},
  author={Schultz, Wolfram},
  journal={Journal of neurophysiology},
  volume={80},
  number={1},
  pages={1--27},
  year={1998},
  publisher={American Physiological Society Bethesda, MD}
}

@article{ororbia2020reducing,
  title={Reducing the Computational Burden of Deep Learning with Recursive Local Representation Alignment},
  author={Ororbia, Alexander and Mali, Ankur and Kifer, Daniel and Giles, C Lee},
  journal={arXiv preprint arXiv:2002.03911},
  year={2020}
}

@article{ororbia2018conducting,
  title={Conducting credit assignment by aligning local representations},
  author={Ororbia, Alexander G and Mali, Ankur and Kifer, Daniel and Giles, C Lee},
  journal={arXiv preprint arXiv:1803.01834},
  year={2018}
}

@article{ororbia2017learning,
  title={Learning to adapt by minimizing discrepancy},
  author={Ororbia II, Alexander G and Haffner, Patrick and Reitter, David and Giles, C Lee},
  journal={arXiv preprint arXiv:1711.11542},
  year={2017}
}

@article{bellec2020solution,
  title={A solution to the learning dilemma for recurrent networks of spiking neurons},
  author={Bellec, Guillaume and Scherr, Franz and Subramoney, Anand and Hajek, Elias and Salaj, Darjan and Legenstein, Robert and Maass, Wolfgang},
  journal={bioRxiv},
  pages={738385},
  year={2020},
  publisher={Cold Spring Harbor Laboratory}
}

@article{launay2020direct,
  title={Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures},
  author={Launay, Julien and Poli, Iacopo and Boniface, Fran{\c{c}}ois and Krzakala, Florent},
  journal={arXiv preprint arXiv:2006.12878},
  year={2020}
}

@article{launay2019principled,
  title={Principled Training of Neural Networks with Direct Feedback Alignment},
  author={Launay, Julien and Poli, Iacopo and Krzakala, Florent},
  journal={arXiv preprint arXiv:1906.04554},
  year={2019}
}

@inproceedings{bartunov2018assessing,
  title={Assessing the scalability of biologically-motivated deep learning algorithms and architectures},
  author={Bartunov, Sergey and Santoro, Adam and Richards, Blake and Marris, Luke and Hinton, Geoffrey E and Lillicrap, Timothy},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9368--9378},
  year={2018}
}

@article{millidge2020activation,
  title={Activation Relaxation: A Local Dynamical Approximation to Backpropagation in the Brain},
  author={Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L and Seth, Anil},
  journal={arXiv preprint arXiv:2009.05359},
  year={2020}
}

@article{huang2011predictive,
  title={Predictive coding},
  author={Huang, Yanping and Rao, Rajesh PN},
  journal={Wiley Interdisciplinary Reviews: Cognitive Science},
  volume={2},
  number={5},
  pages={580--593},
  year={2011},
  publisher={Wiley Online Library},
  keywords={survey},
  url={https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcs.142?casa_token=TJvdr2nDbr8AAAAA:0T3LOAIXt6I7YYpJIqOs204qnwU0FFQiVC976sVifVv0XB4wFlrLZ7WvALY9x_qdoIGciEZWd12hfNQ}
}

@article{srinivasan1982predictive,
  title={Predictive coding: a fresh view of inhibition in the retina},
  author={Srinivasan, Mandyam Veerambudi and Laughlin, Simon Barry and Dubs, Andreas},
  journal={Proceedings of the Royal Society of London. Series B. Biological Sciences},
  volume={216},
  number={1205},
  pages={427--459},
  year={1982},
  publisher={The Royal Society London},
  keywords={classic},
  url={https://royalsocietypublishing.org/doi/abs/10.1098/rspb.1982.0085?casa_token=gdNrGbAlmC8AAAAA%3Ac1xArFgNym4QLB0vI-dDd0ywIS0ozVZjzjnhogf4CVpFZi2zIW8cMU3OIZwvV8cFCoVqAaDOFo_IFDY},
}

@article{hosoya2005dynamic,
  title={Dynamic predictive coding by the retina},
  author={Hosoya, Toshihiko and Baccus, Stephen A and Meister, Markus},
  journal={Nature},
  volume={436},
  number={7047},
  pages={71--77},
  year={2005},
  publisher={Nature Publishing Group},
  keywords={process},
  url={https://www.nature.com/articles/nature03689}
}

@article{spratling2008predictive,
  title={Predictive coding as a model of biased competition in visual attention},
  author={Spratling, Michael W},
  journal={Vision research},
  volume={48},
  number={12},
  pages={1391--1408},
  year={2008},
  publisher={Elsevier},
  keywords={process},
  url={https://www.sciencedirect.com/science/article/pii/S0042698908001466}
}

@article{friston2010generalised,
  title={Generalised filtering},
  author={Friston, Karl and Stephan, Klaas and Li, Baojuan and Daunizeau, Jean},
  journal={Mathematical Problems in Engineering},
  volume={2010},
  year={2010},
  publisher={Hindawi},
  keywords={classic},
  url={https://www.hindawi.com/journals/mpe/2010/621670/}
}

@article{friston2008variational2,
  title={Variational filtering},
  author={Friston, Karl J},
  journal={NeuroImage},
  volume={41},
  number={3},
  pages={747--766},
  year={2008},
  publisher={Elsevier},
  keywords={classic},
  url={https://www.sciencedirect.com/science/article/pii/S1053811908002462?casa_token=bzK7h_aIzY0AAAAA:rg1CzE6vNo-cktIHO_9EAoqmR5Zpy89klEn-Wy3NAzMoR8NcWgaF5_zEzyhrRB76N5RPyCZTIlY}
}

@article{heilbron2018great,
  title={Great expectations: is there evidence for predictive coding in auditory cortex?},
  author={Heilbron, Micha and Chait, Maria},
  journal={Neuroscience},
  volume={389},
  pages={54--73},
  year={2018},
  publisher={Elsevier},
  keywords={process},
  url={https://www.sciencedirect.com/science/article/pii/S030645221730547X}
}

@incollection{kok2015predictive,
  title={Predictive coding in sensory cortex},
  author={Kok, Peter and de Lange, Floris P},
  booktitle={An introduction to model-based cognitive neuroscience},
  pages={221--244},
  year={2015},
  publisher={Springer},
  keywords={process},
  url={https://link.springer.com/chapter/10.1007/978-1-4939-2236-9_11}
}

@article{sterzer2018predictive,
  title={The predictive coding account of psychosis},
  author={Sterzer, Philipp and Adams, Rick A and Fletcher, Paul and Frith, Chris and Lawrie, Stephen M and Muckli, Lars and Petrovic, Predrag and Uhlhaas, Peter and Voss, Martin and Corlett, Philip R},
  journal={Biological psychiatry},
  volume={84},
  number={9},
  pages={634--643},
  year={2018},
  publisher={Elsevier},
  keywords={applications},
  url={https://www.sciencedirect.com/science/article/pii/S0006322318315324}
}

@article{seth2012interoceptive,
  title={An interoceptive predictive coding model of conscious presence},
  author={Seth, Anil K and Suzuki, Keisuke and Critchley, Hugo D},
  journal={Frontiers in psychology},
  volume={2},
  pages={395},
  year={2012},
  publisher={Frontiers},
  keywords={applications},
  url={https://www.frontiersin.org/articles/10.3389/fpsyg.2011.00395/full}
}

@article{seth2013extending,
  title={Extending predictive processing to the body: emotion as interoceptive inference},
  author={Seth, Anil K and Critchley, Hugo D},
  journal={Behav. Brain Sci},
  volume={36},
  number={3},
  pages={227--228},
  year={2013},
  keywords={applications},
  url={https://pdfs.semanticscholar.org/d8ab/0cbc439db9c0a5783bc4c51a7bb6454ff711.pdf}
}

@article{song2020can,
  title={Can the Brain Do Backpropagation?---Exact Implementation of Backpropagation in Predictive Coding Networks},
  author={Song, Yuhang and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020},
  keywords={backprop},
  url={https://proceedings.neurips.cc/paper/2020/hash/fec87a37cdeec1c6ecf8181c0aa2d3bf-Abstract.html}
}

@article{orchard2019making,
  title={Making Predictive Coding Networks Generative},
  author={Orchard, Jeff and Sun, Wei},
  journal={arXiv preprint arXiv:1910.12151},
  year={2019},
  keywords={extensions},
  url={https://arxiv.org/abs/1910.12151}
}

@article{sun2020predictive,
  title={A Predictive-Coding Network That Is Both Discriminative and Generative},
  author={Sun, Wei and Orchard, Jeff},
  journal={Neural Computation},
  volume={32},
  number={10},
  pages={1836--1862},
  year={2020},
  publisher={MIT Press},
  keywords={extensions},
  url={https://www.mitpressjournals.org/doi/abs/10.1162/neco_a_01311}
}

@article{bogacz2020dopamine,
  title={Dopamine role in learning and action inference},
  author={Bogacz, Rafal},
  journal={Elife},
  volume={9},
  pages={e53262},
  year={2020},
  publisher={eLife Sciences Publications Limited},
  keywords={extensions},
  url={https://elifesciences.org/articles/53262}
}

@inproceedings{han2019video,
  title={Video representation learning by dense predictive coding},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019},
  keywords={ml},
  url={https://openaccess.thecvf.com/content_ICCVW_2019/html/HVU/Han_Video_Representation_Learning_by_Dense_Predictive_Coding_ICCVW_2019_paper.html}
}

@article{boutin2019meaningful,
  title={Meaningful representations emerge from sparse deep predictive coding},
  author={Boutin, Victor and Franciosini, Angelo and Ruffier, Franck and Perrinet, Laurent},
  journal={arXiv preprint arXiv:1902.07651},
  year={2019},
  keywords={ml},
  url={https://www.researchgate.net/profile/Laurent_Perrinet/publication/331246369_Meaningful_representations_emerge_from_Sparse_Deep_Predictive_Coding/links/5cbe0d1ba6fdcc1d49a86405/Meaningful-representations-emerge-from-Sparse-Deep-Predictive-Coding.pdf}
}

@article{hosseini2020hierarchical,
  title={Hierarchical Predictive Coding Models in a Deep-Learning Framework},
  author={Hosseini, Matin and Maida, Anthony},
  journal={arXiv preprint arXiv:2005.03230},
  year={2020}
}

@inproceedings{rane2020prednet,
  title={PredNet and Predictive Coding: A Critical Review},
  author={Rane, Roshan Prakash and Sz{\"u}gyi, Edit and Saxena, Vageesh and Ofner, Andr{\'e} and Stober, Sebastian},
  booktitle={Proceedings of the 2020 International Conference on Multimedia Retrieval},
  pages={233--241},
  year={2020}
}

@article{lawson2014aberrant,
  title={An aberrant precision account of autism},
  author={Lawson, Rebecca P and Rees, Geraint and Friston, Karl J},
  journal={Frontiers in human neuroscience},
  volume={8},
  pages={302},
  year={2014},
  publisher={Frontiers},
  keywords={applications},
  url={https://www.frontiersin.org/articles/10.3389/fnhum.2014.00302/full}
}

@article{van2013predictive,
  title={A predictive coding perspective on autism spectrum disorders},
  author={Van Boxtel, Jeroen JA and Lu, Hongjing},
  journal={Frontiers in psychology},
  volume={4},
  pages={19},
  year={2013},
  publisher={Frontiers},
  keywords={applications},
  url={https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00019/full}
}

@article{kilner2007predictive,
  title={Predictive coding: an account of the mirror neuron system},
  author={Kilner, James M and Friston, Karl J and Frith, Chris D},
  journal={Cognitive processing},
  volume={8},
  number={3},
  pages={159--166},
  year={2007},
  publisher={Springer},
  keywords={applications},
  url={https://pubmed.ncbi.nlm.nih.gov/17429704/}
}

@article{spratling2010predictive,
  title={Predictive coding as a model of response properties in cortical area V1},
  author={Spratling, Michael W},
  journal={Journal of neuroscience},
  volume={30},
  number={9},
  pages={3531--3543},
  year={2010},
  publisher={Soc Neuroscience},
  keywords={applications},
  url={https://www.jneurosci.org/content/30/9/3531.short}
}

@article{spratling2019fitting,
  title={Fitting predictive coding to the neurophysiological data},
  author={Spratling, MW},
  journal={Brain research},
  volume={1720},
  pages={146313},
  year={2019},
  publisher={Elsevier},
  keywords={process},
  url={https://www.sciencedirect.com/science/article/pii/S0006899319303592?casa_token=Mq4I-lQm6OMAAAAA:qGWBzjDg799T4lW-YLpp6Mm6Hkh5WhNO1D4teQVE6fRuRCY_2Uv3q2d3xpgXtFCzdhzBy9mzSjg}
}

@article{amari1995information,
  title={Information geometry of the EM and em algorithms for neural networks},
  author={Amari, Shun-Ichi},
  journal={Neural networks},
  volume={8},
  number={9},
  pages={1379--1408},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{gal2015modern,
  title={On modern deep learning and variational inference},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={Advances in Approximate Bayesian Inference workshop, NIPS},
  volume={2},
  year={2015}
}

@article{dayan1995helmholtz,
  title={The helmholtz machine},
  author={Dayan, Peter and Hinton, Geoffrey E and Neal, Radford M and Zemel, Richard S},
  journal={Neural computation},
  volume={7},
  number={5},
  pages={889--904},
  year={1995},
  publisher={MIT Press}
}

@book{ghahramani2000graphical,
  title={Graphical models and variational methods},
  author={Ghahramani, Zoubin and Beal, Matthew J and others},
  year={2000},
  publisher={Advanced mean field methods-theory and practice. MIT Press}
}

@inproceedings{hinton1994autoencoders,
  title={Autoencoders, minimum description length and Helmholtz free energy},
  author={Hinton, Geoffrey E and Zemel, Richard S},
  booktitle={Advances in neural information processing systems},
  pages={3--10},
  year={1994}
}

@article{mumford1992computational,
  title={On the computational architecture of the neocortex},
  author={Mumford, David},
  journal={Biological cybernetics},
  volume={66},
  number={3},
  pages={241--251},
  year={1992},
  publisher={Springer}
}

@article{helmholtz1866concerning,
  title={Concerning the perceptions in general},
  author={Helmholtz, H von},
  journal={Treatise on physiological optics,},
  year={1866}
}

@article{shannon1948mathematical,
  title={A mathematical theory of communication},
  author={Shannon, Claude E},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}

@article{barlow1961coding,
  title={The coding of sensory messages},
  author={Barlow, Horace B},
  journal={Current problems in animal behavior},
  year={1961},
  publisher={Cambridge University Press}
}

@article{barlow1989unsupervised,
  title={Unsupervised learning},
  author={Barlow, Horace B},
  journal={Neural computation},
  volume={1},
  number={3},
  pages={295--311},
  year={1989},
  publisher={MIT Press}
}

@article{barlow1961possible,
  title={Possible principles underlying the transformation of sensory messages},
  author={Barlow, Horace B and others},
  journal={Sensory communication},
  volume={1},
  pages={217--234},
  year={1961}
}

@incollection{neal1998view,
  title={A view of the EM algorithm that justifies incremental, sparse, and other variants},
  author={Neal, Radford M and Hinton, Geoffrey E},
  booktitle={Learning in graphical models},
  pages={355--368},
  year={1998},
  publisher={Springer}
}

@incollection{jordan1998introduction,
  title={An introduction to variational methods for graphical models},
  author={Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  booktitle={Learning in graphical models},
  pages={105--161},
  year={1998},
  publisher={Springer}
}
@article{jordan1998variational,
  title={The variational formulation of the Fokker--Planck equation},
  author={Jordan, Richard and Kinderlehrer, David and Otto, Felix},
  journal={SIAM journal on mathematical analysis},
  volume={29},
  number={1},
  pages={1--17},
  year={1998},
  publisher={SIAM}
}

@book{wiener2019cybernetics,
  title={Cybernetics or Control and Communication in the Animal and the Machine},
  author={Wiener, Norbert},
  year={2019},
  publisher={MIT press}
}

@article{conant1970every,
  title={Every good regulator of a system must be a model of that system},
  author={Conant, Roger C and Ross Ashby, W},
  journal={International journal of systems science},
  volume={1},
  number={2},
  pages={89--97},
  year={1970},
  publisher={Taylor \& Francis}
}

@book{johnson2005pid,
  title={PID control},
  author={Johnson, Michael A and Moradi, Mohammad H},
  year={2005},
  publisher={Springer}
}

@article{gershman2019does,
  title={What does the free energy principle tell us about the brain?},
  author={Gershman, Samuel J},
  journal={arXiv preprint arXiv:1901.07945},
  year={2019},
  keywords={philosophy},
  url={https://arxiv.org/abs/1901.07945}
}

@article{fortier2018woodlice,
  title={Of woodlice and men},
  author={Fortier, Martin and Friedman, Daniel A},
  journal={The editors wish to express their gratitude to Cordelia Erickson-Davis, Brendan Fleig-Goldstein, Ella Letort, Olivia Marcus, and Sarvin Tafazoli for their valuable help in proofreading the interviews, and to all the contributors for accepting to participate to this issue.},
  pages={17},
  year={2018},
  keywords={classic},
  url={https://www.aliusresearch.org/uploads/9/1/6/0/91600416/alius_bulletin_n%C2%B02__2018_.pdf#page=27}
}

@article{ramstead2020tale,
  title={A tale of two densities: Active inference is enactive inference},
  author={Ramstead, Maxwell JD and Kirchhoff, Michael D and Friston, Karl J},
  journal={Adaptive Behavior},
  volume={28},
  number={4},
  pages={225--239},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England},
  keywords={philosophy},
  url={https://journals.sagepub.com/doi/pdf/10.1177/1059712319862774}
}

@article{ramstead2018answering,
  title={Answering Schr{\"o}dinger's question: A free-energy formulation},
  author={Ramstead, Maxwell James D{\'e}sormeau and Badcock, Paul Benjamin and Friston, Karl John},
  journal={Physics of life reviews},
  volume={24},
  pages={1--16},
  year={2018},
  publisher={Elsevier},
  keywords={philosophy},
  url={https://www.sciencedirect.com/science/article/pii/S1571064517301409}
}

@article{veissiere2020thinking,
  title={Thinking through other minds: A variational approach to cognition and culture},
  author={Veissi{\`e}re, Samuel PL and Constant, Axel and Ramstead, Maxwell JD and Friston, Karl J and Kirmayer, Laurence J},
  journal={Behavioral and Brain Sciences},
  volume={43},
  year={2020},
  publisher={Cambridge University Press},
  keywords={philosophy},
  url={https://royalsocietypublishing.org/doi/full/10.1098/rsif.2017.0685}
}

@article{veissiere2020ttom,
  title={TTOM in action: Refining the variational approach to cognition and culture},
  author={Veissi{\`e}re, Samuel PL and Constant, Axel and Ramstead, Maxwell JD and Friston, Karl J and Kirmayer, Laurence J},
  journal={Behavioral and Brain Sciences},
  volume={43},
  year={2020},
  publisher={Cambridge University Press},
  keywords={philosophy},
  url={https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/ttom-in-action-refining-the-variational-approach-to-cognition-and-culture/ADD060A9EE6937A3104FA23290F2C519}
}

@inproceedings{bouchard2004tradeoff,
  title={The tradeoff between generative and discriminative classifiers},
  author={Bouchard, Guillaume and Triggs, Bill},
  booktitle={16th IASC International Symposium on Computational Statistics (COMPSTAT'04)},
  pages={721--728},
  year={2004}
}

@article{parkhurst2002modeling,
  title={Modeling the role of salience in the allocation of overt visual attention},
  author={Parkhurst, Derrick and Law, Klinton and Niebur, Ernst},
  journal={Vision research},
  volume={42},
  number={1},
  pages={107--123},
  year={2002},
  publisher={Elsevier}
}

@article{henderson2017gaze,
  title={Gaze control as prediction},
  author={Henderson, John M},
  journal={Trends in cognitive sciences},
  volume={21},
  number={1},
  pages={15--23},
  year={2017},
  publisher={Elsevier}
}

@article{kanan2009sun,
  title={SUN: Top-down saliency using natural statistics},
  author={Kanan, Christopher and Tong, Mathew H and Zhang, Lingyun and Cottrell, Garrison W},
  journal={Visual cognition},
  volume={17},
  number={6-7},
  pages={979--1003},
  year={2009},
  publisher={Taylor \& Francis}
}

@article{torralba2003statistics,
  title={Statistics of natural image categories},
  author={Torralba, Antonio and Oliva, Aude},
  journal={Network: computation in neural systems},
  volume={14},
  number={3},
  pages={391--412},
  year={2003},
  publisher={Taylor \& Francis}
}

@article{kanizsa1955margini,
  title={Margini quasi-percettivi in campi con stimolazione omogenea},
  author={Kanizsa, Gaetano},
  journal={Rivista di psicologia},
  volume={49},
  number={1},
  pages={7--30},
  year={1955}
}

@article{turrigiano1999homeostatic,
  title={Homeostatic plasticity in neuronal networks: the more things change, the more they stay the same},
  author={Turrigiano, Gina G},
  journal={Trends in neurosciences},
  volume={22},
  number={5},
  pages={221--227},
  year={1999},
  publisher={Elsevier}
}

@article{watt2010homeostatic,
  title={Homeostatic plasticity and STDP: keeping a neuron's cool in a fluctuating world},
  author={Watt, Alanna J and Desai, Niraj S},
  journal={Frontiers in synaptic neuroscience},
  volume={2},
  pages={5},
  year={2010},
  publisher={Frontiers}
}

@article{cichocki2010families,
  title={Families of alpha-beta-and gamma-divergences: Flexible and robust measures of similarities},
  author={Cichocki, Andrzej and Amari, Shun-ichi},
  journal={Entropy},
  volume={12},
  number={6},
  pages={1532--1568},
  year={2010},
  publisher={Molecular Diversity Preservation International}
}

@techreport{dellaert2002expectation,
  title={The expectation maximization algorithm},
  author={Dellaert, Frank},
  year={2002},
  institution={Georgia Institute of Technology}
}

@book{gupta2011theory,
  title={Theory and use of the EM algorithm},
  author={Gupta, Maya R and Chen, Yihua},
  year={2011},
  publisher={Now Publishers Inc}
}

@article{boyles1983convergence,
  title={On the convergence of the EM algorithm},
  author={Boyles, Russell A},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={45},
  number={1},
  pages={47--50},
  year={1983},
  publisher={Wiley Online Library}
}

@article{wasserman2000bayesian,
  title={Bayesian model selection and model averaging},
  author={Wasserman, Larry},
  journal={Journal of mathematical psychology},
  volume={44},
  number={1},
  pages={92--107},
  year={2000},
  publisher={Elsevier}
}

@article{olah2017feature,
  title={Feature visualization},
  author={Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  journal={Distill},
  volume={2},
  number={11},
  pages={e7},
  year={2017}
}

@article{banerjee2005clustering,
  title={Clustering with Bregman divergences.},
  author={Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S and Ghosh, Joydeep and Lafferty, John},
  journal={Journal of machine learning research},
  volume={6},
  number={10},
  year={2005}
}

@article{bruineberg2018anticipating,
  title={The anticipating brain is not a scientist: the free-energy principle from an ecological-enactive perspective},
  author={Bruineberg, Jelle and Kiverstein, Julian and Rietveld, Erik},
  journal={Synthese},
  volume={195},
  number={6},
  pages={2417--2444},
  year={2018},
  publisher={Springer},
  keywords={philosophy},
  url={https://link.springer.com/article/10.1007/s11229-016-1239-1}
}

@article{williams2018predictive,
  title={Predictive processing and the representation wars},
  author={Williams, Daniel},
  journal={Minds and Machines},
  volume={28},
  number={1},
  pages={141--172},
  year={2018},
  publisher={Springer},
  keywords={philosophy},
  url={https://link.springer.com/article/10.1007/s11023-017-9441-6}
}

@inproceedings{baltieri2020predictions,
  title={Predictions in the eye of the beholder: an active inference account of Watt governors},
  author={Baltieri, Manuel and Buckley, Christopher L and Bruineberg, Jelle},
  booktitle={Artificial Life Conference Proceedings},
  pages={121--129},
  year={2020},
  organization={MIT Press},
  keywords={philosophy},
  url={https://www.mitpressjournals.org/doi/abs/10.1162/isal_a_00288}
}

@article{friston2013life,
  title={Life as we know it},
  author={Friston, Karl},
  journal={Journal of the Royal Society Interface},
  volume={10},
  number={86},
  pages={20130475},
  year={2013},
  publisher={The Royal Society}
}

@article{friston2015knowing,
  title={Knowing one's place: a free-energy approach to pattern regulation},
  author={Friston, Karl and Levin, Michael and Sengupta, Biswa and Pezzulo, Giovanni},
  journal={Journal of the Royal Society Interface},
  volume={12},
  number={105},
  pages={20141383},
  year={2015},
  publisher={The Royal Society},
  keywords={self-organisation},
  url={https://royalsocietypublishing.org/doi/full/10.1098/rsif.2014.1383}
}

@article{kuchling2019morphogenesis,
  title={Morphogenesis as Bayesian inference: A variational approach to pattern formation and control in complex biological systems},
  author={Kuchling, Franz and Friston, Karl and Georgiev, Georgi and Levin, Michael},
  journal={Physics of life reviews},
  year={2019},
  publisher={Elsevier},
  keywords={self-organisation},
  url={https://www.sciencedirect.com/science/article/pii/S1571064519300909?casa_token=IrMsxOkLhfYAAAAA:2agLQQPi8aeYTxxqotIPCyEzsHbpvOLwf_0eK5oW2Li0Gi5THHn2XRpWYfNT99M0Xy5pPD_S9CA}
}

@article{ramstead2020neural,
  title={Neural and phenotypic representation under the free-energy principle},
  author={Ramstead, Maxwell JD and Hesp, Casper and Tschantz, Alexander and Smith, Ryan and Constant, Axel and Friston, Karl},
  journal={Neuroscience \& Biobehavioral Reviews},
  year={2020},
  publisher={Elsevier},
  keywords={self-organisation},
  url={https://www.sciencedirect.com/science/article/pii/S0149763420306643?casa_token=16rC0ManFBUAAAAA:3mbntn5I7fObnA_Y397rvZbWrnUzkqmALD1LtS88tGrIRxbw9RQvU55XJuH-zKdBi6tPaN9faDM}
}

@article{friston2020parcels,
  title={Parcels and particles: Markov blankets in the brain},
  author={Friston, Karl J and Fagerholm, Erik D and Zarghami, Tahereh S and Parr, Thomas and Hip{\'o}lito, In{\^e}s and Magrou, Lo{\"\i}c and Razi, Adeel},
  journal={arXiv preprint arXiv:2007.09704},
  year={2020},
  keywords={self-organisation},
  url={https://arxiv.org/abs/2007.09704}
}

@article{hipolito2020markov,
  title={Markov blankets in the brain},
  author={Hipolito, Ines and Ramstead, Maxwell and Convertino, Laura and Bhat, Anjali and Friston, Karl and Parr, Thomas},
  journal={arXiv preprint arXiv:2006.02741},
  year={2020},
  keywords={self-organisation},
  url={https://arxiv.org/abs/2006.02741}
}

@article{parr2020modules,
  title={Modules or Mean-Fields?},
  author={Parr, Thomas and Sajid, Noor and Friston, Karl J},
  journal={Entropy},
  volume={22},
  number={5},
  pages={552},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute},
  keywords={self-organisation},
  url={https://www.mdpi.com/1099-4300/22/5/552},
}

@article{palacios2017biological,
  title={Biological self-organisation and Markov blankets},
  author={Palacios, Ensor Rafael and Razi, Adeel and Parr, Thomas and Kirchhoff, Michael and Friston, Karl},
  journal={BioRxiv},
  pages={227181},
  year={2017},
  publisher={Cold Spring Harbor Laboratory},
  keywords={self-organisation},
  url={https://www.biorxiv.org/content/10.1101/227181v1.abstract}
}

@article{bruineberg2020emperor,
  title={The Emperor’s New Markov Blankets},
  author={Bruineberg, Jelle and Dolega, Krzysztof and Dewhurst, Joe and Baltieri, Manuel},
  year={2020},
  keywords={self-organisation},
  url={http://philsci-archive.pitt.edu/18467/}
}

@article{friston2020sophisticated,
  title={Sophisticated Inference},
  author={Friston, Karl and Da Costa, Lancelot and Hafner, Danijar and Hesp, Casper and Parr, Thomas},
  journal={arXiv preprint arXiv:2006.04120},
  year={2020},
  keywords={discrete},
  url={https://arxiv.org/abs/2006.04120}
}

@article{sajid2019active,
  title={Active inference: demystified and compared},
  author={Sajid, Noor and Ball, Philip J and Friston, Karl J},
  journal={arXiv},
  pages={arXiv--1909},
  year={2019},
  keywords={discrete},
  url={https://ui.adsabs.harvard.edu/abs/2019arXiv190910863S/abstract}
}

@article{da2020relationship,
  title={The relationship between dynamic programming and active inference: The discrete, finite-horizon case},
  author={Da Costa, Lancelot and Sajid, Noor and Parr, Thomas and Friston, Karl and Smith, Ryan},
  journal={arXiv preprint arXiv:2009.08111},
  year={2020},
  keywords={discrete},
  url={https://arxiv.org/abs/2009.08111}
}

@inproceedings{tschantz2020scaling,
  title={Scaling active inference},
  author={Tschantz, Alexander and Baltieri, Manuel and Seth, Anil K and Buckley, Christopher L},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2020},
  organization={IEEE},
  keywords={deep},
  url={https://ieeexplore.ieee.org/abstract/document/9207382/?casa_token=TfYG9cq3UvwAAAAA:Fn2oE7PCTGHlEN0jPQQE4P-qBiO_V-7xRFXXqYn7ubVoZeoiBd6ViBAxWf1L7j-R1wiKEOKvaXQ}
}

@article{watson2020active,
  title={Active Inference or Control as Inference? A Unifying View},
  author={Watson, Joe and Imohiosen, Abraham and Peters, Jan},
  journal={arXiv preprint arXiv:2010.00262},
  year={2020},
  keywords={continous},
  url={https://arxiv.org/abs/2010.00262}
}

@article{van2019application,
  title={Application of the Free Energy Principle to Estimation and Control},
  author={van de Laar, Thijs and {\"O}z{\c{c}}elikkale, Ay{\c{c}}a and Wymeersch, Henk},
  journal={arXiv preprint arXiv:1910.09823},
  year={2019},
  keywords={continuous},
  url={https://arxiv.org/abs/1910.09823}
}

@article{grimbergen2019state,
  title={The State Space Formulation of Active Inference: Towards Brain-Inspired Robot Control},
  author={Grimbergen, Sherin},
  year={2019},
  keywords={continuous},
  url={https://repository.tudelft.nl/islandora/object/uuid:0f56c37c-d22b-478b-8a85-dca615a8f419}
}

@article{oliver2019active,
  title={Active inference body perception and action for humanoid robots},
  author={Oliver, Guillermo and Lanillos, Pablo and Cheng, Gordon},
  journal={arXiv preprint arXiv:1906.03022},
  year={2019},
  keywords={robotics},
  url={https://arxiv.org/abs/1906.03022}
}

@article{vanderbroeck2019active,
  title={Active inference for robot control: A factor graph approach},
  author={Vanderbroeck, Mees and Baioumy, Mohamed and van der Lans, Daan and de Rooij, Rens and van der Werf, Tiis},
  journal={Student Undergraduate Research E-journal!},
  volume={5},
  pages={1--5},
  year={2019},
  keywords={robotics},
  url={https://pdfs.semanticscholar.org/e177/b21b0a7f43ad3969ceb42bd8f1d912ea8d43.pdf}
}

@article{pezzato2020novel,
  title={A novel adaptive controller for robot manipulators based on active inference},
  author={Pezzato, Corrado and Ferrari, Riccardo and Corbato, Carlos Hern{\'a}ndez},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={2973--2980},
  year={2020},
  publisher={IEEE},
  keywords={robotics},
  url={https://ieeexplore.ieee.org/abstract/document/9000729/?casa_token=OBL93SqhogUAAAAA:6w99NtC-Fk7P0tIiXx6QmTNsWnPS-GKK0OtsJEz-HWgniXwpY0Rtue_qlc5Fe9HQ2vj0ropx7hM}
}

@article{pezzulo2018hierarchical,
  title={Hierarchical active inference: A theory of motivated control},
  author={Pezzulo, Giovanni and Rigoli, Francesco and Friston, Karl J},
  journal={Trends in cognitive sciences},
  volume={22},
  number={4},
  pages={294--306},
  year={2018},
  publisher={Elsevier},
  keywords={continuous},
  url={https://www.sciencedirect.com/science/article/pii/S1364661318300226},
}

@article{corcoran2020allostatic,
  title={From allostatic agents to counterfactual cognisers: active inference, biological regulation, and the origins of cognition},
  author={Corcoran, Andrew W and Pezzulo, Giovanni and Hohwy, Jakob},
  journal={Biology \& Philosophy},
  volume={35},
  number={3},
  pages={1--45},
  year={2020},
  publisher={Springer},
  keywords={philosophy},
  url={https://link.springer.com/article/10.1007/s10539-020-09746-2},
}

@article{seth2013interoceptive,
  title={Interoceptive inference, emotion, and the embodied self},
  author={Seth, Anil K},
  journal={Trends in cognitive sciences},
  volume={17},
  number={11},
  pages={565--573},
  year={2013},
  publisher={Elsevier},
  keywords={philosophy},
  url={https://www.sciencedirect.com/science/article/pii/S1364661313002118}
}

@article{seth2016active,
  title={Active interoceptive inference and the emotional brain},
  author={Seth, Anil K and Friston, Karl J},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={371},
  number={1708},
  pages={20160007},
  year={2016},
  publisher={The Royal Society},
  keywords={philosophy},
  url={https://royalsocietypublishing.org/doi/full/10.1098/rstb.2016.0007}
}

@book{seth2014cybernetic,
  title={The cybernetic Bayesian brain},
  author={Seth, Anil K},
  year={2014},
  publisher={Open MIND. Frankfurt am Main: MIND Group},
  keywords={philosophy},
  url={https://open-mind.net/papers/the-cybernetic-bayesian-brain},
}

@article{seth2015presence,
  title={Presence, objecthood, and the phenomenology of predictive perception},
  author={Seth, Anil K},
  journal={Cognitive neuroscience},
  volume={6},
  number={2-3},
  pages={111--117},
  year={2015},
  publisher={Taylor \& Francis},
  keywords={philosophy},
  url={https://www.tandfonline.com/doi/full/10.1080/17588928.2015.1026888?casa_token=IA7GL_oM2VAAAAAA%3AXkJ7HbhxHcW7qCdSWyRSerOo8iZevM3x_8QV1b7C7qAvAqJMveeq4IeGRBTCCbQOCJ6Ix9p70VkKww}
}

@article{smith2020recent,
  title={Recent advances in the application of predictive coding and active inference models within clinical neuroscience},
  author={Smith, Ryan and Badcock, Paul and Friston, Karl J},
  journal={Psychiatry and Clinical Neurosciences},
  year={2020},
  publisher={Wiley Online Library},
  keywords={applications},
  url={https://onlinelibrary.wiley.com/doi/abs/10.1111/pcn.13138}
}

@article{whyte2020predictive,
  title={The Predictive Global Neuronal Workspace: A Formal Active Inference Model of Visual Consciousness},
  author={Whyte, Christopher J and Smith, Ryan},
  journal={bioRxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory},
  keywords={applications},
  url={https://www.sciencedirect.com/science/article/pii/S0301008220301738}
}

@article{smith2019neurocomputational,
  title={Neurocomputational mechanisms underlying emotional awareness: insights afforded by deep active inference and their potential clinical relevance},
  author={Smith, Ryan and Lane, Richard D and Parr, Thomas and Friston, Karl J},
  journal={Neuroscience \& Biobehavioral Reviews},
  volume={107},
  pages={473--491},
  year={2019},
  publisher={Elsevier},
  keywords={applications},
  url={https://www.sciencedirect.com/science/article/pii/S014976341930541X?casa_token=c1UILIbIsKYAAAAA:tQbclbvyieFsSPf_oqulTP8Manv6fU6CeI1iHGZe5Iq4TryLR4pGRjK0Y7RD4gZCfjJo02uWyvw}
}

@article{smith2019simulating,
  title={Simulating emotions: An active inference model of emotional state inference and emotion concept learning},
  author={Smith, Ryan and Parr, Thomas and Friston, Karl J},
  journal={Frontiers in psychology},
  volume={10},
  pages={2844},
  year={2019},
  publisher={Frontiers},
  keywords={applications},
  url={https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02844/full}
}

@article{andrews2020math,
  title={The Math is not the Territory: Navigating the Free Energy Principle},
  author={Andrews, Mel},
  year={2020},
  keywords={philosophy},
  url={http://philsci-archive.pitt.edu/18315/}
}

@article{smith2017hierarchical,
  title={The hierarchical basis of neurovisceral integration},
  author={Smith, Ryan and Thayer, Julian F and Khalsa, Sahib S and Lane, Richard D},
  journal={Neuroscience \& biobehavioral reviews},
  volume={75},
  pages={274--296},
  year={2017},
  publisher={Elsevier},
  keywords={applications},
  url={https://www.sciencedirect.com/science/article/pii/S014976341630673X?casa_token=V0kmqFxZWg4AAAAA:QE5VJB7jp6k22u8L7S7iWYh2_EiLV9a4gyXGUfSMIXOte_zYxGsH2YXUkvKY6PeDKriYy8nu11o}
}

@inproceedings{lanillos2018adaptive,
  title={Adaptive robot body learning and estimation through predictive coding},
  author={Lanillos, Pablo and Cheng, Gordon},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4083--4090},
  year={2018},
  organization={IEEE},
  keywords={robotics},
  url={https://ieeexplore.ieee.org/document/8593684/}
}

@article{friston2010action,
  title={Action and behavior: a free-energy formulation},
  author={Friston, Karl J and Daunizeau, Jean and Kilner, James and Kiebel, Stefan J},
  journal={Biological cybernetics},
  volume={102},
  number={3},
  pages={227--260},
  year={2010},
  publisher={Springer},
  keywords={classic},
  url={https://link.springer.com/article/10.1007/s00422-010-0364-z}
}

@article{marino2020predictive,
  title={Predictive Coding, Variational Autoencoders, and Biological Connections},
  author={Marino, Joseph},
  journal={arXiv preprint arXiv:2011.07464},
  year={2020}
}

@article{hubel1962receptive,
  title={Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
  author={Hubel, David H and Wiesel, Torsten N},
  journal={The Journal of physiology},
  volume={160},
  number={1},
  pages={106},
  year={1962},
  publisher={Wiley-Blackwell}
}

@article{feynman1998statistical,
  title={Statistical mechanics: a set of lectures (advanced book classics)},
  author={Feynman, Richard},
  year={1998}
}


@article{metropolis1953equation,
  title={Equation of state calculations by fast computing machines},
  author={Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
  journal={The journal of chemical physics},
  volume={21},
  number={6},
  pages={1087--1092},
  year={1953},
  publisher={American Institute of Physics}
}

@article{hastings1970monte,
  title={Monte Carlo sampling methods using Markov chains and their applications},
  author={Hastings, W Keith},
  year={1970},
  publisher={Oxford University Press}
}

@misc{welch1995introduction,
  title={An introduction to the Kalman filter},
  author={Welch, Greg and Bishop, Gary and others},
  year={1995},
  publisher={Citeseer}
}

@article{carandini2012normalization,
  title={Normalization as a canonical neural computation},
  author={Carandini, Matteo and Heeger, David J},
  journal={Nature Reviews Neuroscience},
  volume={13},
  number={1},
  pages={51--62},
  year={2012},
  publisher={Nature Publishing Group}
}

@article{ditchburn1955eye,
  title={Eye-movements in relation to retinal action.},
  author={Ditchburn, RW},
  journal={Optica Acta},
  year={1955}
}

@article{gerrits1970artificial,
  title={Artificial movements of a stabilized image},
  author={Gerrits, HJM and Vendrik, AJH},
  journal={Vision Research},
  volume={10},
  number={12},
  pages={1443--1456},
  year={1970},
  publisher={Elsevier}
}

@article{riggs1953disappearance,
  title={The disappearance of steadily fixated visual test objects},
  author={Riggs, Lorrin A and Ratliff, Floyd and Cornsweet, Janet C and Cornsweet, Tom N},
  journal={JOSA},
  volume={43},
  number={6},
  pages={495--501},
  year={1953},
  publisher={Optical Society of America}
}

@article{coppola1996extraordinarily,
  title={The extraordinarily rapid disappearance of entopic images},
  author={Coppola, David and Purves, Dale},
  journal={Proceedings of the National Academy of Sciences},
  volume={93},
  number={15},
  pages={8001--8004},
  year={1996},
  publisher={National Acad Sciences}
}

@article{papamakarios2019normalizing,
  title={Normalizing flows for probabilistic modeling and inference},
  author={Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02762},
  year={2019}
}

@article{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir},
  journal={arXiv preprint arXiv:1505.05770},
  year={2015}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

@article{desimone1998visual,
  title={Visual attention mediated by biased competition in extrastriate visual cortex},
  author={Desimone, Robert},
  journal={Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
  volume={353},
  number={1373},
  pages={1245--1255},
  year={1998},
  publisher={The Royal Society}
}

@article{desimone1995neural,
  title={Neural mechanisms of selective visual attention},
  author={Desimone, Robert and Duncan, John},
  journal={Annual review of neuroscience},
  volume={18},
  number={1},
  pages={193--222},
  year={1995},
  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}
}

@article{reynolds1999competitive,
  title={Competitive mechanisms subserve attention in macaque areas V2 and V4},
  author={Reynolds, John H and Chelazzi, Leonardo and Desimone, Robert},
  journal={Journal of Neuroscience},
  volume={19},
  number={5},
  pages={1736--1753},
  year={1999},
  publisher={Soc Neuroscience}
}

@book{harpur1994experiments,
  title={Experiments with simple Hebbian-based learning rules in pattern classification tasks},
  author={Harpur, George F and Prager, Richard W},
  year={1994},
  publisher={Citeseer}
}

@article{child2020very,
  title={Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images},
  author={Child, Rewon},
  journal={arXiv preprint arXiv:2011.10650},
  year={2020}
}

@inproceedings{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6306--6315},
  year={2017}
}

@article{millidge2018predictive,
  title={A Predictive Processing Account of Bottom-Up Visual Saliency Using Cross-Predicting Autoencoders},
  author={Millidge, Beren and Shillcock, Richard},
  year={2018},
  publisher={PsyArXiv}
}

@article{baltieri2020bayesian,
  title={A Bayesian perspective on classical control},
  author={Baltieri, Manuel},
  journal={arXiv preprint arXiv:2004.10288},
  year={2020}
}

@book{alon2019introduction,
  title={An introduction to systems biology: design principles of biological circuits},
  author={Alon, Uri},
  year={2019},
  publisher={CRC press}
}

@article{millidge2020investigating,
  title={Investigating the Scalability and Biological Plausibility of the Activation Relaxation Algorithm},
  author={Millidge, Beren and Tschantz, Alexander and Seth, Anil and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2010.06219},
  year={2020}
}

@article{williams1989experimental,
  title={Experimental analysis of the real-time recurrent learning algorithm},
  author={Williams, Ronald J and Zipser, David},
  journal={Connection science},
  volume={1},
  number={1},
  pages={87--111},
  year={1989},
  publisher={Taylor \& Francis}
}

@article{kogo2015predictive,
  title={Is predictive coding theory articulated enough to be testable?},
  author={Kogo, Naoki and Trengove, Chris},
  journal={Frontiers in computational neuroscience},
  volume={9},
  pages={111},
  year={2015},
  publisher={Frontiers}
}

@article{keller2018predictive,
  title={Predictive processing: a canonical cortical computation},
  author={Keller, Georg B and Mrsic-Flogel, Thomas D},
  journal={Neuron},
  volume={100},
  number={2},
  pages={424--435},
  year={2018},
  publisher={Elsevier}
}

@article{van2020going,
  title={Going in circles is the way forward: the role of recurrence in visual inference},
  author={van Bergen, Ruben S and Kriegeskorte, Nikolaus},
  journal={arXiv preprint arXiv:2003.12128},
  year={2020}
}

@article{kietzmann2019recurrence,
  title={Recurrence is required to capture the representational dynamics of the human visual system},
  author={Kietzmann, Tim C and Spoerer, Courtney J and S{\"o}rensen, Lynn KA and Cichy, Radoslaw M and Hauk, Olaf and Kriegeskorte, Nikolaus},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={43},
  pages={21854--21863},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{elsayed2019reduced,
  title={Reduced-Gate Convolutional LSTM Architecture for Next-Frame Video Prediction Using Predictive Coding},
  author={Elsayed, Nelly and Maida, Anthony S and Bayoumi, Magdy},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--9},
  year={2019},
  organization={IEEE}
}

@inproceedings{lee2001algorithms,
  title={Algorithms for non-negative matrix factorization},
  author={Lee, Daniel D and Seung, H Sebastian},
  booktitle={Advances in neural information processing systems},
  pages={556--562},
  year={2001}
}

@inproceedings{felleman1991distributed,
  title={Distributed hierarchical processing in the primate cerebral cortex},
  author={Felleman, Daniel J and Van Essen, David C},
  booktitle={Cereb cortex},
  year={1991},
  organization={Citeseer}
}

@article{cao2020new,
  title={New labels for old ideas: Predictive processing and the interpretation of neural signals},
  author={Cao, Rosa},
  journal={Review of Philosophy and Psychology},
  volume={11},
  number={3},
  pages={517--546},
  year={2020},
  publisher={Springer}
}

@article{marr1982vision,
  title={Vision: A computational investigation into the human representation and processing of visual information},
  author={Marr, David},
  year={1982},
  publisher={CUMINCAD}
}

@article{grill2004human,
  title={The human visual cortex},
  author={Grill-Spector, Kalanit and Malach, Rafael},
  journal={Annu. Rev. Neurosci.},
  volume={27},
  pages={649--677},
  year={2004},
  publisher={Annual Reviews}
}

@article{kaelbling1998planning,
  title={Planning and acting in partially observable stochastic domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998},
  publisher={Elsevier}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000},
  organization={Citeseer}
}

@article{hafner2020action,
  title={Action and perception as divergence minimization},
  author={Hafner, Danijar and Ortega, Pedro A and Ba, Jimmy and Parr, Thomas and Friston, Karl and Heess, Nicolas},
  journal={arXiv preprint arXiv:2009.01791},
  year={2020}
}

@article{agakov2004algorithm,
  title={The im algorithm: a variational approach to information maximization},
  author={Agakov, David Barber Felix},
  journal={Advances in neural information processing systems},
  volume={16},
  pages={201},
  year={2004}
}

@article{karl2017unsupervised,
  title={Unsupervised real-time control through variational empowerment},
  author={Karl, Maximilian and Soelch, Maximilian and Becker-Ehmck, Philip and Benbouzid, Djalel and van der Smagt, Patrick and Bayer, Justin},
  journal={arXiv preprint arXiv:1710.05101},
  year={2017}
}

@article{gregor2016variational,
  title={Variational intrinsic control},
  author={Gregor, Karol and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint arXiv:1611.07507},
  year={2016}
}

@article{baumli2020relative,
  title={Relative Variational Intrinsic Control},
  author={Baumli, Kate and Warde-Farley, David and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:2012.07827},
  year={2020}
}

@article{jung2011empowerment,
  title={Empowerment for continuous agent—environment systems},
  author={Jung, Tobias and Polani, Daniel and Stone, Peter},
  journal={Adaptive Behavior},
  volume={19},
  number={1},
  pages={16--39},
  year={2011},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{klyubin2005empowerment,
  title={Empowerment: A universal agent-centric measure of control},
  author={Klyubin, Alexander S and Polani, Daniel and Nehaniv, Chrystopher L},
  booktitle={2005 IEEE Congress on Evolutionary Computation},
  volume={1},
  pages={128--135},
  year={2005},
  organization={IEEE}
}

@article{dabney2020distributional,
  title={A distributional code for value in dopamine-based reinforcement learning},
  author={Dabney, Will and Kurth-Nelson, Zeb and Uchida, Naoshige and Starkweather, Clara Kwon and Hassabis, Demis and Munos, R{\'e}mi and Botvinick, Matthew},
  journal={Nature},
  pages={1--5},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{sajid2019demystifying,
  title={Demystifying active inference},
  author={Sajid, Noor and Ball, Philip J and Friston, Karl J},
  journal={arXiv preprint arXiv:1909.10863},
  year={2019}
}

@article{meyes2017motion,
  title={Motion planning for industrial robots using reinforcement learning},
  author={Meyes, Richard and Tercan, Hasan and Roggendorf, Simon and Thiele, Thomas and B{\"u}scher, Christian and Obdenbusch, Markus and Brecher, Christian and Jeschke, Sabina and Meisen, Tobias},
  journal={Procedia CIRP},
  volume={63},
  pages={107--112},
  year={2017},
  publisher={Elsevier}
}

@article{l2008bayesian,
  title={Bayesian models of cognition},
  author={L Griffiths, Thomas and Kemp, Charles and B Tenenbaum, Joshua},
  year={2008},
  publisher={Carnegie Mellon University}
}

@inproceedings{shyam_model-based_2019,
	title = {Model-Based Active Exploration},
	url = {http://proceedings.mlr.press/v97/shyam19a.html},
	abstract = {Efficient exploration is an unsolved problem in Reinforcement Learning which is usually addressed by reactively rewarding the agent for fortuitously encountering novel situations. This paper introd...},
	eventtitle = {International Conference on Machine Learning},
	pages = {5779--5788},
	booktitle = {International Conference on Machine Learning},
	author = {Shyam, Pranav and Jaśkowski, Wojciech and Gomez, Faustino},
	urldate = {2019-10-11},
	date = {2019-05-24},
	year = {2019},
	langid = {english},
	file = {Full Text PDF:/Users/at449/Zotero/storage/XYT4HHIN/Shyam et al. - 2019 - Model-Based Active Exploration.pdf:application/pdf;Snapshot:/Users/at449/Zotero/storage/6YG82E3Y/shyam19a.html:text/html}
}

@article{chatzilygeroudis_survey_2018,
	title = {A survey on policy search algorithms for learning robot controllers in a handful of trials},
	url = {http://arxiv.org/abs/1807.02303},
	abstract = {Most policy search algorithms require thousands of training episodes to find an effective policy, which is often infeasible with a physical robot. This survey article focuses on the extreme other end of the spectrum: how can a robot adapt with only a handful of trials (a dozen) and a few minutes? By analogy with the word "big-data", we refer to this challenge as "micro-data reinforcement learning". We show that a first strategy is to leverage prior knowledge on the policy structure (e.g., dynamic movement primitives), on the policy parameters (e.g., demonstrations), or on the dynamics (e.g., simulators). A second strategy is to create data-driven surrogate models of the expected reward (e.g., Bayesian optimization) or the dynamical model (e.g., model-based policy search), so that the policy optimizer queries the model instead of the real system. Overall, all successful micro-data algorithms combine these two strategies by varying the kind of model and prior knowledge. The current scientific challenges essentially revolve around scaling up to complex robots (e.g., humanoids), designing generic priors, and optimizing the computing time.},
	journaltitle = {{arXiv}:1807.02303 [cs, stat]},
	author = {Chatzilygeroudis, Konstantinos and Vassiliades, Vassilis and Stulp, Freek and Calinon, Sylvain and Mouret, Jean-Baptiste},
	urldate = {2019-10-15},
	date = {2018-07-06},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1807.02303},
	file = {arXiv\:1807.02303 PDF:/Users/at449/Zotero/storage/LVKBINJS/Chatzilygeroudis et al. - 2018 - A survey on policy search algorithms for learning .pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/PJ5C4Z5B/1807.html:text/html}
}

@article{okada_variational_2019,
	title = {Variational Inference {MPC} for Bayesian Model-based Reinforcement Learning},
	url = {http://arxiv.org/abs/1907.04202},
	abstract = {In recent studies on model-based reinforcement learning ({MBRL}), incorporating uncertainty in forward dynamics is a state-of-the-art strategy to enhance learning performance, making {MBRLs} competitive to cutting-edge model free methods, especially in simulated robotics tasks. Probabilistic ensembles with trajectory sampling ({PETS}) is a leading type of {MBRL}, which employs Bayesian inference to dynamics modeling and model predictive control ({MPC}) with stochastic optimization via the cross entropy method ({CEM}). In this paper, we propose a novel extension to the uncertainty-aware {MBRL}. Our main contributions are twofold: Firstly, we introduce a variational inference {MPC}, which reformulates various stochastic methods, including {CEM}, in a Bayesian fashion. Secondly, we propose a novel instance of the framework, called probabilistic action ensembles with trajectory sampling ({PaETS}). As a result, our Bayesian {MBRL} can involve multimodal uncertainties both in dynamics and optimal trajectories. In comparison to {PETS}, our method consistently improves asymptotic performance on several challenging locomotion tasks.},
	journaltitle = {{arXiv}:1907.04202 [cs, eess, stat]},
	author = {Okada, Masashi and Taniguchi, Tadahiro},
	urldate = {2019-10-16},
	date = {2019-07-07},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1907.04202},
	file = {arXiv\:1907.04202 PDF:/Users/at449/Zotero/storage/T9AFYKNH/Okada and Taniguchi - 2019 - Variational Inference MPC for Bayesian Model-based.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/EBUPJI9R/1907.html:text/html}
}

@article{chitta_deep_2018,
	title = {Deep Probabilistic Ensembles: Approximate Variational Inference through {KL} Regularization},
	url = {http://arxiv.org/abs/1811.02640},
	shorttitle = {Deep Probabilistic Ensembles},
	abstract = {In this paper, we introduce Deep Probabilistic Ensembles ({DPEs}), a scalable technique that uses a regularized ensemble to approximate a deep Bayesian Neural Network ({BNN}). We do so by incorporating a {KL} divergence penalty term into the training objective of an ensemble, derived from the evidence lower bound used in variational inference. We evaluate the uncertainty estimates obtained from our models for active learning on visual classification. Our approach steadily improves upon active learning baselines as the annotation budget is increased.},
	journaltitle = {{arXiv}:1811.02640 [cs, stat]},
	author = {Chitta, Kashyap and Alvarez, Jose M. and Lesnikowski, Adam},
	urldate = {2019-10-16},
	date = {2018-11-06},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1811.02640},
	file = {arXiv\:1811.02640 PDF:/Users/at449/Zotero/storage/RB5JY9CE/Chitta et al. - 2018 - Deep Probabilistic Ensembles Approximate Variatio.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/8P28BRFD/1811.html:text/html}
}

@article{houthooft_vime:_2016,
	title = {{VIME}: Variational Information Maximizing Exploration},
	url = {http://arxiv.org/abs/1605.09674},
	shorttitle = {{VIME}},
	abstract = {Scalable and effective exploration remains a key challenge in reinforcement learning ({RL}). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep {RL} scenarios. As such, most contemporary {RL} relies on simple heuristics such as epsilon-greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration ({VIME}), an exploration strategy based on maximization of information gain about the agent's belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. {VIME} modifies the {MDP} reward function, and can be applied with several different underlying {RL} algorithms. We demonstrate that {VIME} achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.},
	journaltitle = {{arXiv}:1605.09674 [cs, stat]},
	author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
	urldate = {2019-10-18},
	date = {2016-05-31},
	year = {2016},
	eprinttype = {arxiv},
	eprint = {1605.09674},
	file = {arXiv\:1605.09674 PDF:/Users/at449/Zotero/storage/MFS379FF/Houthooft et al. - 2016 - VIME Variational Information Maximizing Explorati.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/RWMAMMLX/1605.html:text/html}
}

@article{depeweg_decomposition_2017,
	title = {Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning},
	url = {http://arxiv.org/abs/1710.07283},
	abstract = {Bayesian neural networks with latent variables are scalable and flexible probabilistic models: They account for uncertainty in the estimation of the network weights and, by making use of latent variables, can capture complex noise patterns in the data. We show how to extract and decompose uncertainty into epistemic and aleatoric components for decision-making purposes. This allows us to successfully identify informative points for active learning of functions with heteroscedastic and bimodal noise. Using the decomposition we further define a novel risk-sensitive criterion for reinforcement learning to identify policies that balance expected cost, model-bias and noise aversion.},
	journaltitle = {{arXiv}:1710.07283 [cs, stat]},
	author = {Depeweg, Stefan and Hernández-Lobato, José Miguel and Doshi-Velez, Finale and Udluft, Steffen},
	urldate = {2019-10-18},
	date = {2017-10-19},
	year = {2017},
	eprinttype = {arxiv},
	eprint = {1710.07283},
	file = {arXiv\:1710.07283 PDF:/Users/at449/Zotero/storage/334CIFGW/Depeweg et al. - 2017 - Decomposition of Uncertainty in Bayesian Deep Lear.pdf:application/pdf;arXiv\:1710.07283 PDF:/Users/at449/Zotero/storage/9DQ5IEBL/Depeweg et al. - 2017 - Decomposition of Uncertainty in Bayesian Deep Lear.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/F73T3YSU/1710.html:text/html;arXiv.org Snapshot:/Users/at449/Zotero/storage/SMRZCXGZ/1710.html:text/html}
}

@article{kim_emi:_2018,
	title = {{EMI}: Exploration with Mutual Information},
	url = {http://arxiv.org/abs/1810.01176},
	shorttitle = {{EMI}},
	abstract = {Reinforcement learning algorithms struggle when the reward signal is very sparse. In these cases, naive random exploration methods essentially rely on a random walk to stumble onto a rewarding state. Recent works utilize intrinsic motivation to guide the exploration via generative models, predictive forward models, or discriminative modeling of novelty. We propose {EMI}, which is an exploration method that constructs embedding representation of states and actions that does not rely on generative decoding of the full observation but extracts predictive signals that can be used to guide exploration based on forward prediction in the representation space. Our experiments show competitive results on challenging locomotion tasks with continuous control and on image-based exploration tasks with discrete actions on Atari. The source code is available at https://github.com/snu-mllab/{EMI} .},
	journaltitle = {{arXiv}:1810.01176 [cs, stat]},
	author = {Kim, Hyoungseok and Kim, Jaekyeom and Jeong, Yeonwoo and Levine, Sergey and Song, Hyun Oh},
	urldate = {2019-10-18},
	date = {2018-10-02},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1810.01176},
	file = {arXiv\:1810.01176 PDF:/Users/at449/Zotero/storage/ZIG7CPMW/Kim et al. - 2018 - EMI Exploration with Mutual Information.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/D4N9HSHN/1810.html:text/html}
}

@article{teigen_active_2018,
	title = {An Active Learning Perspective on Exploration in Reinforcement Learning},
	url = {https://www.duo.uio.no/handle/10852/62823},
	abstract = {Reinforcement learning is a research field concerned with automatically solving problems by trial and error. With each trial, a reinforcement learning agent extracts information about the problem. The agent can choose to apply its current knowledge and solve the problem as well as that information allows, or it can decide to do something new and untried with the hope that this will yield new and useful information. Balancing this trade-off is called the exploration vs. exploitation problem, and is the primary focus of this thesis. The work is organized around three related research questions. Exploration algorithms have proliferated in the last few years. There are differences in the way exploration techniques create exploratory behavior. The first part of this work presents a categorization of exploration methods based on these differences. Techniques from each category are then tested and analyzed to evaluate their benefits and weaknesses. The categorization scheme makes it possible to easily combine exploration techniques. The second part of this work shows how to combine different exploration methods. Experimental results demonstrate that such a combination can produce new exploration algorithms which significantly outperform methods from each category. The best combined method outperforms the best single-category method, and is more robust to changes in the other parameters of the learning system. Combining methods from different categories of exploration techniques gives better results, but there are still some relatively simple problems the combined methods can not efficiently solve. The third part of the work further investigates the family of exploration techniques known as intrinsic motivation. Inspired by how humans are motivated to explore, the field of intrinsic motivation creates curious {AI} agents. The current state of the art intrinsic motivation techniques work very well on many problems but can not solve problems where the solution requires modeling randomness. This work investigates a novel intrinsic motivation algorithm designed to remove this known weakness.},
	author = {Teigen, Bjørn Ivar},
	urldate = {2019-10-18},
	date = {2018},
	year = {2018},
	file = {Full Text PDF:/Users/at449/Zotero/storage/GYAVBIVI/Teigen - 2018 - An Active Learning Perspective on Exploration in R.pdf:application/pdf;Snapshot:/Users/at449/Zotero/storage/NCLF5WE7/62823.html:text/html}
}

@article{depeweg_decomposition_2017-1,
	title = {Decomposition of Uncertainty for Active Learning and Reliable Reinforcement Learning in Stochastic Systems},
	abstract = {Bayesian neural networks ({BNNs}) with latent variables are probabilistic models which can automatically identify complex stochastic patterns in the data. We study in these models a decomposition of predictive uncertainty into its epistemic and aleatoric components. We show how such a decomposition arises naturally in a Bayesian active learning scenario and develop a new objective for reliable reinforcement learning ({RL}) with an epistemic and aleatoric risk element. Our experiments illustrate the usefulness of the resulting decomposition in active learning and reliable {RL}.},
	author = {Depeweg, Stefan and Hernández-Lobato, José and Doshi-Velez, Finale and Udluft, Steffen},
	date = {2017-10-19},
	year = {2017},
	file = {Full Text PDF:/Users/at449/Zotero/storage/EEQT6RWG/Depeweg et al. - 2017 - Decomposition of Uncertainty for Active Learning a.pdf:application/pdf}
}

@article{mirchev_approximate_2018,
	title = {Approximate Bayesian inference in spatial environments},
	url = {http://arxiv.org/abs/1805.07206},
	abstract = {Model-based approaches bear great promise for decision making of agents interacting with the physical world. In the context of spatial environments, different types of problems such as localisation, mapping, navigation or autonomous exploration are typically adressed with specialised methods, often relying on detailed knowledge of the system at hand. We express these tasks as probabilistic inference and planning under the umbrella of deep sequential generative models. Using the frameworks of variational inference and neural networks, our method inherits favourable properties such as flexibility, scalability and the ability to learn from data. The method performs comparably to specialised state-of-the-art methodology in two distinct simulated environments.},
	journaltitle = {{arXiv}:1805.07206 [cs, stat]},
	author = {Mirchev, Atanas and Kayalibay, Baris and Soelch, Maximilian and van der Smagt, Patrick and Bayer, Justin},
	urldate = {2019-10-19},
	date = {2018-05-18},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1805.07206},
	file = {arXiv\:1805.07206 PDF:/Users/at449/Zotero/storage/ITZF9WYC/Mirchev et al. - 2018 - Approximate Bayesian inference in spatial environm.pdf:application/pdf;arXiv\:1805.07206 PDF:/Users/at449/Zotero/storage/GHRCHUCF/Mirchev et al. - 2018 - Approximate Bayesian inference in spatial environm.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/PSUY5THJ/1805.html:text/html;arXiv.org Snapshot:/Users/at449/Zotero/storage/G6VS9K65/1805.html:text/html}
}

@article{blundell_weight_2015,
	title = {Weight Uncertainty in Neural Networks},
	url = {http://arxiv.org/abs/1505.05424},
	abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on {MNIST} classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	journaltitle = {{arXiv}:1505.05424 [cs, stat]},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	urldate = {2019-10-19},
	date = {2015-05-20},
	year = {2015},
	eprinttype = {arxiv},
	eprint = {1505.05424},
	file = {arXiv\:1505.05424 PDF:/Users/at449/Zotero/storage/BZGXLGIL/Blundell et al. - 2015 - Weight Uncertainty in Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/65UNLFIC/1505.html:text/html}
}

@article{kingma_auto-encoding_2013,
	title = {Auto-Encoding Variational Bayes},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	journaltitle = {{arXiv}:1312.6114 [cs, stat]},
	author = {Kingma, Diederik P. and Welling, Max},
	urldate = {2019-10-19},
	date = {2013-12-20},
	year = {2013},
	eprinttype = {arxiv},
	eprint = {1312.6114},
	file = {arXiv\:1312.6114 PDF:/Users/at449/Zotero/storage/BTYGSA3R/Kingma and Welling - 2013 - Auto-Encoding Variational Bayes.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/2HLB6YG3/1312.html:text/html}
}

@article{barron_information_2018,
	title = {Information Maximizing Exploration with a Latent Dynamics Model},
	url = {http://arxiv.org/abs/1804.01238},
	abstract = {All reinforcement learning algorithms must handle the trade-off between exploration and exploitation. Many state-of-the-art deep reinforcement learning methods use noise in the action selection, such as Gaussian noise in policy gradient methods or \${\textbackslash}epsilon\$-greedy in Q-learning. While these methods are appealing due to their simplicity, they do not explore the state space in a methodical manner. We present an approach that uses a model to derive reward bonuses as a means of intrinsic motivation to improve model-free reinforcement learning. A key insight of our approach is that this dynamics model can be learned in the latent feature space of a value function, representing the dynamics of the agent and the environment. This method is both theoretically grounded and computationally advantageous, permitting the efficient use of Bayesian information-theoretic methods in high-dimensional state spaces. We evaluate our method on several continuous control tasks, focusing on improving exploration.},
	journaltitle = {{arXiv}:1804.01238 [cs, stat]},
	author = {Barron, Trevor and Obst, Oliver and Amor, Heni Ben},
	urldate = {2019-10-19},
	date = {2018-04-04},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1804.01238},
	file = {arXiv\:1804.01238 PDF:/Users/at449/Zotero/storage/PQQ5M627/Barron et al. - 2018 - Information Maximizing Exploration with a Latent D.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/63KVXCVF/1804.html:text/html}
}

@article{aubret_survey_2019,
	title = {A survey on intrinsic motivation in reinforcement learning},
	url = {http://arxiv.org/abs/1908.06976},
	abstract = {Despite numerous research work in reinforcement learning ({RL}) and the recent successes obtained by combining it with deep learning, deep reinforcement learning ({DRL}) is still facing many challenges. Some of them, like the ability to abstract actions or the difficulty to explore the environment with sparse rewards, can be addressed by the use of intrinsic motivation. In this article, we provide a survey on the role of intrinsic motivation in {DRL}. We categorize the different kinds of intrinsic motivations and detail their interests and limitations. Our investigation shows that the combination of {DRL} and intrinsic motivation enables to learn more complicated and more generalisable behaviours than standard {DRL}. We provide an in-depth analysis describing learning modules through an unifying scheme composed of information theory, compression theory and reinforcement learning. We then explain how these modules could serve as building blocks over a complete developmental architecture, highlighting the numerous outlooks of the domain.},
	journaltitle = {{arXiv}:1908.06976 [cs]},
	author = {Aubret, Arthur and Matignon, Laetitia and Hassas, Salima},
	urldate = {2019-10-19},
	date = {2019-08-19},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1908.06976},
	file = {arXiv\:1908.06976 PDF:/Users/at449/Zotero/storage/64SNA3IC/Aubret et al. - 2019 - A survey on intrinsic motivation in reinforcement .pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/YU6XI5G9/1908.html:text/html}
}

@article{millidge_deep_2019,
	title = {Deep Active Inference as Variational Policy Gradients},
	url = {http://arxiv.org/abs/1907.03876},
	abstract = {Active Inference is a theory of action arising from neuroscience which casts action and planning as a bayesian inference problem to be solved by minimizing a single quantity - the variational free energy. Active Inference promises a unifying account of action and perception coupled with a biologically plausible process theory. Despite these potential advantages, current implementations of Active Inference can only handle small, discrete policy and state-spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm which approximates key densities using deep neural networks as flexible function approximators, which enables Active Inference to scale to significantly larger and more complex tasks. We demonstrate our approach on a suite of {OpenAIGym} benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm shows similarities with maximum entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.},
	journaltitle = {{arXiv}:1907.03876 [cs]},
	author = {Millidge, Beren},
	urldate = {2019-10-19},
	date = {2019-07-08},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1907.03876},
	file = {arXiv\:1907.03876 PDF:/Users/at449/Zotero/storage/26Y2SNEM/Millidge - 2019 - Deep Active Inference as Variational Policy Gradie.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/Y5JV9RWL/1907.html:text/html}
}

@article{ha_recurrent_2018,
	title = {Recurrent World Models Facilitate Policy Evolution},
	url = {http://arxiv.org/abs/1809.01999},
	abstract = {A generative recurrent neural network is quickly trained in an unsupervised manner to model popular reinforcement learning environments through compressed spatio-temporal representations. The world model's extracted features are fed into compact and simple policies trained by evolution, achieving state of the art results in various environments. We also train our agent entirely inside of an environment generated by its own internal world model, and transfer this policy back into the actual environment. Interactive version of paper at https://worldmodels.github.io},
	journaltitle = {{arXiv}:1809.01999 [cs, stat]},
	author = {Ha, David and Schmidhuber, Jürgen},
	urldate = {2019-10-19},
	date = {2018-09-04},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1809.01999},
	file = {arXiv\:1809.01999 PDF:/Users/at449/Zotero/storage/JD9SNDBG/Ha and Schmidhuber - 2018 - Recurrent World Models Facilitate Policy Evolution.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/WSL7M3GP/1809.html:text/html}
}

@article{chua_deep_2018,
	title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
	url = {http://arxiv.org/abs/1805.12114},
	abstract = {Model-based reinforcement learning ({RL}) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling ({PETS}) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep {RL} algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).},
	journaltitle = {{arXiv}:1805.12114 [cs, stat]},
	author = {Chua, Kurtland and Calandra, Roberto and {McAllister}, Rowan and Levine, Sergey},
	urldate = {2019-10-19},
	date = {2018-05-30},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1805.12114},
	file = {arXiv\:1805.12114 PDF:/Users/at449/Zotero/storage/WWCU7QFI/Chua et al. - 2018 - Deep Reinforcement Learning in a Handful of Trials.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/APMETL2K/1805.html:text/html}
}

@article{kaiser_model-based_2019,
	title = {Model-Based Reinforcement Learning for Atari},
	url = {http://arxiv.org/abs/1903.00374},
	abstract = {Model-free reinforcement learning ({RL}) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning ({SimPLe}), a complete model-based deep {RL} algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate {SimPLe} on a range of Atari games in low data regime of \$100\$K interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games {SimPLe} outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.},
	journaltitle = {{arXiv}:1903.00374 [cs, stat]},
	author = {Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H. and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and Mohiuddin, Afroz and Sepassi, Ryan and Tucker, George and Michalewski, Henryk},
	urldate = {2019-10-19},
	date = {2019-03-01},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1903.00374},
	file = {arXiv\:1903.00374 PDF:/Users/at449/Zotero/storage/H8L94X5A/Kaiser et al. - 2019 - Model-Based Reinforcement Learning for Atari.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/IKWDAZ4P/1903.html:text/html}
}

@article{catal_bayesian_2019,
	title = {Bayesian policy selection using active inference},
	url = {http://arxiv.org/abs/1904.08149},
	abstract = {Learning to take actions based on observations is a core requirement for artificial agents to be able to be successful and robust at their task. Reinforcement Learning ({RL}) is a well-known technique for learning such policies. However, current {RL} algorithms often have to deal with reward shaping, have difficulties generalizing to other environments and are most often sample inefficient. In this paper, we explore active inference and the free energy principle, a normative theory from neuroscience that explains how self-organizing biological systems operate by maintaining a model of the world and casting action selection as an inference problem. We apply this concept to a typical problem known to the {RL} community, the mountain car problem, and show how active inference encompasses both {RL} and learning from demonstrations.},
	journaltitle = {{arXiv}:1904.08149 [cs]},
	author = {Çatal, Ozan and Nauta, Johannes and Verbelen, Tim and Simoens, Pieter and Dhoedt, Bart},
	urldate = {2019-10-19},
	date = {2019-04-17},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1904.08149},
	file = {arXiv\:1904.08149 PDF:/Users/at449/Zotero/storage/CKV7F7AH/Çatal et al. - 2019 - Bayesian policy selection using active inference.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/IJBUX7EC/1904.html:text/html}
}

@article{gong_icebreaker:_2019,
	title = {Icebreaker: Element-wise Active Information Acquisition with Bayesian Deep Latent Gaussian Model},
	url = {http://arxiv.org/abs/1908.04537},
	shorttitle = {Icebreaker},
	abstract = {In this paper we introduce the ice-start problem, i.e., the challenge of deploying machine learning models when only little or no training data is initially available, and acquiring each feature element of data is associated with costs. This setting is representative for the real-world machine learning applications. For instance, in the health-care domain, when training an {AI} system for predicting patient metrics from lab tests, obtaining every single measurement comes with a high cost. Active learning, where only the label is associated with a cost does not apply to such problem, because performing all possible lab tests to acquire a new training datum would be costly, as well as unnecessary due to redundancy. We propose Icebreaker, a principled framework to approach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent Gaussian Model ({BELGAM}) with a novel inference method. Our proposed method combines recent advances in amortized inference and stochastic gradient {MCMC} to enable fast and accurate posterior inference. By utilizing {BELGAM}'s ability to fully quantify model uncertainty, we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that {BELGAM} performs significantly better than the previous {VAE} (Variational autoencoder) based models, when the data set size is small, using both machine learning benchmarks and real-world recommender systems and health-care applications. Moreover, based on {BELGAM}, Icebreaker further improves the performance and demonstrate the ability to use minimum amount of the training data to obtain the highest test time performance.},
	journaltitle = {{arXiv}:1908.04537 [cs, stat]},
	author = {Gong, Wenbo and Tschiatschek, Sebastian and Turner, Richard and Nowozin, Sebastian and Hernández-Lobato, José Miguel and Zhang, Cheng},
	urldate = {2019-10-19},
	date = {2019-08-13},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1908.04537},
	file = {arXiv\:1908.04537 PDF:/Users/at449/Zotero/storage/NZNCPUIH/Gong et al. - 2019 - Icebreaker Element-wise Active Information Acquis.pdf:application/pdf;arXiv\:1908.04537 PDF:/Users/at449/Zotero/storage/GFNKCGHE/Gong et al. - 2019 - Icebreaker Element-wise Active Information Acquis.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/GXXE4E6B/1908.html:text/html;arXiv.org Snapshot:/Users/at449/Zotero/storage/ET58EDEJ/1908.html:text/html}
}

@article{ueltzhoffer_deep_2018,
	title = {Deep Active Inference},
	volume = {112},
	issn = {0340-1200, 1432-0770},
	url = {http://arxiv.org/abs/1709.02341},
	doi = {10.1007/s00422-018-0785-7},
	abstract = {This work combines the free energy principle from cognitive neuroscience and the ensuing active inference dynamics with recent advances in variational inference in deep generative models, and evolution strategies to introduce the "deep active inference" agent. This agent minimises a variational free energy bound on the average surprise of its sensations, which is motivated by a homeostatic argument. It does so by optimising the parameters of a generative latent variable model of its sensory inputs, together with a variational density approximating the posterior distribution over the latent variables, given its observations, and by acting on its environment to actively sample input that is likely under this generative model. The internal dynamics of the agent are implemented using deep and recurrent neural networks, as used in machine learning, making the deep active inference agent a scalable and very flexible class of active inference agent. Using the mountain car problem, we show how goal directed behaviour can be implemented by defining appropriate priors on the latent states in the agent's model. Furthermore, we show that the deep active inference agent can learn a generative model of the environment, which can be sampled from to understand the agent's beliefs about the environment and its interaction therewith.},
	pages = {547--573},
	number = {6},
	journaltitle = {Biological Cybernetics},
	shortjournal = {Biol Cybern},
	author = {Ueltzhöffer, Kai},
	urldate = {2019-10-19},
	date = {2018-12},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1709.02341},
	file = {arXiv\:1709.02341 PDF:/Users/at449/Zotero/storage/RFP3NQDL/Ueltzhöffer - 2018 - Deep Active Inference.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/YQXETGBC/1709.html:text/html}
}
@article{williams2020brain,
  title={Is the Brain an Organ for Prediction Error Minimization?},
  author={Williams, Daniel},
  year={2020}
}

@inproceedings{yarin_gal_improving_2016,
	title = {Improving {PILCO} with Bayesian neural network dynamics models},
	eventtitle = {International Conference on Machine Learning},
	booktitle = {Data-Efficient Machine Learning workshop},
	author = {{Yarin Gal} and {Rowan McAllister} and {Carl Edward Rasmussen}},
	date = {2016},
	year = {2016},
}

@article{friston_active_2017,
	title = {Active Inference: A Process Theory},
	volume = {29},
	issn = {1530-888X},
	doi = {10.1162/NECO_a_00912},
	shorttitle = {Active Inference},
	abstract = {This article describes a process theory based on active inference and belief propagation. Starting from the premise that all neuronal processing (and action selection) can be explained by maximizing Bayesian model evidence-or minimizing variational free energy-we ask whether neuronal responses can be described as a gradient descent on variational free energy. Using a standard (Markov decision process) generative model, we derive the neuronal dynamics implicit in this description and reproduce a remarkable range of well-characterized neuronal phenomena. These include repetition suppression, mismatch negativity, violation responses, place-cell activity, phase precession, theta sequences, theta-gamma coupling, evidence accumulation, race-to-bound dynamics, and transfer of dopamine responses. Furthermore, the (approximately Bayes' optimal) behavior prescribed by these dynamics has a degree of face validity, providing a formal explanation for reward seeking, context learning, and epistemic foraging. Technically, the fact that a gradient descent appears to be a valid description of neuronal activity means that variational free energy is a Lyapunov function for neuronal dynamics, which therefore conform to Hamilton's principle of least action.},
	pages = {1--49},
	number = {1},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Comput},
	author = {Friston, Karl and {FitzGerald}, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},
	date = {2017},
	year = {2017},
	pmid = {27870614},
	file = {Accepted Version:/Users/at449/Zotero/storage/8LD3W6XZ/Friston et al. - 2017 - Active Inference A Process Theory.pdf:application/pdf}
}

@article{friston_free_2019,
	title = {A free energy principle for a particular physics},
	url = {https://arxiv.org/abs/1906.10184v1},
	abstract = {This monograph attempts a theory of every 'thing' that can be distinguished
from other things in a statistical sense. The ensuing statistical
independencies, mediated by Markov blankets, speak to a recursive composition
of ensembles (of things) at increasingly higher spatiotemporal scales. This
decomposition provides a description of small things; e.g., quantum mechanics -
via the Schrodinger equation, ensembles of small things - via statistical
mechanics and related fluctuation theorems, through to big things - via
classical mechanics. These descriptions are complemented with a Bayesian
mechanics for autonomous or active things. Although this work provides a
formulation of every thing, its main contribution is to examine the
implications of Markov blankets for self-organisation to nonequilibrium
steady-state. In brief, we recover an information geometry and accompanying
free energy principle that allows one to interpret the internal states of
something as representing or making inferences about its external states. The
ensuing Bayesian mechanics is compatible with quantum, statistical and
classical mechanics and may offer a formal description of lifelike particles.},
	author = {Friston, Karl},
	urldate = {2019-10-20},
	date = {2019-06-24},
	year = {2019},
	langid = {english},
	file = {Full Text PDF:/Users/at449/Zotero/storage/YPA7YGWK/Friston - 2019 - A free energy principle for a particular physics.pdf:application/pdf;Snapshot:/Users/at449/Zotero/storage/DPF2ISZN/1906.html:text/html}
}

@article{friston_active_2015,
	title = {Active inference and epistemic value},
	volume = {6},
	issn = {1758-8936},
	doi = {10.1080/17588928.2015.1020053},
	abstract = {We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.},
	pages = {187--214},
	number = {4},
	journaltitle = {Cognitive Neuroscience},
	shortjournal = {Cogn Neurosci},
	author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
	date = {2015},
	year = {2015},
	pmid = {25689102}
}

@article{sun_planning_2011,
	title = {Planning to Be Surprised: Optimal Bayesian Exploration in Dynamic Environments},
	url = {http://arxiv.org/abs/1103.5708},
	shorttitle = {Planning to Be Surprised},
	abstract = {To maximize its success, an {AGI} typically needs to explore its initially unknown world. Is there an optimal way of doing so? Here we derive an affirmative answer for a broad class of environments.},
	journaltitle = {{arXiv}:1103.5708 [cs, stat]},
	author = {Sun, Yi and Gomez, Faustino and Schmidhuber, Juergen},
	urldate = {2019-10-20},
	date = {2011-03-29},
	year = {2011},
	eprinttype = {arxiv},
	eprint = {1103.5708},
	file = {arXiv\:1103.5708 PDF:/Users/at449/Zotero/storage/M9QUXTXP/Sun et al. - 2011 - Planning to Be Surprised Optimal Bayesian Explora.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/7WCY7V64/1103.html:text/html}
}

@article{friston_predictive_2009,
	title = {Predictive coding under the free-energy principle},
	volume = {364},
	issn = {1471-2970},
	doi = {10.1098/rstb.2008.0300},
	abstract = {This paper considers prediction and perceptual categorization as an inference problem that is solved by the brain. We assume that the brain models the world as a hierarchy or cascade of dynamical systems that encode causal structure in the sensorium. Perception is equated with the optimization or inversion of these internal models, to explain sensory data. Given a model of how sensory data are generated, we can invoke a generic approach to model inversion, based on a free energy bound on the model's evidence. The ensuing free-energy formulation furnishes equations that prescribe the process of recognition, i.e. the dynamics of neuronal activity that represent the causes of sensory input. Here, we focus on a very general model, whose hierarchical and dynamical structure enables simulated brains to recognize and predict trajectories or sequences of sensory states. We first review hierarchical dynamical models and their inversion. We then show that the brain has the necessary infrastructure to implement this inversion and illustrate this point using synthetic birds that can recognize and categorize birdsongs.},
	pages = {1211--1221},
	number = {1521},
	journaltitle = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences},
	shortjournal = {Philos. Trans. R. Soc. Lond., B, Biol. Sci.},
	author = {Friston, Karl and Kiebel, Stefan},
	date = {2009-05-12},
	year = {2009},
	pmid = {19528002},
	pmcid = {PMC2666703},
	file = {Full Text:/Users/at449/Zotero/storage/F33DUQSG/Friston and Kiebel - 2009 - Predictive coding under the free-energy principle.pdf:application/pdf}
}

@book{camacho_model_2007,
	location = {London},
	edition = {2},
	title = {Model Predictive Control},
	isbn = {978-1-85233-694-3},
	url = {https://www.springer.com/gp/book/9781852336943},
	series = {Advanced Textbooks in Control and Signal Processing},
	abstract = {From power plants to sugar refining, model predictive control ({MPC}) schemes have established themselves as the preferred control strategies for a wide variety of processes. The second edition of Model Predictive Control provides a thorough introduction to theoretical and practical aspects of the most commonly used {MPC} strategies. It bridges the gap between the powerful but often abstract techniques of control researchers and the more empirical approach of practitioners. Model Predictive Control demonstrates that a powerful technique does not always require complex control algorithms. The text features material on the following subjects: general {MPC} elements and algorithms;commercial {MPC} schemes;generalized predictive controlmultivariable, robust, constrained nonlinear and hybrid {MPC};fast methods for {MPC} implementation;applications. All of the material is thoroughly updated for the second edition with the chapters on nonlinear {MPC}, {MPC} and hybrid systems and {MPC} implementation being entirely new. Many new exercises and examples have also have also been added throughout and {MATLAB}® programs to aid in their solution can be downloaded from extras.springer.com. The text is an excellent aid for graduate and advanced undergraduate students and will also be of use to researchers and industrial practitioners wishing to keep abreast of a fast-moving field.},
	publisher = {Springer-Verlag},
	author = {Camacho, Eduardo F. and Alba, Carlos Bordons},
	urldate = {2019-11-15},
	date = {2007},
	year = {2007},
	langid = {english},
	doi = {10.1007/978-0-85729-398-5},
	file = {Snapshot:/Users/at449/Zotero/storage/5VU7DS2Q/9781852336943.html:text/html}
}

@article{richards_deep_2019,
	title = {A deep learning framework for neuroscience},
	volume = {22},
	rights = {2019 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0520-2},
	doi = {10.1038/s41593-019-0520-2},
	abstract = {A deep network is best understood in terms of components used to design it—objective functions, architecture and learning rules—rather than unit-by-unit computation. Richards et al. argue that this inspires fruitful approaches to systems neuroscience.},
	pages = {1761--1770},
	number = {11},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Richards, Blake A. and Lillicrap, Timothy P. and Beaudoin, Philippe and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and Clopath, Claudia and Costa, Rui Ponte and Berker, Archy de and Ganguli, Surya and Gillon, Colleen J. and Hafner, Danijar and Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and Lindsay, Grace W. and Miller, Kenneth D. and Naud, Richard and Pack, Christopher C. and Poirazi, Panayiota and Roelfsema, Pieter and Sacramento, João and Saxe, Andrew and Scellier, Benjamin and Schapiro, Anna C. and Senn, Walter and Wayne, Greg and Yamins, Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien, Denis and Kording, Konrad P.},
	urldate = {2019-11-15},
	date = {2019-11},
	year = {2019},
	langid = {english},
	file = {Full Text PDF:/Users/at449/Zotero/storage/H5DG59MI/Richards et al. - 2019 - A deep learning framework for neuroscience.pdf:application/pdf;Snapshot:/Users/at449/Zotero/storage/GITWC66C/s41593-019-0520-2.html:text/html}
}

@article{friston_deep_2018,
	title = {Deep temporal models and active inference},
	volume = {90},
	issn = {0149-7634},
	url = {http://www.sciencedirect.com/science/article/pii/S0149763418302525},
	doi = {10.1016/j.neubiorev.2018.04.004},
	abstract = {How do we navigate a deeply structured world? Why are you reading this sentence first – and did you actually look at the fifth word? This review offers some answers by appealing to active inference based on deep temporal models. It builds on previous formulations of active inference to simulate behavioural and electrophysiological responses under hierarchical generative models of state transitions. Inverting these models corresponds to sequential inference, such that the state at any hierarchical level entails a sequence of transitions in the level below. The deep temporal aspect of these models means that evidence is accumulated over nested time scales, enabling inferences about narratives (i.e., temporal scenes). We illustrate this behaviour with Bayesian belief updating – and neuronal process theories – to simulate the epistemic foraging seen in reading. These simulations reproduce perisaccadic delay period activity and local field potentials seen empirically. Finally, we exploit the deep structure of these models to simulate responses to local (e.g., font type) and global (e.g., semantic) violations; reproducing mismatch negativity and P300 responses respectively.},
	pages = {486--501},
	journaltitle = {Neuroscience \& Biobehavioral Reviews},
	shortjournal = {Neuroscience \& Biobehavioral Reviews},
	author = {Friston, Karl J. and Rosch, Richard and Parr, Thomas and Price, Cathy and Bowman, Howard},
	urldate = {2019-11-15},
	date = {2018-07-01},
	year={2018},
	langid = {english},
	file = {ScienceDirect Full Text PDF:/Users/at449/Zotero/storage/T6RWT9XZ/Friston et al. - 2018 - Deep temporal models and active inference.pdf:application/pdf;ScienceDirect Snapshot:/Users/at449/Zotero/storage/U6CMYAZ8/S0149763418302525.html:text/html}
}

@article{friston_active_2017-1,
	title = {Active Inference, Curiosity and Insight},
	volume = {29},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco_a_00999},
	doi = {10.1162/neco_a_00999},
	abstract = {This article offers a formal account of curiosity and insight in terms of active (Bayesian) inference. It deals with the dual problem of inferring states of the world and learning its statistical structure. In contrast to current trends in machine learning (e.g., deep learning), we focus on how people attain insight and understanding using just a handful of observations, which are solicited through curious behavior. We use simulations of abstract rule learning and approximate Bayesian inference to show that minimizing (expected) variational free energy leads to active sampling of novel contingencies. This epistemic behavior closes explanatory gaps in generative models of the world, thereby reducing uncertainty and satisfying curiosity. We then move from epistemic learning to model selection or structure learning to show how abductive processes emerge when agents test plausible hypotheses about symmetries (i.e., invariances or rules) in their generative models. The ensuing Bayesian model reduction evinces mechanisms associated with sleep and has all the hallmarks of “aha” moments. This formulation moves toward a computational account of consciousness in the pre-Cartesian sense of sharable knowledge (i.e., con: “together”; scire: “to know”).},
	pages = {2633--2683},
	number = {10},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Friston, Karl J. and Lin, Marco and Frith, Christopher D. and Pezzulo, Giovanni and Hobson, J. Allan and Ondobaka, Sasha},
	urldate = {2019-11-15},
	date = {2017-08-04},
	year = {2017},
	file = {Snapshot:/Users/at449/Zotero/storage/SU7PZ2S4/neco_a_00999.html:text/html}
}

@article{schwartenbeck_computational_2019,
	title = {Computational mechanisms of curiosity and goal-directed exploration},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.41703},
	doi = {10.7554/eLife.41703},
	abstract = {Successful behaviour depends on the right balance between maximising reward and soliciting information about the world. Here, we show how different types of information-gain emerge when casting behaviour as surprise minimisation. We present two distinct mechanisms for goal-directed exploration that express separable profiles of active sampling to reduce uncertainty. ‘Hidden state’ exploration motivates agents to sample unambiguous observations to accurately infer the (hidden) state of the world. Conversely, ‘model parameter’ exploration, compels agents to sample outcomes associated with high uncertainty, if they are informative for their representation of the task structure. We illustrate the emergence of these types of information-gain, termed active inference and active learning, and show how these forms of exploration induce distinct patterns of ‘Bayes-optimal’ behaviour. Our findings provide a computational framework for understanding how distinct levels of uncertainty systematically affect the exploration-exploitation trade-off in decision-making.},
	pages = {e41703},
	journaltitle = {{eLife}},
	author = {Schwartenbeck, Philipp and Passecker, Johannes and Hauser, Tobias U and {FitzGerald}, Thomas {HB} and Kronbichler, Martin and Friston, Karl J},
	editor = {Frank, Michael J},
	urldate = {2019-11-15},
	date = {2019-05-10},
	year = {2019},
	file = {Full Text PDF:/Users/at449/Zotero/storage/NFYCJHLH/Schwartenbeck et al. - 2019 - Computational mechanisms of curiosity and goal-dir.pdf:application/pdf}
}

@article{tschantz_learning_2019,
	title = {Learning action-oriented models through active inference},
	rights = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NonCommercial} 4.0 International), {CC} {BY}-{NC} 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/764969v1},
	doi = {10.1101/764969},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Converging theories suggest that organisms learn and exploit probabilistic models of their environment. However, it remains unclear how such models can be learned in practice. The open-ended complexity of natural environments means that it is generally infeasible for organisms to model their environment comprehensively. Alternatively, \textit{action-oriented} models attempt to encode a parsimonious representation of adaptive agent-environment interactions. One approach to learning action-oriented models is to learn online in the presence of goal-directed behaviours. This constrains an agent to behaviourally relevant trajectories, reducing the diversity of the data a model need account for. Unfortunately, this approach can cause models to prematurely converge to sub-optimal solutions, through a process we refer to as a \textit{bad-bootstrap}. Here, we exploit the normative framework of \textit{active inference} to show that efficient action-oriented models can be learned by balancing goal-oriented and epistemic (\textit{information-seeking}) behaviours in a principled manner. We illustrate our approach using a simple agent-based model of bacterial chemotaxis. We first demonstrate that learning via goal-directed behaviour indeed constrains models to behaviorally relevant aspects of the environment, but that this approach is prone to sub-optimal convergence. We then demonstrate that epistemic behaviours facilitate the construction of accurate and comprehensive models, but that these models are not tailored to any specific behavioural niche and are therefore less efficient in their use of data. Finally, we show that active inference agents learn models that are parsimonious, tailored to action, and which avoid bad bootstraps and sub-optimal convergence. Critically, our results indicate that models learned through active inference can support adaptive behaviour in spite of, and indeed \textit{because of}, their departure from veridical representations of the environment. Our approach provides a principled method for learning adaptive models from limited interactions with an environment, highlighting a route to sample efficient learning algorithms.{\textless}/p{\textgreater}},
	pages = {764969},
	journaltitle = {{bioRxiv}},
	author = {Tschantz, Alexander and Seth, Anil K. and Buckley, Christopher L.},
	urldate = {2019-11-15},
	date = {2019-09-11},
	year = {2019},
	langid = {english},
	file = {Full Text PDF:/Users/at449/Zotero/storage/56VX3XVG/Tschantz et al. - 2019 - Learning action-oriented models through active inf.pdf:application/pdf;Snapshot:/Users/at449/Zotero/storage/7LZSAHZD/764969v1.html:text/html}
}

@online{noauthor_[1506.07365]_nodate,
	title = {[1506.07365] Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
	url = {https://arxiv.org/abs/1506.07365},
	urldate = {2019-11-15},
	file = {[1506.07365] Embed to Control\: A Locally Linear Latent Dynamics Model for Control from Raw Images:/Users/at449/Zotero/storage/3U2BY6NU/1506.html:text/html}
}

@article{watter_embed_2015,
	title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
	url = {http://arxiv.org/abs/1506.07365},
	shorttitle = {Embed to Control},
	abstract = {We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems.},
	journaltitle = {{arXiv}:1506.07365 [cs, stat]},
	author = {Watter, Manuel and Springenberg, Jost Tobias and Boedecker, Joschka and Riedmiller, Martin},
	urldate = {2019-11-15},
	date = {2015-11-20},
	year = {2015},
	eprinttype = {arxiv},
	eprint = {1506.07365},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/68IM82VK/Watter et al. - 2015 - Embed to Control A Locally Linear Latent Dynamics.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/77ZJXK6P/1506.html:text/html}
}

@article{nagabandi_neural_2017,
	title = {Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning},
	url = {http://arxiv.org/abs/1708.02596},
	abstract = {Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that medium-sized neural network models can in fact be combined with model predictive control ({MPC}) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits to accomplish various complex locomotion tasks. We also propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on {MuJoCo} locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5x on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf},
	journaltitle = {{arXiv}:1708.02596 [cs]},
	author = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S. and Levine, Sergey},
	urldate = {2019-11-15},
	date = {2017-12-01},
	year = {2017},
	eprinttype = {arxiv},
	eprint = {1708.02596},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/4JGCPPD2/Nagabandi et al. - 2017 - Neural Network Dynamics for Model-Based Deep Reinf.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/3N2ZLTYK/1708.html:text/html}
}

@article{clark_whatever_2013,
	title = {Whatever next? Predictive brains, situated agents, and the future of cognitive science},
	volume = {36},
	issn = {1469-1825},
	doi = {10.1017/S0140525X12000477},
	shorttitle = {Whatever next?},
	abstract = {Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this "hierarchical prediction machine" approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.},
	pages = {181--204},
	number = {3},
	journaltitle = {The Behavioral and Brain Sciences},
	shortjournal = {Behav Brain Sci},
	author = {Clark, Andy},
	date = {2013-06},
	year = {2013},
	pmid = {23663408},
	file = {Full Text:/Users/at449/Zotero/storage/JHPY4N7Q/Clark - 2013 - Whatever next Predictive brains, situated agents,.pdf:application/pdf}
}

@article{agrawal_analysis_2012,
	title = {Analysis of Thompson Sampling for the multi-armed bandit problem},
	url = {http://arxiv.org/abs/1111.1797},
	abstract = {The multi-armed bandit problem is a popular model for studying exploration/exploitation trade-off in sequential decision problems. Many algorithms are now available for this well-studied problem. One of the earliest algorithms, given by W. R. Thompson, dates back to 1933. This algorithm, referred to as Thompson Sampling, is a natural Bayesian algorithm. The basic idea is to choose an arm to play according to its probability of being the best arm. Thompson Sampling algorithm has experimentally been shown to be close to optimal. In addition, it is efficient to implement and exhibits several desirable properties such as small regret for delayed feedback. However, theoretical understanding of this algorithm was quite limited. In this paper, for the first time, we show that Thompson Sampling algorithm achieves logarithmic expected regret for the multi-armed bandit problem. More precisely, for the two-armed bandit problem, the expected regret in time \$T\$ is \$O({\textbackslash}frac\{{\textbackslash}ln T\}\{{\textbackslash}Delta\} + {\textbackslash}frac\{1\}\{{\textbackslash}Delta{\textasciicircum}3\})\$. And, for the \$N\$-armed bandit problem, the expected regret in time \$T\$ is \$O([({\textbackslash}sum\_\{i=2\}{\textasciicircum}N {\textbackslash}frac\{1\}\{{\textbackslash}Delta\_i{\textasciicircum}2\}){\textasciicircum}2] {\textbackslash}ln T)\$. Our bounds are optimal but for the dependence on \${\textbackslash}Delta\_i\$ and the constant factors in big-Oh.},
	journaltitle = {{arXiv}:1111.1797 [cs]},
	author = {Agrawal, Shipra and Goyal, Navin},
	urldate = {2019-11-19},
	date = {2012-04-09},
	year = {2012},
	eprinttype = {arxiv},
	eprint = {1111.1797},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/KQCWTF84/Agrawal and Goyal - 2012 - Analysis of Thompson Sampling for the multi-armed .pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/CS9WHUVU/1111.html:text/html}
}

@article{bellemare_unifying_2016,
	title = {Unifying Count-Based Exploration and Intrinsic Motivation},
	url = {http://arxiv.org/abs/1606.01868},
	abstract = {We consider an agent's uncertainty about its environment and the problem of generalizing this uncertainty across observations. Specifically, we focus on the problem of exploration in non-tabular reinforcement learning. Drawing inspiration from the intrinsic motivation literature, we use density models to measure uncertainty, and propose a novel algorithm for deriving a pseudo-count from an arbitrary density model. This technique enables us to generalize count-based exploration algorithms to the non-tabular case. We apply our ideas to Atari 2600 games, providing sensible pseudo-counts from raw pixels. We transform these pseudo-counts into intrinsic rewards and obtain significantly improved exploration in a number of hard games, including the infamously difficult Montezuma's Revenge.},
	journaltitle = {{arXiv}:1606.01868 [cs, stat]},
	author = {Bellemare, Marc G. and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
	urldate = {2019-11-19},
	date = {2016-11-07},
	year = {2016},
	eprinttype = {arxiv},
	eprint = {1606.01868},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/CWLCQZPI/Bellemare et al. - 2016 - Unifying Count-Based Exploration and Intrinsic Mot.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/WDY866QW/1606.html:text/html}
}

@article{stadie_incentivizing_2015,
	title = {Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models},
	url = {http://arxiv.org/abs/1507.00814},
	abstract = {Achieving efficient and scalable exploration in complex domains poses a major challenge in reinforcement learning. While Bayesian and {PAC}-{MDP} approaches to the exploration problem offer strong formal guarantees, they are often impractical in higher dimensions due to their reliance on enumerating the state-action space. Hence, exploration in complex domains is often performed with simple epsilon-greedy methods. In this paper, we consider the challenging Atari games domain, which requires processing raw pixel inputs and delayed rewards. We evaluate several more sophisticated exploration strategies, including Thompson sampling and Boltzman exploration, and propose a new exploration method based on assigning exploration bonuses from a concurrently learned model of the system dynamics. By parameterizing our learned model with a neural network, we are able to develop a scalable and efficient approach to exploration bonuses that can be applied to tasks with complex, high-dimensional state spaces. In the Atari domain, our method provides the most consistent improvement across a range of games that pose a major challenge for prior methods. In addition to raw game-scores, we also develop an {AUC}-100 metric for the Atari Learning domain to evaluate the impact of exploration on this benchmark.},
	journaltitle = {{arXiv}:1507.00814 [cs, stat]},
	author = {Stadie, Bradly C. and Levine, Sergey and Abbeel, Pieter},
	urldate = {2019-11-19},
	date = {2015-11-19},
	year = {2015},
	eprinttype = {arxiv},
	eprint = {1507.00814},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/XPDNHRXQ/Stadie et al. - 2015 - Incentivizing Exploration In Reinforcement Learnin.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/SDN8QP4I/1507.html:text/html}
}

@incollection{chentanez_intrinsically_2005,
	title = {Intrinsically Motivated Reinforcement Learning},
	url = {http://papers.nips.cc/paper/2552-intrinsically-motivated-reinforcement-learning.pdf},
	pages = {1281--1288},
	booktitle = {Advances in Neural Information Processing Systems 17},
	publisher = {{MIT} Press},
	author = {Chentanez, Nuttapong and Barto, Andrew G. and Singh, Satinder P.},
	editor = {Saul, L. K. and Weiss, Y. and Bottou, L.},
	urldate = {2019-11-19},
	date = {2005},
	year = {2005},
	file = {NIPS Full Text PDF:/Users/at449/Zotero/storage/MA2B56WW/Chentanez et al. - 2005 - Intrinsically Motivated Reinforcement Learning.pdf:application/pdf;NIPS Snapshot:/Users/at449/Zotero/storage/HEJM8V56/2552-intrinsically-motivated-reinforcement-learning.html:text/html}
}

@article{lindley_measure_1956,
	title = {On a Measure of the Information Provided by an Experiment},
	volume = {27},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/euclid.aoms/1177728069},
	doi = {10.1214/aoms/1177728069},
	abstract = {A measure is introduced of the information provided by an experiment. The measure is derived from the work of Shannon [10] and involves the knowledge prior to performing the experiment, expressed through a prior probability distribution over the parameter space. The measure is used to compare some pairs of experiments without reference to prior distributions; this method of comparison is contrasted with the methods discussed by Blackwell. Finally, the measure is applied to provide a solution to some problems of experimental design, where the object of experimentation is not to reach decisions but rather to gain knowledge about the world.},
	pages = {986--1005},
	number = {4},
	journaltitle = {The Annals of Mathematical Statistics},
	shortjournal = {Ann. Math. Statist.},
	author = {Lindley, D. V.},
	urldate = {2019-11-19},
	date = {1956-12},
	year = {1956},
	mrnumber = {MR83936},
	zmnumber = {0073.14103},
	file = {Full Text PDF:/Users/at449/Zotero/storage/5LU9DW6H/Lindley - 1956 - On a Measure of the Information Provided by an Exp.pdf:application/pdf;Snapshot:/Users/at449/Zotero/storage/EMBMT2UT/1177728069.html:text/html}
}

@article{still_information-theoretic_2012,
	title = {An information-theoretic approach to curiosity-driven reinforcement learning},
	volume = {131},
	issn = {1611-7530},
	doi = {10.1007/s12064-011-0142-z},
	abstract = {We provide a fresh look at the problem of exploration in reinforcement learning, drawing on ideas from information theory. First, we show that Boltzmann-style exploration, one of the main exploration methods used in reinforcement learning, is optimal from an information-theoretic point of view, in that it optimally trades expected return for the coding cost of the policy. Second, we address the problem of curiosity-driven learning. We propose that, in addition to maximizing the expected return, a learner should choose a policy that also maximizes the learner's predictive power. This makes the world both interesting and exploitable. Optimal policies then have the form of Boltzmann-style exploration with a bonus, containing a novel exploration-exploitation trade-off which emerges naturally from the proposed optimization principle. Importantly, this exploration-exploitation trade-off persists in the optimal deterministic policy, i.e., when there is no exploration due to randomness. As a result, exploration is understood as an emerging behavior that optimizes information gain, rather than being modeled as pure randomization of action choices.},
	pages = {139--148},
	number = {3},
	journaltitle = {Theory in Biosciences = Theorie in Den Biowissenschaften},
	shortjournal = {Theory Biosci.},
	author = {Still, Susanne and Precup, Doina},
	date = {2012-09},
	year = {2012},
	pmid = {22791268}
}

@article{mohamed_variational_2015,
	title = {Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning},
	url = {http://arxiv.org/abs/1509.08731},
	abstract = {The mutual information is a core statistical quantity that has applications in all areas of machine learning, whether this is in training of density models over multiple data modalities, in maximising the efficiency of noisy transmission channels, or when learning behaviour policies for exploration by artificial agents. Most learning algorithms that involve optimisation of the mutual information rely on the Blahut-Arimoto algorithm --- an enumerative algorithm with exponential complexity that is not suitable for modern machine learning applications. This paper provides a new approach for scalable optimisation of the mutual information by merging techniques from variational inference and deep learning. We develop our approach by focusing on the problem of intrinsically-motivated learning, where the mutual information forms the definition of a well-known internal drive known as empowerment. Using a variational lower bound on the mutual information, combined with convolutional networks for handling visual input streams, we develop a stochastic optimisation algorithm that allows for scalable information maximisation and empowerment-based reasoning directly from pixels to actions.},
	journaltitle = {{arXiv}:1509.08731 [cs, stat]},
	author = {Mohamed, Shakir and Rezende, Danilo Jimenez},
	urldate = {2019-11-19},
	date = {2015-09-29},
	year = {2015},
	eprinttype = {arxiv},
	eprint = {1509.08731},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/QCV5GTWX/Mohamed and Rezende - 2015 - Variational Information Maximisation for Intrinsic.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/UQRFADST/1509.html:text/html}
}

@article{fort_deep_2019,
	title = {Deep Ensembles: A Loss Landscape Perspective},
	url = {http://arxiv.org/abs/1912.02757},
	shorttitle = {Deep Ensembles},
	abstract = {Deep ensembles have been empirically shown to be a promising approach for improving accuracy, uncertainty and out-of-distribution robustness of deep learning models. While deep ensembles were theoretically motivated by the bootstrap, non-bootstrap ensembles trained with just random initialization also perform well in practice, which suggests that there could be other explanations for why deep ensembles work well. Bayesian neural networks, which learn distributions over the parameters of the network, are theoretically well-motivated by Bayesian principles, but do not perform as well as deep ensembles in practice, particularly under dataset shift. One possible explanation for this gap between theory and practice is that popular scalable approximate Bayesian methods tend to focus on a single mode, whereas deep ensembles tend to explore diverse modes in function space. We investigate this hypothesis by building on recent work on understanding the loss landscape of neural networks and adding our own exploration to measure the similarity of functions in the space of predictions. Our results show that random initializations explore entirely different modes, while functions along an optimization trajectory or sampled from the subspace thereof cluster within a single mode predictions-wise, while often deviating significantly in the weight space. We demonstrate that while low-loss connectors between modes exist, they are not connected in the space of predictions. Developing the concept of the diversity--accuracy plane, we show that the decorrelation power of random initializations is unmatched by popular subspace sampling methods.},
	journaltitle = {{arXiv}:1912.02757 [cs, stat]},
	author = {Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
	urldate = {2019-12-07},
	date = {2019-12-05},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1912.02757},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/9FVM7LC2/Fort et al. - 2019 - Deep Ensembles A Loss Landscape Perspective.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/KCDSS8C9/1912.html:text/html}
}

@article{tschiatschek_variational_2018,
	title = {Variational Inference for Data-Efficient Model Learning in {POMDPs}},
	url = {http://arxiv.org/abs/1805.09281},
	abstract = {Partially observable Markov decision processes ({POMDPs}) are a powerful abstraction for tasks that require decision making under uncertainty, and capture a wide range of real world tasks. Today, effective planning approaches exist that generate effective strategies given black-box models of a {POMDP} task. Yet, an open question is how to acquire accurate models for complex domains. In this paper we propose {DELIP}, an approach to model learning for {POMDPs} that utilizes amortized structured variational inference. We empirically show that our model leads to effective control strategies when coupled with state-of-the-art planners. Intuitively, model-based approaches should be particularly beneficial in environments with changing reward structures, or where rewards are initially unknown. Our experiments confirm that {DELIP} is particularly effective in this setting.},
	journaltitle = {{arXiv}:1805.09281 [cs, stat]},
	author = {Tschiatschek, Sebastian and Arulkumaran, Kai and Stühmer, Jan and Hofmann, Katja},
	urldate = {2019-12-11},
	date = {2018-05-23},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1805.09281},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/KL78Q23Q/Tschiatschek et al. - 2018 - Variational Inference for Data-Efficient Model Lea.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/5TM5NB6V/1805.html:text/html}
}

@article{markovic_meta-control_2019,
	title = {Meta-control of the exploration-exploitation dilemma emerges from probabilistic inference over a hierarchy of time scales},
	rights = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NoDerivs} 4.0 International), {CC} {BY}-{ND} 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/847566v1},
	doi = {10.1101/847566},
	abstract = {{\textless}p{\textgreater}Cognitive control is typically understood as a set of mechanisms which enable humans to reach goals that require integrating the consequences of actions over longer time scales. Importantly, using routine beheavior or making choices beneficial only at a short time scales would prevent one from attaining these goals. During the past two decades, researchers have proposed various computational cognitive models that successfully account for behaviour related to cognitive control in a wide range of laboratory tasks. As humans operate in a dynamic and uncertain environment, making elaborate plans and integrating experience over multiple time scales is computationally expensive, the specific question of how uncertain consequences at different time scales are integrated into adaptive decisions remains poorly understood. Here, we propose that precisely the problem of integrating experience and forming elaborate plans over multiple time scales is a key component for better understanding how human agents solve cognitive control dilemmas such as the exploration-exploitation dilemma. In support of this conjecture, we present a computational model of probabilistic inference over hidden states and actions, which are represented as a hierarchy of time scales. Simulations of goal-reaching agents instantiating the model in an uncertain and dynamic task environment show how the exploration-exploitation dilemma may be solved by inferring meta-control states which adapt behaviour to changing contexts.{\textless}/p{\textgreater}},
	pages = {847566},
	journaltitle = {{bioRxiv}},
	author = {Marković, Dimitrije and Goschke, Thomas and Kiebel, Stefan J.},
	urldate = {2019-12-10},
	date = {2019-11-20},
	year = {2019},
	langid = {english}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}

@article{tschantz_scaling_2019,
	title = {Scaling active inference},
	url = {http://arxiv.org/abs/1911.10601},
	abstract = {In reinforcement learning ({RL}), agents often operate in partially observed and uncertain environments. Model-based {RL} suggests that this is best achieved by learning and exploiting a probabilistic model of the world. 'Active inference' is an emerging normative framework in cognitive and computational neuroscience that offers a unifying account of how biological agents achieve this. On this framework, inference, learning and action emerge from a single imperative to maximize the Bayesian evidence for a niched model of the world. However, implementations of this process have thus far been restricted to low-dimensional and idealized situations. Here, we present a working implementation of active inference that applies to high-dimensional tasks, with proof-of-principle results demonstrating efficient exploration and an order of magnitude increase in sample efficiency over strong model-free baselines. Our results demonstrate the feasibility of applying active inference at scale and highlight the operational homologies between active inference and current model-based approaches to {RL}.},
	journaltitle = {{arXiv}:1911.10601 [cs, eess, math, stat]},
	author = {Tschantz, Alexander and Baltieri, Manuel and Seth, Anil K. and Buckley, Christopher L.},
	urldate = {2020-02-08},
	date = {2019-11-24},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1911.10601},
	file = {arXiv Fulltext PDF:/Users/at449/Zotero/storage/SSG9C97W/Tschantz et al. - 2019 - Scaling active inference.pdf:application/pdf;arXiv.org Snapshot:/Users/at449/Zotero/storage/JQM9X22W/1911.html:text/html}
}

@article{PEZZULO2018294,
title = "Hierarchical Active Inference: A Theory of Motivated Control",
journal = "Trends in Cognitive Sciences",
volume = "22",
number = "4",
pages = "294 - 306",
year = "2018",
issn = "1364-6613",
doi = "https://doi.org/10.1016/j.tics.2018.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S1364661318300226",
author = "Giovanni Pezzulo and Francesco Rigoli and Karl J. Friston",
keywords = "active inference, cognitive control, executive function, goal-directed decision making, hierarchical inference, motivated control",
abstract = "Motivated control refers to the coordination of behaviour to achieve affectively valenced outcomes or goals. The study of motivated control traditionally assumes a distinction between control and motivational processes, which map to distinct (dorsolateral versus ventromedial) brain systems. However, the respective roles and interactions between these processes remain controversial. We offer a novel perspective that casts control and motivational processes as complementary aspects − goal propagation and prioritization, respectively − of active inference and hierarchical goal processing under deep generative models. We propose that the control hierarchy propagates prior preferences or goals, but their precision is informed by the motivational context, inferred at different levels of the motivational hierarchy. The ensuing integration of control and motivational processes underwrites action and policy selection and, ultimately, motivated behaviour, by enabling deep inference to prioritize goals in a context-sensitive way."
}

@article{nagabandi2019deep,
  title={Deep Dynamics Models for Learning Dexterous Manipulation},
  author={Nagabandi, Anusha and Konoglie, Kurt and Levine, Sergey and Kumar, Vikash},
  journal={arXiv preprint arXiv:1909.11652},
  year={2019}
}

@inproceedings{schmidhuber2007simple,
  title={Simple algorithmic principles of discovery, subjective beauty, selective attention, curiosity \& creativity},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Discovery Science},
  pages={26--38},
  year={2007},
  organization={Springer}
}

@inproceedings{schmidhuber1999artificial,
  title={Artificial curiosity based on discovering novel algorithmic predictability through coevolution},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406)},
  volume={3},
  pages={1612--1618},
  year={1999},
  organization={IEEE}
}

@inproceedings{schmidhuber1991possibility,
  title={A possibility for implementing curiosity and boredom in model-building neural controllers},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proc. of the international conference on simulation of adaptive behavior: From animals to animats},
  pages={222--227},
  year={1991}
}

@inproceedings{storck1995reinforcement,
  title={Reinforcement driven information acquisition in non-deterministic environments},
  author={Storck, Jan and Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the international conference on artificial neural networks, Paris},
  volume={2},
  pages={159--164},
  year={1995},
  organization={Citeseer}
}

@article{haarnoja2018softapplications,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{kim2018emi,
  title={Emi: Exploration with mutual information},
  author={Kim, Hyoungseok and Kim, Jaekyeom and Jeong, Yeonwoo and Levine, Sergey and Song, Hyun Oh},
  journal={arXiv preprint arXiv:1810.01176},
  year={2018}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in neural information processing systems},
  pages={1471--1479},
  year={2016}
}

@article{o2017uncertainty,
  title={The uncertainty bellman equation and exploration},
  author={O'Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1709.05380},
  year={2017}
}

@inproceedings{leibfried2019unified,
  title={A Unified Bellman Optimality Principle Combining Reward Maximization and Empowerment},
  author={Leibfried, Felix and Pascual-Diaz, Sergio and Grau-Moya, Jordi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7867--7878},
  year={2019}
}

@article{de2018unified,
  title={A unified strategy for implementing curiosity and empowerment driven reinforcement learning},
  author={de Abril, Ildefons Magrans and Kanai, Ryota},
  journal={arXiv preprint arXiv:1806.06505},
  year={2018}
}

@article{polydoros2017survey,
  title={Survey of model-based reinforcement learning: Applications on robotics},
  author={Polydoros, Athanasios S and Nalpantidis, Lazaros},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={86},
  number={2},
  pages={153--173},
  year={2017},
  publisher={Springer}
}

@article{friston2019particularphysics,
  title={A free energy principle for a particular physics},
  author={Friston, Karl},
  journal={arXiv preprint arXiv:1906.10184},
  year={2019}
}

@article{yang2016theoretical,
  title={Theoretical perspectives on active sensing},
  author={Yang, Scott Cheng-Hsin and Wolpert, Daniel M and Lengyel, M{\'a}t{\'e}},
  journal={Current opinion in behavioral sciences},
  volume={11},
  pages={100--108},
  year={2016},
  publisher={Elsevier}
}

@article{cohen2007should,
  title={Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration},
  author={Cohen, Jonathan D and McClure, Samuel M and Yu, Angela J},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={362},
  number={1481},
  pages={933--942},
  year={2007},
  publisher={The Royal Society London}
}

@article{dayan2008decision,
  title={Decision theory, reinforcement learning, and the brain},
  author={Dayan, Peter and Daw, Nathaniel D},
  journal={Cognitive, Affective, \& Behavioral Neuroscience},
  volume={8},
  number={4},
  pages={429--453},
  year={2008},
  publisher={Springer}
}

@article{mobbs2018foraging,
  title={Foraging for foundations in decision neuroscience: insights from ethology},
  author={Mobbs, Dean and Trimmer, Pete C and Blumstein, Daniel T and Dayan, Peter},
  journal={Nature Reviews Neuroscience},
  volume={19},
  number={7},
  pages={419--427},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{wilson2014humans,
  title={Humans use directed and random exploration to solve the explore--exploit dilemma.},
  author={Wilson, Robert C and Geana, Andra and White, John M and Ludvig, Elliot A and Cohen, Jonathan D},
  journal={Journal of Experimental Psychology: General},
  volume={143},
  number={6},
  pages={2074},
  year={2014},
  publisher={American Psychological Association}
}

@article{berger2014exploration,
  title={The exploration-exploitation dilemma: a multidisciplinary framework},
  author={Berger-Tal, Oded and Nathan, Jonathan and Meron, Ehud and Saltz, David},
  journal={PloS one},
  volume={9},
  number={4},
  pages={e95693},
  year={2014},
  publisher={Public Library of Science}
}

@inproceedings{thrun1991active,
  title={Active exploration in dynamic environments},
  author={Thrun, Sebastian B and M{\"o}ller, Knut},
  booktitle={Proceedings of the 4th International Conference on Neural Information Processing Systems},
  pages={531--538},
  year={1991}
}

@article{thrun1992efficient,
  title={Efficient exploration in reinforcement learning},
  author={Thrun, Sebastian B},
  year={1992},
  publisher={Citeseer}
}

@inproceedings{geana2016boredom,
  title={Boredom, Information-Seeking and Exploration.},
  author={Geana, Andra and Wilson, Robert and Daw, Nathaniel D and Cohen, Jonathan D},
  booktitle={CogSci},
  year={2016}
}

@article{march1991exploration,
  title={Exploration and exploitation in organizational learning},
  author={March, James G},
  journal={Organization science},
  volume={2},
  number={1},
  pages={71--87},
  year={1991},
  publisher={INFORMS}
}

@article{gupta2006interplay,
  title={The interplay between exploration and exploitation},
  author={Gupta, Anil K and Smith, Ken G and Shalley, Christina E},
  journal={Academy of management journal},
  volume={49},
  number={4},
  pages={693--706},
  year={2006},
  publisher={Academy of Management Briarcliff Manor, NY 10510}
}

@article{miller2016organizational,
  title={Organizational learning with forgetting: Reconsidering the exploration--exploitation tradeoff},
  author={Miller, Kent D and Martignoni, Dirk},
  journal={Strategic Organization},
  volume={14},
  number={1},
  pages={53--72},
  year={2016},
  publisher={Sage Publications Sage UK: London, England}
}

@article{sudhir2016exploration,
  title={The exploration-exploitation tradeoff and efficiency in knowledge production},
  author={Sudhir, K},
  journal={Marketing Science},
  volume={35},
  number={1},
  pages={1--9},
  year={2016},
  publisher={INFORMS}
}

@article{vcrepinvsek2013exploration,
  title={Exploration and exploitation in evolutionary algorithms: A survey},
  author={{\v{C}}repin{\v{s}}ek, Matej and Liu, Shih-Hsi and Mernik, Marjan},
  journal={ACM computing surveys (CSUR)},
  volume={45},
  number={3},
  pages={1--33},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@article{mehlhorn2015unpacking,
  title={Unpacking the exploration--exploitation tradeoff: A synthesis of human and animal literatures.},
  author={Mehlhorn, Katja and Newell, Ben R and Todd, Peter M and Lee, Michael D and Morgan, Kate and Braithwaite, Victoria A and Hausmann, Daniel and Fiedler, Klaus and Gonzalez, Cleotilde},
  journal={Decision},
  volume={2},
  number={3},
  pages={191},
  year={2015},
  publisher={Educational Publishing Foundation}
}

@article{kramer1991exploration,
  title={Exploration versus exploitation: a field study of time allocation to environmental tracking by foraging chipmunks},
  author={Kramer, Donald L and Weary, Daniel M},
  journal={Animal Behaviour},
  volume={41},
  number={3},
  pages={443--449},
  year={1991},
  publisher={Elsevier}
}

@article{zhang2019balancing,
  title={Balancing exploration and exploitation in multiobjective evolutionary optimization},
  author={Zhang, Hu and Sun, Jianyong and Liu, Tonglin and Zhang, Ke and Zhang, Qingfu},
  journal={Information Sciences},
  volume={497},
  pages={129--148},
  year={2019},
  publisher={Elsevier}
}

@article{traulsen2009exploration,
  title={Exploration dynamics in evolutionary games},
  author={Traulsen, Arne and Hauert, Christoph and De Silva, Hannelore and Nowak, Martin A and Sigmund, Karl},
  journal={Proceedings of the National Academy of Sciences},
  volume={106},
  number={3},
  pages={709--712},
  year={2009},
  publisher={National Acad Sciences}
}

@article{macready1998bandit,
  title={Bandit problems and the exploration/exploitation tradeoff},
  author={Macready, William G and Wolpert, David H},
  journal={IEEE Transactions on evolutionary computation},
  volume={2},
  number={1},
  pages={2--22},
  year={1998},
  publisher={IEEE}
}

@article{he2004exploration,
  title={Exploration vs. exploitation: An empirical test of the ambidexterity hypothesis},
  author={He, Zi-Lin and Wong, Poh-Kam},
  journal={Organization science},
  volume={15},
  number={4},
  pages={481--494},
  year={2004},
  publisher={INFORMS}
}

@article{li2008exploration,
  title={Exploration and exploitation in innovation: Reframing the interpretation},
  author={Li, Ying and Vanhaverbeke, Wim and Schoenmakers, Wilfred},
  journal={Creativity and innovation management},
  volume={17},
  number={2},
  pages={107--126},
  year={2008},
  publisher={Wiley Online Library}
}

@incollection{akerlof1978market,
  title={The market for “lemons”: Quality uncertainty and the market mechanism},
  author={Akerlof, George A},
  booktitle={Uncertainty in economics},
  pages={235--251},
  year={1978},
  publisher={Elsevier}
}

@article{stigler1961economics,
  title={The economics of information},
  author={Stigler, George J},
  journal={Journal of political economy},
  volume={69},
  number={3},
  pages={213--225},
  year={1961},
  publisher={The University of Chicago Press}
}

@article{charnov2006optimal,
  title={Optimal foraging: some theoretical explorations},
  author={Charnov, Eric and Orians, Gordon H},
  year={2006}
}

@article{brenner2006behavior,
  title={On the behavior of proposers in ultimatum games},
  author={Brenner, Thomas and Vriend, Nicolaas J},
  journal={Journal of Economic Behavior \& Organization},
  volume={61},
  number={4},
  pages={617--631},
  year={2006},
  publisher={Elsevier}
}

@article{krebs1978test,
  title={Test of optimal sampling by foraging great tits},
  author={Krebs, John R and Kacelnik, Alejandro and Taylor, Peter},
  journal={Nature},
  volume={275},
  number={5675},
  pages={27--31},
  year={1978},
  publisher={Nature Publishing Group}
}

@article{aston2005integrative,
  title={An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance},
  author={Aston-Jones, Gary and Cohen, Jonathan D},
  journal={Annu. Rev. Neurosci.},
  volume={28},
  pages={403--450},
  year={2005},
  publisher={Annual Reviews}
}

@article{angela2005uncertainty,
  title={Uncertainty, neuromodulation, and attention},
  author={Angela, J Yu and Dayan, Peter},
  journal={Neuron},
  volume={46},
  number={4},
  pages={681--692},
  year={2005},
  publisher={Elsevier}
}

@article{yeung2004neural,
  title={The neural basis of error detection: conflict monitoring and the error-related negativity.},
  author={Yeung, Nick and Botvinick, Matthew M and Cohen, Jonathan D},
  journal={Psychological review},
  volume={111},
  number={4},
  pages={931},
  year={2004},
  publisher={American Psychological Association}
}

@article{sara2009locus,
  title={The locus coeruleus and noradrenergic modulation of cognition},
  author={Sara, Susan J},
  journal={Nature reviews neuroscience},
  volume={10},
  number={3},
  pages={211--223},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{aston1994locus,
  title={Locus coeruleus neurons in monkey are selectively activated by attended cues in a vigilance task},
  author={Aston-Jones, Gary and Rajkowski, Janusz and Kubiak, Piotr and Alexinsky, Tatiana},
  journal={Journal of Neuroscience},
  volume={14},
  number={7},
  pages={4467--4480},
  year={1994},
  publisher={Soc Neuroscience}
}

@inproceedings{gilzenrat2003pupil,
  title={Pupil dynamics predict changes in task engagement mediated by locus coeruleus},
  author={Gilzenrat, MS and Cohen, JD and Rajkowski, Janusz and Aston-Jones, Gary},
  booktitle={Society for Neuroscience Abstracts},
  volume={515},
  pages={19},
  year={2003}
}

@article{gottlieb2013information,
  title={Information-seeking, curiosity, and attention: computational and neural mechanisms},
  author={Gottlieb, Jacqueline and Oudeyer, Pierre-Yves and Lopes, Manuel and Baranes, Adrien},
  journal={Trends in cognitive sciences},
  volume={17},
  number={11},
  pages={585--593},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{jamieson2014lil,
  title={lil’ucb: An optimal exploration algorithm for multi-armed bandits},
  author={Jamieson, Kevin and Malloy, Matthew and Nowak, Robert and Bubeck, S{\'e}bastien},
  booktitle={Conference on Learning Theory},
  pages={423--439},
  year={2014},
  organization={PMLR}
}

@inproceedings{kolter2009near,
  title={Near-Bayesian exploration in polynomial time},
  author={Kolter, J Zico and Ng, Andrew Y},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={513--520},
  year={2009}
}

@article{gittins1974dynamic,
  title={A dynamic allocation index for the sequential design of experiments},
  author={Gittins, John},
  journal={Progress in statistics},
  pages={241--266},
  year={1974},
  publisher={North Holland}
}
@inproceedings{wang2016dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={1995--2003},
  year={2016},
  organization={PMLR}
}
@article{kaplan2018planning,
  title={Planning and navigation as active inference},
  author={Kaplan, Raphael and Friston, Karl J},
  journal={Biological cybernetics},
  volume={112},
  number={4},
  pages={323--343},
  year={2018},
  publisher={Springer}
}
@article{heins2020deep,
  title={Deep Active Inference and Scene Construction},
  author={Heins, R Conor and Mirza, M Berk and Parr, Thomas and Friston, Karl and Kagan, Igor and Pooresmaeili, Arezoo},
  journal={Frontiers in Artificial Intelligence},
  volume={3},
  pages={81},
  year={2020},
  publisher={Frontiers}
}
@article{schwartenbeck2015optimal,
  title={Optimal inference with suboptimal models: addiction and active Bayesian inference},
  author={Schwartenbeck, Philipp and FitzGerald, Thomas HB and Mathys, Christoph and Dolan, Ray and Wurst, Friedrich and Kronbichler, Martin and Friston, Karl},
  journal={Medical hypotheses},
  volume={84},
  number={2},
  pages={109--117},
  year={2015},
  publisher={Elsevier}
}
@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@article{sutton1996generalization,
  title={Generalization in reinforcement learning: Successful examples using sparse coarse coding},
  author={Sutton, Richard S},
  journal={Advances in neural information processing systems},
  pages={1038--1044},
  year={1996},
  publisher={Citeseer}
}
@article{singh1996reinforcement,
  title={Reinforcement learning with replacing eligibility traces},
  author={Singh, Satinder P and Sutton, Richard S},
  journal={Machine learning},
  volume={22},
  number={1},
  pages={123--158},
  year={1996},
  publisher={Springer}
}
@incollection{gordon1995stable,
  title={Stable function approximation in dynamic programming},
  author={Gordon, Geoffrey J},
  booktitle={Machine Learning Proceedings 1995},
  pages={261--268},
  year={1995},
  publisher={Elsevier}
}
@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}
@article{doya2000reinforcement,
  title={Reinforcement learning in continuous time and space},
  author={Doya, Kenji},
  journal={Neural computation},
  volume={12},
  number={1},
  pages={219--245},
  year={2000},
  publisher={MIT Press}
}
@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}


@article{gaissmaier2008smart,
  title={The smart potential behind probability matching},
  author={Gaissmaier, Wolfgang and Schooler, Lael J},
  journal={Cognition},
  volume={109},
  number={3},
  pages={416--422},
  year={2008},
  publisher={Elsevier}
}

@article{shanks2002re,
  title={A re-examination of probability matching and rational choice},
  author={Shanks, David R and Tunney, Richard J and McCarthy, John D},
  journal={Journal of Behavioral Decision Making},
  volume={15},
  number={3},
  pages={233--250},
  year={2002},
  publisher={Wiley Online Library}
}
@article{tran2018bayesian,
  title={Bayesian layers: A module for neural network uncertainty},
  author={Tran, Dustin and Dusenberry, Michael W and van der Wilk, Mark and Hafner, Danijar},
  journal={arXiv preprint arXiv:1812.03973},
  year={2018}
}
@inproceedings{gal2016improving,
  title={Improving PILCO with Bayesian neural network dynamics models},
  author={Gal, Yarin and McAllister, Rowan and Rasmussen, Carl Edward},
  booktitle={Data-Efficient Machine Learning workshop, ICML},
  volume={4},
  number={34},
  pages={25},
  year={2016}
}
@book{sarkka2013bayesian,
  title={Bayesian filtering and smoothing},
  author={S{\"a}rkk{\"a}, Simo},
  number={3},
  year={2013},
  publisher={Cambridge University Press}
}
@book{bear2020neuroscience,
  title={Neuroscience: Exploring the brain},
  author={Bear, Mark and Connors, Barry and Paradiso, Michael A},
  year={2020},
  publisher={Jones \& Bartlett Learning, LLC}
}
@article{gerstner2002mathematical,
  title={Mathematical formulations of Hebbian learning},
  author={Gerstner, Wulfram and Kistler, Werner M},
  journal={Biological cybernetics},
  volume={87},
  number={5},
  pages={404--415},
  year={2002},
  publisher={Springer}
}
@article{hebb1949first,
  title={The first stage of perception: growth of the assembly},
  author={Hebb, Donald O},
  journal={The Organization of Behavior},
  volume={4},
  pages={60--78},
  year={1949},
  publisher={Wiley, New York}
}
@article{o1999biologically,
  title={A biologically based computational model of working memory},
  author={O’Reilly, Randall C and Braver, Todd S and Cohen, Jonathan D and others},
  journal={Models of working memory: Mechanisms of active maintenance and executive control},
  pages={375--411},
  year={1999}
}
@article{stuart1997action,
  title={Action potential initiation and backpropagation in neurons of the mammalian CNS},
  author={Stuart, Greg and Spruston, Nelson and Sakmann, Bert and H{\"a}usser, Michael},
  journal={Trends in neurosciences},
  volume={20},
  number={3},
  pages={125--131},
  year={1997},
  publisher={Elsevier}
}
@article{gibson2002theory,
  title={A theory of direct visual perception},
  author={Gibson, James J},
  journal={Vision and Mind: selected readings in the philosophy of perception},
  pages={77--90},
  year={2002}
}


@article{wozny2010probability,
  title={Probability matching as a computational strategy used in perception},
  author={Wozny, David R and Beierholm, Ulrik R and Shams, Ladan},
  journal={PLoS Comput Biol},
  volume={6},
  number={8},
  pages={e1000871},
  year={2010},
  publisher={Public Library of Science}
}

@article{west2003probability,
  title={Is probability matching smart? Associations between probabilistic choices and cognitive ability},
  author={West, Richard F and Stanovich, Keith E},
  journal={Memory \& Cognition},
  volume={31},
  number={2},
  pages={243--251},
  year={2003},
  publisher={Springer}
}

@article{monk2018ecology,
  title={How ecology shapes exploitation: a framework to predict the behavioural response of human and animal foragers along exploration--exploitation trade-offs},
  author={Monk, Christopher T and Barbier, Matthieu and Romanczuk, Pawel and Watson, James R and Al{\'o}s, Josep and Nakayama, Shinnosuke and Rubenstein, Daniel I and Levin, Simon A and Arlinghaus, Robert},
  journal={Ecology letters},
  volume={21},
  number={6},
  pages={779--793},
  year={2018},
  publisher={Wiley Online Library}
}
@inproceedings{baltieri2020predictions,
  title={Predictions in the eye of the beholder: an active inference account of Watt governors},
  author={Baltieri, Manuel and Buckley, Christopher L and Bruineberg, Jelle},
  booktitle={Artificial Life Conference Proceedings},
  pages={121--129},
  year={2020},
  organization={MIT Press}
}
@article{friston2007parcels,
  title={Parcels and particles: Markov blankets in the brain},
  author={Friston, Karl J and Fagerholm, Erik D and Zarghami, Tahereh S and Parr, Thomas and Hip{\'o}lito, In{\^e}s and Magrou, Lo{\"\i}c and Razi, Adeel},
  journal={Network Neuroscience},
  number={Just Accepted},
  pages={1--76},
  year={2007},
  publisher={MIT Press}
}


@article{burns2009chance,
  title={A chance to learn: On matching probabilities to optimize utilities},
  author={Burns, Kevin J and Demaree, Heath A},
  journal={Information Sciences},
  volume={179},
  number={11},
  pages={1599--1607},
  year={2009},
  publisher={Elsevier}
}

@article{tversky1974judgment,
  title={Judgment under uncertainty: Heuristics and biases},
  author={Tversky, Amos and Kahneman, Daniel},
  journal={science},
  volume={185},
  number={4157},
  pages={1124--1131},
  year={1974},
  publisher={American association for the advancement of science}
}

@article{vulkan2000economist,
  title={An economist’s perspective on probability matching},
  author={Vulkan, Nir},
  journal={Journal of economic surveys},
  volume={14},
  number={1},
  pages={101--118},
  year={2000},
  publisher={Wiley Online Library}
}

@article{pyke1984optimal,
  title={Optimal foraging theory: a critical review},
  author={Pyke, Graham H},
  journal={Annual review of ecology and systematics},
  volume={15},
  number={1},
  pages={523--575},
  year={1984},
  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}
}

